{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb4652a",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02c805a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import load_data, prepare_all_samples, get_entity_date_pairs, calculate_metrics\n",
    "from bert_training import tokenize_function, add_special_tokens, make_training_pairs, balance_classes, gold_lookup\n",
    "from bert_extractor import get_context_window, mark_entity, mark_date, preprocess_input, bert_extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e368136f",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b69680b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 101 records\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = load_data(\"data/synthetic.csv\")\n",
    "print(f\"Loaded {len(df)} records\")\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0fc9f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 101 samples\n"
     ]
    }
   ],
   "source": [
    "# Prepare all samples\n",
    "samples = prepare_all_samples(df)\n",
    "print(f\"Prepared {len(samples)} samples\")\n",
    "#samples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128c81f2",
   "metadata": {},
   "source": [
    "BERT Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "597c91cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load local model and tokenizer\n",
    "#model_path = \"./bert_model_training/base_model\"\n",
    "model_path = \"google/bert_uncased_L-2_H-128_A-2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=2, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbe8a875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Patient diagnosed with asthma on 2024-08-02. Diabetes was ruled out on 2024-08-02. Family history of hypertension, last reviewed in 2022. Patient may have pneumonia, last seen on 2024-08-02.',\n",
       " {'start': 23, 'end': 29, 'label': 'asthma'},\n",
       " {'start': 33, 'end': 43, 'parsed': '2024-08-02'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example note\n",
    "note_text = (\n",
    "    \"Patient diagnosed with asthma on 2024-08-02. \"\n",
    "    \"Diabetes was ruled out on 2024-08-02. \"\n",
    "    \"Family history of hypertension, last reviewed in 2022. \"\n",
    "    \"Patient may have pneumonia, last seen on 2024-08-02.\"\n",
    ")\n",
    "\n",
    "# Example entity and date spans (positions are for illustration)\n",
    "entity = {'start': 23, 'end': 29, 'label': 'asthma'}  # \"asthma\"\n",
    "date = {'start': 33, 'end': 43, 'parsed': '2024-08-02'}  # \"2024-08-02\"\n",
    "\n",
    "note_text, entity, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fc165b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context window:\n",
      " Patient diagnosed with asthma on 2024-08-02. Diabetes was ruled out on 2024-08-02. \n"
     ]
    }
   ],
   "source": [
    "#Test context window\n",
    "context = get_context_window(note_text, entity['start'], date['start'], window_size=50)\n",
    "print(\"Context window:\\n\", context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aee65a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity marked:\n",
      " Patient diagnosed with [E]asthma[E] on 2024-08-02. Diabetes was ruled out on 2024-08-02. \n"
     ]
    }
   ],
   "source": [
    "#Test entity marking\n",
    "entity_text = note_text[entity['start']:entity['end']]\n",
    "offset = context.find(entity_text)\n",
    "entity_rel = {'start': offset, 'end': offset + len(entity_text)}\n",
    "\n",
    "marked_entity = mark_entity(context, entity_rel)\n",
    "print(\"Entity marked:\\n\", marked_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98b8343f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date marked:\n",
      " Patient diagnosed with asthma on [D]2024-08-02[D]. Diabetes was ruled out on 2024-08-02. \n"
     ]
    }
   ],
   "source": [
    "#Test date marking\n",
    "date_text = note_text[date['start']:date['end']]\n",
    "offset_date = context.find(date_text)\n",
    "date_rel = {'start': offset_date, 'end': offset_date + len(date_text)}\n",
    "\n",
    "marked_date = mark_date(context, date_rel)\n",
    "print(\"Date marked:\\n\", marked_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "312bc800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed input:\n",
      " ient diagnosed with [E]asthma[E] on [D]2024-08-02[D]. Diabetes\n"
     ]
    }
   ],
   "source": [
    "#Do full pre-processing\n",
    "preprocessed = preprocess_input(note_text, entity, date, window_size=20)\n",
    "print(\"Preprocessed input:\\n\", preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d6298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process samples\n",
    "predictions = []\n",
    "\n",
    "#for sample in tqdm(samples, desc=\"Samples\"):\n",
    "    #pairs = get_entity_date_pairs(sample['entities_list'], sample['dates'])\n",
    "    #for pair in pairs:\n",
    "        #text = f\"Does '{pair['entity_label']}' relate to '{pair['date']}'? {sample['note_text']}...\"\n",
    "        #pred, conf = bert_extraction(text, model, tokenizer)\n",
    "        #if pred == 1:\n",
    "            #predictions.append({'entity_label': pair['entity_label'], 'date': pair['date'], 'confidence': conf})\n",
    "\n",
    "for sample in tqdm(samples, desc=\"Samples\"):\n",
    "    pairs = get_entity_date_pairs(sample['entities_list'], sample['dates'])\n",
    "    for pair in pairs:\n",
    "        entity = pair['entity']\n",
    "        date = pair['date_info']\n",
    "        pred, conf = bert_extraction(sample['note_text'], entity, date, model, tokenizer, window_size=100)\n",
    "        if pred == 1:\n",
    "            predictions.append({'entity_label': entity['label'], 'date': date['parsed'], 'confidence': conf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13064391",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at predictions\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d434c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "metrics = calculate_metrics(predictions, df)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50803ee7",
   "metadata": {},
   "source": [
    "BERT Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203003ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add special tokens to tokenizer\n",
    "add_special_tokens(tokenizer)\n",
    "\n",
    "# Resize model embeddings to match new tokenizer size\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe92557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do some layer freezing here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed8e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split samples\n",
    "train_samples, val_samples = train_test_split(samples, test_size=0.2, random_state=42)\n",
    "print(f\"Train: {len(train_samples)}, Val: {len(val_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbda4182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare training pairs\n",
    "training_pairs = make_training_pairs(train_samples, gold_lookup, window_size=100)\n",
    "val_pairs = make_training_pairs(val_samples, gold_lookup, window_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6666cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balance classes (only training set)\n",
    "training_pairs = balance_classes(training_pairs, ratio=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5c8ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to Datasets\n",
    "train_dataset = Dataset.from_pandas(training_pairs)\n",
    "val_dataset = Dataset.from_pandas(val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b782d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "tokenized_train = train_dataset.map(lambda x: tokenize_function(x, tokenizer), batched=True)\n",
    "tokenized_val = val_dataset.map(lambda x: tokenize_function(x, tokenizer), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793e648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at tokenized dataset\n",
    "tokenized_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d7bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert_model_training/bert_finetuned\",\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fb7e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93471464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c2fedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process validation samples\n",
    "predictions = []\n",
    "\n",
    "for sample in tqdm(val_samples, desc=\"Validation Samples\"):\n",
    "    pairs = get_entity_date_pairs(sample['entities_list'], sample['dates'])\n",
    "    for pair in pairs:\n",
    "        entity = pair['entity']\n",
    "        date = pair['date_info']\n",
    "        pred, conf = bert_extraction(sample['note_text'], entity, date, model, tokenizer, window_size=100)\n",
    "        if pred == 1:\n",
    "            predictions.append({'entity_label': entity['label'], 'date': date['parsed'], 'confidence': conf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d83e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at predictions\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183b3d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "metrics = calculate_metrics(predictions, df)\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
