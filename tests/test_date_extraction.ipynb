{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ae3025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Add utils to path\n",
    "utils_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'utils'))\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.insert(0, utils_path)\n",
    "\n",
    "from date_extractor_utils import clean_value, extract_absolute_dates, normalise_relative, extract_relative_dates, add_relative_dates\n",
    "from general_utils import load_data\n",
    "from naive_extractor_utils import naive_extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ed2da3",
   "metadata": {},
   "source": [
    "Test Absolute Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9470e563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on simple example\n",
    "test_text = \"Patient was seen on 15/06/2025 for follow-up. Next appointment scheduled for January 4th, 2026.\"\n",
    "absolute_dates = extract_absolute_dates(test_text)\n",
    "print(\"\\nSimple test:\")\n",
    "print(f\"Text: {test_text}\")\n",
    "print(\"Results:\")\n",
    "for date in absolute_dates:\n",
    "    print(f\"  '{date['value']}' -> (start: {date['start']}, end: {date['end']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3af8f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on comprehensive examples\n",
    "test_text = \"\"\"\n",
    "Various date formats:\n",
    "1. Standard formats:\n",
    "   - 15/06/2025\n",
    "   - 2025-06-15\n",
    "   - 15-06-2025\n",
    "   \n",
    "2. Month name formats:\n",
    "   - June 15, 2025\n",
    "   - 15 June 2025\n",
    "   - Jun 15, 2025\n",
    "   \n",
    "3. Mixed in text:\n",
    "   The patient was seen on 15/06/2025 and had a follow-up on June 15, 2025.\n",
    "   Next appointment scheduled for January 4th, 2026.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nComprehensive test:\")\n",
    "print(f\"Text: {test_text}\")\n",
    "absolute_dates = extract_absolute_dates(test_text)\n",
    "print(\"\\nResults:\")\n",
    "for date in absolute_dates:\n",
    "    print(f\"  '{date['value']}' -> (start: {date['start']}, end: {date['end']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73a2336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test edge cases\n",
    "edge_cases = [\n",
    "    \"\",  # Empty string\n",
    "    \"No dates here\",  # No dates\n",
    "    \"Invalid dates: 35/13/2025, 00/00/0000\",  # Invalid dates\n",
    "    \"Partial dates: June 2025, 2025\",  # Partial dates\n",
    "]\n",
    "\n",
    "print(\"\\nTesting edge cases:\")\n",
    "for text in edge_cases:\n",
    "    dates = extract_absolute_dates(text)\n",
    "    print(f\"\\nText: '{text}'\")\n",
    "    print(f\"Found {len(dates)} dates:\")\n",
    "    for date in dates:\n",
    "        print(f\"  '{date['value']}' -> (start: {date['start']}, end: {date['end']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e71ecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on actual dataset sample\n",
    "print(\"\\nTesting on dataset sample:\")\n",
    "df = pd.read_csv(\"../data/data.csv\")\n",
    "sample_text = df.iloc[0]['note_text']\n",
    "print(f\"Text: {sample_text[:200]}...\")\n",
    "dates = extract_absolute_dates(sample_text)\n",
    "print(f\"\\nFound {len(dates)} dates:\")\n",
    "for date in dates:\n",
    "    print(f\"  '{date['value']}' -> (start: {date['start']}, end: {date['end']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af7aca",
   "metadata": {},
   "source": [
    "Test Relative Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a93e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on one example\n",
    "test_text = \"Patient was seen last week for follow-up. Next appointment scheduled for tomorrow. Symptoms started 3 days ago.\"\n",
    "relative_dates = extract_relative_dates(test_text)\n",
    "relative_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515f3bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on comprehensive examples to verify all pattern types\n",
    "test_text = \"\"\"\n",
    "Patient was seen last week for follow-up. \n",
    "Next appointment scheduled for tomorrow. \n",
    "Symptoms started 3 days ago.\n",
    "Last visit was on Monday.\n",
    "Previous checkup was 2 weeks earlier.\n",
    "Past few days have been difficult.\n",
    "Several months ago the condition worsened.\n",
    "Earlier this week the patient improved.\n",
    "Last visit was productive.\n",
    "Next few days will be critical.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Testing comprehensive relative date extraction:\")\n",
    "print(f\"Text: {test_text.strip()}\")\n",
    "print(\"\\nResults:\")\n",
    "\n",
    "results = extract_relative_dates(test_text)\n",
    "for result in results:\n",
    "    print(f\"  '{result['value']}' -> (pattern: {result['pattern_type']})\")\n",
    "\n",
    "print(f\"\\nTotal patterns found: {len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1bd9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load main dataset using existing load_data function\n",
    "df = load_data(\"../data/training_dataset_synthetic2.csv\")\n",
    "\n",
    "print(f\"Main dataset: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d7468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add relative dates using the simplified function\n",
    "df = add_relative_dates(df)\n",
    "\n",
    "print(f\"Added relative_dates_json column\")\n",
    "print(f\"Final dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07ea77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many rows have relative dates\n",
    "has_relative_dates = df['relative_dates_json'].apply(lambda x: x != '[]')\n",
    "print(f\"Rows with relative dates: {has_relative_dates.sum()}\")\n",
    "print(f\"Total relative dates found: {sum(len(json.loads(rd)) for rd in df['relative_dates_json'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0928ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows that have relative dates\n",
    "rows_with_relative_dates = df[has_relative_dates]\n",
    "\n",
    "print(f\"\\nExamining {len(rows_with_relative_dates)} rows with relative dates:\")\n",
    "\n",
    "# Show detailed results for each row with relative dates\n",
    "for i, (idx, row) in enumerate(rows_with_relative_dates.iterrows()):\n",
    "    print(f\"\\n--- Row {i+1} (Index {idx}) ---\")\n",
    "    print(f\"Text: {row['note_text'][:200]}...\")\n",
    "    \n",
    "    # Parse and display relative dates\n",
    "    relative_dates = json.loads(row['relative_dates_json'])\n",
    "    print(f\"Found {len(relative_dates)} relative dates:\")\n",
    "    for rd in relative_dates:\n",
    "        print(f\"  '{rd['value']}' -> (pattern: {rd['pattern_type']})\")\n",
    "    \n",
    "    # Only show first 5 rows to avoid too much output\n",
    "    if i >= 4:\n",
    "        remaining = len(rows_with_relative_dates) - 5\n",
    "        if remaining > 0:\n",
    "            print(f\"\\n... and {remaining} more rows with relative dates\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9109d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the row with relative dates\n",
    "row_with_relative = df[has_relative_dates].iloc[0]\n",
    "print(\"Testing naive extractor with relative dates:\")\n",
    "print(f\"Text: {row_with_relative['note_text'][:200]}...\")\n",
    "\n",
    "# Get entities and dates\n",
    "entities = row_with_relative['entities_json']\n",
    "absolute_dates = row_with_relative['dates_json']\n",
    "relative_dates = json.loads(row_with_relative['relative_dates_json'])\n",
    "\n",
    "print(f\"\\nEntities: {len(entities)}\")\n",
    "for i, entity in enumerate(entities[:3]):  # Show first 3\n",
    "    print(f\"  {i+1}. {entity['value']} (pos: {entity['start']})\")\n",
    "\n",
    "print(f\"\\nAbsolute dates: {len(absolute_dates)}\")\n",
    "for i, date in enumerate(absolute_dates[:3]):  # Show first 3\n",
    "    print(f\"  {i+1}. {date['value']} (pos: {date['start']})\")\n",
    "\n",
    "print(f\"\\nRelative dates: {len(relative_dates)}\")\n",
    "for i, date in enumerate(relative_dates):\n",
    "    print(f\"  {i+1}. {date['value']} (pos: {date['start']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd035207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test naive extraction with absolute dates only\n",
    "print(\"=== NAIVE EXTRACTION WITH ABSOLUTE DATES ONLY ===\")\n",
    "relationships_absolute = naive_extraction(entities, absolute_dates, max_distance=400)\n",
    "print(f\"Found {len(relationships_absolute)} relationships:\")\n",
    "for rel in relationships_absolute:\n",
    "    print(f\"  {rel['entity_label']} -> {rel['date']} (distance: {rel['distance']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5271e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test naive extraction with relative dates only\n",
    "print(\"=== NAIVE EXTRACTION WITH RELATIVE DATES ONLY ===\")\n",
    "relationships_relative = naive_extraction(entities, relative_dates, max_distance=400)\n",
    "print(f\"Found {len(relationships_relative)} relationships:\")\n",
    "for rel in relationships_relative:\n",
    "    print(f\"  {rel['entity_label']} -> {rel['date']} (distance: {rel['distance']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118896bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test naive extraction with combined dates\n",
    "print(\"=== NAIVE EXTRACTION WITH COMBINED DATES ===\")\n",
    "all_dates = absolute_dates + relative_dates\n",
    "print(f\"Total dates: {len(all_dates)} (absolute: {len(absolute_dates)}, relative: {len(relative_dates)})\")\n",
    "\n",
    "relationships_combined = naive_extraction(entities, all_dates, max_distance=400)\n",
    "print(f\"Found {len(relationships_combined)} relationships:\")\n",
    "for rel in relationships_combined:\n",
    "    print(f\"  {rel['entity_label']} -> {rel['date']} (distance: {rel['distance']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbb3760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug - show all entity-date distances\n",
    "print(\"=== ENTITY-DATE DISTANCE ANALYSIS ===\")\n",
    "for entity in entities:\n",
    "    print(f\"\\nEntity: {entity['value']} (pos: {entity['start']})\")\n",
    "    print(\"Distances to dates:\")\n",
    "    \n",
    "    for date in all_dates:\n",
    "        distance = abs(entity['start'] - date['start'])\n",
    "        date_type = \"absolute\" if date in absolute_dates else \"relative\"\n",
    "        print(f\"  {date['value']} ({date_type}): distance = {distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf8aa30",
   "metadata": {},
   "source": [
    "Test Against Labelled Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b31287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training dataset using existing load_data function\n",
    "df = load_data(\"../data/training_dataset.csv\")\n",
    "\n",
    "print(f\"Main dataset: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7141c75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialize counters ---\n",
    "abs_results = []\n",
    "rel_results = []\n",
    "\n",
    "# --- Loop through each note ---\n",
    "for _, row in df.iterrows():\n",
    "    text = row['note_text']\n",
    "\n",
    "    validated_abs = row.get('dates_json', []) or []\n",
    "    validated_rel = row.get('relative_dates_json', []) or []\n",
    "\n",
    "    if isinstance(validated_rel, str):\n",
    "        try:\n",
    "            validated_rel = json.loads(validated_rel)\n",
    "        except json.JSONDecodeError:\n",
    "            validated_rel = []\n",
    "\n",
    "    # --- Normalise gold values ---\n",
    "    gold_abs_values = {clean_value(d['value']) for d in validated_abs if isinstance(d, dict) and d.get('value')}\n",
    "    gold_rel_values = {normalise_relative(d['value']) for d in validated_rel if isinstance(d, dict) and d.get('value')}\n",
    "\n",
    "    # --- Generate predictions ---\n",
    "    pred_abs = extract_absolute_dates(text)\n",
    "    pred_rel = extract_relative_dates(text)\n",
    "\n",
    "    # --- Normalise predicted values ---\n",
    "    pred_abs_values = {clean_value(p['value']) for p in pred_abs if isinstance(p, dict) and p.get('value')}\n",
    "    pred_rel_values = {normalise_relative(p['value']) for p in pred_rel if isinstance(p, dict) and p.get('value')}\n",
    "\n",
    "    # --- Compare sets using same normalisation ---\n",
    "    tp_abs = len(pred_abs_values & gold_abs_values)\n",
    "    fp_abs = len(pred_abs_values - gold_abs_values)\n",
    "    fn_abs = len(gold_abs_values - pred_abs_values)\n",
    "\n",
    "    tp_rel = len(pred_rel_values & gold_rel_values)\n",
    "    fp_rel = len(pred_rel_values - gold_rel_values)\n",
    "    fn_rel = len(gold_rel_values - pred_rel_values)\n",
    "\n",
    "    abs_results.append((tp_abs, fp_abs, fn_abs))\n",
    "    rel_results.append((tp_rel, fp_rel, fn_rel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c471ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute metrics ---\n",
    "def compute_metrics(results):\n",
    "    tp = sum(r[0] for r in results)\n",
    "    fp = sum(r[1] for r in results)\n",
    "    fn = sum(r[2] for r in results)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    return precision, recall, f1, tp, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889a7f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Print results ---\n",
    "abs_precision, abs_recall, abs_f1, tp_abs, fp_abs, fn_abs = compute_metrics(abs_results)\n",
    "rel_precision, rel_recall, rel_f1, tp_rel, fp_rel, fn_rel = compute_metrics(rel_results)\n",
    "\n",
    "print(\"=== Absolute Dates ===\")\n",
    "print(f\"TP={tp_abs}, FP={fp_abs}, FN={fn_abs}\")\n",
    "print(f\"Precision={abs_precision:.3f}, Recall={abs_recall:.3f}, F1={abs_f1:.3f}\")\n",
    "\n",
    "print(\"\\n=== Relative Dates ===\")\n",
    "print(f\"TP={tp_rel}, FP={fp_rel}, FN={fn_rel}\")\n",
    "print(f\"Precision={rel_precision:.3f}, Recall={rel_recall:.3f}, F1={rel_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6065e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Debug absolute dates (first 10 rows) ---\n",
    "for _, row in df.head(10).iterrows():\n",
    "    text = row['note_text']\n",
    "\n",
    "    abs_data = row.get('dates_json')\n",
    "    if isinstance(abs_data, str):\n",
    "        try:\n",
    "            abs_data = json.loads(abs_data)\n",
    "        except json.JSONDecodeError:\n",
    "            abs_data = []\n",
    "\n",
    "    # Extract validated and predicted values\n",
    "    gold_abs = {d['value'].strip() for d in abs_data if isinstance(d, dict) and 'value' in d}\n",
    "    pred_abs = {p['value'].strip() for p in extract_absolute_dates(text) if isinstance(p, dict) and 'value' in p}\n",
    "\n",
    "    # Only show rows where something exists\n",
    "    if gold_abs or pred_abs:\n",
    "        print(f\"\\nDoc {row.get('doc_id', 'N/A')}\")\n",
    "        print(\"Validated absolute:\", gold_abs)\n",
    "        print(\"Predicted absolute:\", pred_abs)\n",
    "        print(\"Overlap:\", gold_abs & pred_abs)\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d518dfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Debug relative date extraction ---\n",
    "for _, row in df.head(10).iterrows():\n",
    "    text = row['note_text']\n",
    "\n",
    "    # Load gold relative dates safely\n",
    "    rel_data = row.get('relative_dates_json')\n",
    "    if isinstance(rel_data, str):\n",
    "        try:\n",
    "            rel_data = json.loads(rel_data)\n",
    "        except json.JSONDecodeError:\n",
    "            rel_data = []\n",
    "    elif not isinstance(rel_data, list):\n",
    "        rel_data = []\n",
    "\n",
    "    # --- Raw and normalised sets ---\n",
    "    gold_raw = {d['value'] for d in rel_data if isinstance(d, dict) and 'value' in d}\n",
    "    pred_raw = {p['value'] for p in extract_relative_dates(text)}\n",
    "\n",
    "    gold_norm = {normalise_relative(v) for v in gold_raw}\n",
    "    pred_norm = {normalise_relative(v) for v in pred_raw}\n",
    "\n",
    "    # --- Only print docs that have something to inspect ---\n",
    "    if gold_raw or pred_raw:\n",
    "        print(f\"\\nDoc {row.get('doc_id', 'N/A')}\")\n",
    "        print(\"Validated relative (raw):\", gold_raw)\n",
    "        print(\"Predicted relative (raw):\", pred_raw)\n",
    "        print(\"Overlap (raw):\", gold_raw & pred_raw)\n",
    "        print(\"Overlap (normalised):\", gold_norm & pred_norm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
