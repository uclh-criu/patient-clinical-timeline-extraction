{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10dada8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports (unchanged)\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Add utils to path\n",
    "utils_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'utils'))\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.insert(0, utils_path)\n",
    "\n",
    "from general_utils import (\n",
    "    parse_jsonish,\n",
    "    load_data,\n",
    "    prepare_sample,\n",
    "    prepare_all_samples,\n",
    "    get_entity_date_pairs,\n",
    "    calculate_metrics\n",
    ")\n",
    "\n",
    "from bert_training_utils import create_training_pairs\n",
    "from naive_extractor_utils import naive_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d687ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "Number of documents: 119\n",
      "\n",
      "Columns present:\n",
      "- doc_id\n",
      "- note_text\n",
      "- entities_json\n",
      "- dates_json\n",
      "- relative_dates_json\n",
      "- relations_json\n",
      "\n",
      "First row contents:\n",
      "Document ID: 26342\n",
      "Text length: 5643 characters\n",
      "Number of entities: 117\n",
      "Number of dates: 27\n",
      "\n",
      "Sample entities (first 3):\n",
      "- LYMPHOCYTES (Position: 4748-4759)\n",
      "- createnine (Position: 1611-1621)\n",
      "- gliclazide (Position: 1862-1872)\n",
      "\n",
      "Sample dates (first 3):\n",
      "-  11/9/2019 (Position: 1773-1783)\n",
      "- Dec 2018 (Position: 1629-1637)\n",
      "- 10/09/2019 (Position: 4482-4492)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Test load_data\n",
    "def test_load_data():\n",
    "    \"\"\"Test loading and parsing of training dataset\"\"\"\n",
    "    df = load_data(\"../data/training_dataset.csv\")\n",
    "    \n",
    "    print(\"Dataset Overview:\")\n",
    "    print(f\"Number of documents: {len(df)}\")\n",
    "    print(\"\\nColumns present:\")\n",
    "    for col in df.columns:\n",
    "        print(f\"- {col}\")\n",
    "    \n",
    "    # Check first row\n",
    "    first_row = df.iloc[0]\n",
    "    print(\"\\nFirst row contents:\")\n",
    "    print(f\"Document ID: {first_row.get('doc_id')}\")\n",
    "    print(f\"Text length: {len(first_row['note_text'])} characters\")\n",
    "    print(f\"Number of entities: {len(first_row['entities_json'])}\")\n",
    "    print(f\"Number of dates: {len(first_row['dates_json'])}\")\n",
    "    \n",
    "    # Sample of parsed content\n",
    "    print(\"\\nSample entities (first 3):\")\n",
    "    for e in first_row['entities_json'][:3]:\n",
    "        print(f\"- {e['value']} (Position: {e['start']}-{e['end']})\")\n",
    "    \n",
    "    print(\"\\nSample dates (first 3):\")\n",
    "    for d in first_row['dates_json'][:3]:\n",
    "        print(f\"- {d['value']} (Position: {d['start']}-{d['end']})\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Run test\n",
    "df = test_load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef27e245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Preparation Results:\n",
      "\n",
      "Text length: 5643 characters\n",
      "Number of entities: 117\n",
      "Number of dates: 27\n",
      "\n",
      "First 3 entities:\n",
      "- LYMPHOCYTES (Position: 4748-4759)\n",
      "- createnine (Position: 1611-1621)\n",
      "- gliclazide (Position: 1862-1872)\n",
      "\n",
      "First 3 dates:\n",
      "-  11/9/2019 (Position: 1773-1783)\n",
      "- Dec 2018 (Position: 1629-1637)\n",
      "- 10/09/2019 (Position: 4482-4492)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Test prepare_sample\n",
    "def test_prepare_sample():\n",
    "    \"\"\"Test preparation of a single sample\"\"\"\n",
    "    # Get first row\n",
    "    row = df.iloc[0]\n",
    "    \n",
    "    # Prepare sample\n",
    "    note_text, entities_list, dates = prepare_sample(row)\n",
    "    \n",
    "    print(\"Sample Preparation Results:\")\n",
    "    print(f\"\\nText length: {len(note_text)} characters\")\n",
    "    print(f\"Number of entities: {len(entities_list)}\")\n",
    "    print(f\"Number of dates: {len(dates)}\")\n",
    "    \n",
    "    print(\"\\nFirst 3 entities:\")\n",
    "    for e in entities_list[:3]:\n",
    "        print(f\"- {e['value']} (Position: {e['start']}-{e['end']})\")\n",
    "    \n",
    "    print(\"\\nFirst 3 dates:\")\n",
    "    for d in dates[:3]:\n",
    "        print(f\"- {d['value']} (Position: {d['start']}-{d['end']})\")\n",
    "    \n",
    "    return note_text, entities_list, dates\n",
    "\n",
    "# Run test\n",
    "note_text, entities_list, dates = test_prepare_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4462d633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Samples Preparation Results:\n",
      "Number of samples prepared: 119\n",
      "\n",
      "First sample contents:\n",
      "- doc_id: 26342\n",
      "- Text length: 5643 characters\n",
      "- Number of entities: 117\n",
      "- Number of dates: 27\n",
      "- Number of relative dates: 5\n",
      "\n",
      "First 3 entities:\n",
      "- LYMPHOCYTES (Position: 4748-4759)\n",
      "- createnine (Position: 1611-1621)\n",
      "- gliclazide (Position: 1862-1872)\n",
      "\n",
      "First 3 dates:\n",
      "-  11/9/2019 (Position: 1773-1783)\n",
      "- Dec 2018 (Position: 1629-1637)\n",
      "- 10/09/2019 (Position: 4482-4492)\n",
      "\n",
      "First 3 relative dates:\n",
      "- last few month (Position: 196-210)\n",
      "-  last 3 months (Position: 317-331)\n",
      "-  start of 2018 (Position: 292-306)\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Test prepare_all_samples\n",
    "def test_prepare_all_samples():\n",
    "    \"\"\"Test preparation of all samples\"\"\"\n",
    "    samples = prepare_all_samples(df)\n",
    "    \n",
    "    print(\"All Samples Preparation Results:\")\n",
    "    print(f\"Number of samples prepared: {len(samples)}\")\n",
    "    \n",
    "    # Check first sample\n",
    "    first_sample = samples[0]\n",
    "    print(\"\\nFirst sample contents:\")\n",
    "    print(f\"- doc_id: {first_sample['doc_id']}\")\n",
    "    print(f\"- Text length: {len(first_sample['note_text'])} characters\")\n",
    "    print(f\"- Number of entities: {len(first_sample['entities_list'])}\")\n",
    "    print(f\"- Number of dates: {len(first_sample['dates'])}\")\n",
    "    print(f\"- Number of relative dates: {len(first_sample['relative_dates'])}\")\n",
    "    \n",
    "    # Print first few entities and dates\n",
    "    print(\"\\nFirst 3 entities:\")\n",
    "    for e in first_sample['entities_list'][:3]:\n",
    "        print(f\"- {e['value']} (Position: {e['start']}-{e['end']})\")\n",
    "    \n",
    "    print(\"\\nFirst 3 dates:\")\n",
    "    for d in first_sample['dates'][:3]:\n",
    "        print(f\"- {d['value']} (Position: {d['start']}-{d['end']})\")\n",
    "    \n",
    "    print(\"\\nFirst 3 relative dates:\")\n",
    "    for rd in first_sample['relative_dates'][:3]:\n",
    "        print(f\"- {rd['value']} (Position: {rd['start']}-{rd['end']})\")\n",
    "    \n",
    "    return samples\n",
    "\n",
    "# Run test\n",
    "samples = test_prepare_all_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5d8f9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity-Date Pairs Results:\n",
      "Total pairs generated: 3744\n",
      "\n",
      "First 5 pairs:\n",
      "\n",
      "Pair 1:\n",
      "Entity: LYMPHOCYTES (4748-4759)\n",
      "Date:  11/9/2019 (1773-1783)\n",
      "Distance: 2975 chars\n",
      "Date type: absolute\n",
      "\n",
      "Pair 2:\n",
      "Entity: LYMPHOCYTES (4748-4759)\n",
      "Date: Dec 2018 (1629-1637)\n",
      "Distance: 3119 chars\n",
      "Date type: absolute\n",
      "\n",
      "Pair 3:\n",
      "Entity: LYMPHOCYTES (4748-4759)\n",
      "Date: 10/09/2019 (4482-4492)\n",
      "Distance: 266 chars\n",
      "Date type: absolute\n",
      "\n",
      "Pair 4:\n",
      "Entity: LYMPHOCYTES (4748-4759)\n",
      "Date: 10/09/2019 (4508-4518)\n",
      "Distance: 240 chars\n",
      "Date type: absolute\n",
      "\n",
      "Pair 5:\n",
      "Entity: LYMPHOCYTES (4748-4759)\n",
      "Date: 10/09/2019 (4533-4543)\n",
      "Distance: 215 chars\n",
      "Date type: absolute\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Test get_entity_date_pairs\n",
    "def test_get_entity_date_pairs():\n",
    "    \"\"\"Test creation of entity-date pairs\"\"\"\n",
    "    # Get first sample\n",
    "    sample = samples[0]\n",
    "    \n",
    "    # Get pairs\n",
    "    pairs = get_entity_date_pairs(\n",
    "        sample['entities_list'],\n",
    "        sample['dates'],\n",
    "        sample['relative_dates']\n",
    "    )\n",
    "    \n",
    "    print(\"Entity-Date Pairs Results:\")\n",
    "    print(f\"Total pairs generated: {len(pairs)}\")\n",
    "    \n",
    "    print(\"\\nFirst 5 pairs:\")\n",
    "    for i, pair in enumerate(pairs[:5]):\n",
    "        print(f\"\\nPair {i+1}:\")\n",
    "        print(f\"Entity: {pair['entity_label']} ({pair['entity']['start']}-{pair['entity']['end']})\")\n",
    "        print(f\"Date: {pair['date']} ({pair['date_info']['start']}-{pair['date_info']['end']})\")\n",
    "        print(f\"Distance: {pair['distance']} chars\")\n",
    "        print(f\"Date type: {pair['date_type']}\")\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "# Run test\n",
    "pairs = test_get_entity_date_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb1b9041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative Date Analysis:\n",
      "Total relative dates: 5\n",
      "\n",
      "All relative dates:\n",
      "- last few month (Position: 196-210)\n",
      "-  last 3 months (Position: 317-331)\n",
      "-  start of 2018 (Position: 292-306)\n",
      "- 2/7 (Position: 421-424)\n",
      "- today (Position: 664-669)\n",
      "\n",
      "Pairs using relative dates: 585\n",
      "\n",
      "First 3 relative date pairs:\n",
      "\n",
      "Entity: LYMPHOCYTES (4748-4759)\n",
      "Date: last few month (196-210)\n",
      "Distance: 4552 chars\n",
      "\n",
      "Entity: LYMPHOCYTES (4748-4759)\n",
      "Date:  last 3 months (317-331)\n",
      "Distance: 4431 chars\n",
      "\n",
      "Entity: LYMPHOCYTES (4748-4759)\n",
      "Date:  start of 2018 (292-306)\n",
      "Distance: 4456 chars\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Test Relative Date Handling\n",
    "def test_relative_dates():\n",
    "    \"\"\"Test specific handling of relative dates in pairs\"\"\"\n",
    "    \n",
    "    # Get first sample\n",
    "    sample = samples[0]\n",
    "    \n",
    "    print(\"Relative Date Analysis:\")\n",
    "    print(f\"Total relative dates: {len(sample['relative_dates'])}\")\n",
    "    \n",
    "    # Show all relative dates\n",
    "    print(\"\\nAll relative dates:\")\n",
    "    for rd in sample['relative_dates']:\n",
    "        print(f\"- {rd['value']} (Position: {rd['start']}-{rd['end']})\")\n",
    "    \n",
    "    # Find pairs with relative dates\n",
    "    pairs = get_entity_date_pairs(\n",
    "        sample['entities_list'],\n",
    "        sample['dates'],\n",
    "        sample['relative_dates']\n",
    "    )\n",
    "    \n",
    "    relative_pairs = [p for p in pairs if p['date_type'] == 'relative']\n",
    "    print(f\"\\nPairs using relative dates: {len(relative_pairs)}\")\n",
    "    print(\"\\nFirst 3 relative date pairs:\")\n",
    "    for p in relative_pairs[:3]:\n",
    "        print(f\"\\nEntity: {p['entity_label']} ({p['entity']['start']}-{p['entity']['end']})\")\n",
    "        print(f\"Date: {p['date']} ({p['date_info']['start']}-{p['date_info']['end']})\")\n",
    "        print(f\"Distance: {p['distance']} chars\")\n",
    "\n",
    "# Run test\n",
    "test_relative_dates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9562fd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 9: Duplicate Relations Analysis ===\n",
      "\n",
      "Original Relations:\n",
      "Total relations in gold set: 30\n",
      "Unique entity-date pairs: 29\n",
      "\n",
      "Found duplicate relations:\n",
      "- insulin aspart biphasic -> 11/9/2019 (appears 2 times)\n",
      "\n",
      "Training Pairs Analysis:\n",
      "Total pairs created: 3744\n",
      "Positive pairs: 349\n",
      "Unique positive pairs: 29\n",
      "\n",
      "Found duplicate pairs in training data:\n",
      "- LYMPHOCYTES -> 10/09/2019 (appears 19 times)\n",
      "- insulin aspart biphasic -> 11/9/2019 (appears 8 times)\n",
      "- rosuvastatin -> 11/9/2019 (appears 4 times)\n",
      "- linagliptin -> 11/9/2019 (appears 4 times)\n",
      "- HAEMOGLOBIN -> 10/09/2019 (appears 19 times)\n",
      "- NEUTROPHILS -> 10/09/2019 (appears 19 times)\n",
      "- EOSINOPHILS -> 10/09/2019 (appears 19 times)\n",
      "- CREATININE -> 10/09/2019 (appears 19 times)\n",
      "- PLATELET -> 10/09/2019 (appears 19 times)\n",
      "- PCO2 -> 10/09/2019 (appears 19 times)\n",
      "- HCO3 -> 10/09/2019 (appears 19 times)\n",
      "- APTT -> 10/09/2019 (appears 19 times)\n",
      "- MCV -> 10/09/2019 (appears 19 times)\n",
      "- CRP -> 10/09/2019 (appears 19 times)\n",
      "- PH -> 10/09/2019 (appears 19 times)\n",
      "- PO2 -> 10/09/2019 (appears 19 times)\n",
      "- LACTATE -> 10/09/2019 (appears 19 times)\n",
      "- SODIUM -> 10/09/2019 (appears 19 times)\n",
      "- POTASSIUM -> 10/09/2019 (appears 19 times)\n",
      "- INR -> 10/09/2019 (appears 19 times)\n",
      "- NPH -> today (appears 2 times)\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Test Duplicate Relations\n",
    "def test_duplicate_relations(samples):\n",
    "    \"\"\"Investigate potential duplicate relations in training pairs\"\"\"\n",
    "    print(\"=== Test 9: Duplicate Relations Analysis ===\")\n",
    "    \n",
    "    # Get first sample\n",
    "    sample = samples[0]\n",
    "    \n",
    "    # Analyze relations\n",
    "    print(\"\\nOriginal Relations:\")\n",
    "    relations = sample['relations_json']\n",
    "    print(f\"Total relations in gold set: {len(relations)}\")\n",
    "    \n",
    "    # Check for duplicates in relations\n",
    "    entity_date_pairs = [(r['entity'], r['date']) for r in relations]\n",
    "    unique_pairs = set(entity_date_pairs)\n",
    "    print(f\"Unique entity-date pairs: {len(unique_pairs)}\")\n",
    "    \n",
    "    if len(entity_date_pairs) != len(unique_pairs):\n",
    "        print(\"\\nFound duplicate relations:\")\n",
    "        from collections import Counter\n",
    "        duplicates = Counter(entity_date_pairs)\n",
    "        for pair, count in duplicates.items():\n",
    "            if count > 1:\n",
    "                print(f\"- {pair[0]} -> {pair[1]} (appears {count} times)\")\n",
    "    \n",
    "    # Create training pairs and analyze\n",
    "    df = create_training_pairs([sample])\n",
    "    positive_pairs = df[df['label'] == 1]\n",
    "    \n",
    "    print(\"\\nTraining Pairs Analysis:\")\n",
    "    print(f\"Total pairs created: {len(df)}\")\n",
    "    print(f\"Positive pairs: {len(positive_pairs)}\")\n",
    "    \n",
    "    # Check if same entity-date pair appears multiple times\n",
    "    pair_texts = [(row['marked_text'].split('[E1]')[1].split('[/E1]')[0].strip(),\n",
    "                  row['marked_text'].split('[E2]')[1].split('[/E2]')[0].strip())\n",
    "                  for _, row in positive_pairs.iterrows()]\n",
    "    unique_pair_texts = set(pair_texts)\n",
    "    \n",
    "    print(f\"Unique positive pairs: {len(unique_pair_texts)}\")\n",
    "    \n",
    "    if len(pair_texts) != len(unique_pair_texts):\n",
    "        print(\"\\nFound duplicate pairs in training data:\")\n",
    "        duplicates = Counter(pair_texts)\n",
    "        for pair, count in duplicates.items():\n",
    "            if count > 1:\n",
    "                print(f\"- {pair[0]} -> {pair[1]} (appears {count} times)\")\n",
    "\n",
    "# Run test\n",
    "test_duplicate_relations(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9684020e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Text Length and Distance Analysis ===\n",
      "\n",
      "Document Length Analysis:\n",
      "Document length: 5643 characters\n",
      "Average words per document: 858 words\n",
      "\n",
      "Distance Analysis for Relations:\n",
      "\n",
      "All Relations:\n",
      "Total relations: 30\n",
      "Mean distance: 17.8 chars\n",
      "Min distance: 8 chars\n",
      "Max distance: 60 chars\n",
      "\n",
      "Absolute Date Relations:\n",
      "Total relations: 23\n",
      "Mean distance: 12.9 chars\n",
      "Min distance: 8 chars\n",
      "Max distance: 21 chars\n",
      "\n",
      "Relative Date Relations:\n",
      "Total relations: 7\n",
      "Mean distance: 33.9 chars\n",
      "Min distance: 8 chars\n",
      "Max distance: 60 chars\n",
      "\n",
      "Example Relations:\n",
      "\n",
      "Closest Pair:\n",
      "Distance: 8 chars\n",
      "Entity: CT scan (Position: 656-663)\n",
      "Date: today (Position: 664-669)\n",
      "\n",
      "Furthest Pair:\n",
      "Distance: 60 chars\n",
      "Entity: ventriculomegaly (Position: 724-740)\n",
      "Date: today (Position: 664-669)\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Test Token Length and Distance Analysis\n",
    "def test_text_lengths_and_distances():\n",
    "    \"\"\"Analyze document lengths and distances between entities/dates\"\"\"\n",
    "    print(\"=== Text Length and Distance Analysis ===\")\n",
    "    \n",
    "    # Get first sample\n",
    "    sample = samples[0]\n",
    "    \n",
    "    # 1. Document Length Analysis\n",
    "    print(\"\\nDocument Length Analysis:\")\n",
    "    text_length = len(sample['note_text'])\n",
    "    print(f\"Document length: {text_length} characters\")\n",
    "    print(f\"Average words per document: {len(sample['note_text'].split())} words\")\n",
    "    \n",
    "    # 2. Distance Analysis for Relations\n",
    "    print(\"\\nDistance Analysis for Relations:\")\n",
    "    \n",
    "    # Analyze all relations\n",
    "    distances = []\n",
    "    abs_distances = []\n",
    "    rel_distances = []\n",
    "    \n",
    "    for relation in sample['relations_json']:\n",
    "        # Find corresponding entity and date objects\n",
    "        entity = next((e for e in sample['entities_list'] if str(e['id']) == str(relation['entity_id'])), None)\n",
    "        date = next((d for d in sample['dates'] if str(d['id']) == str(relation['date_id'])), None)\n",
    "        rel_date = next((rd for rd in sample['relative_dates'] if str(rd['id']) == str(relation['date_id'])), None)\n",
    "        \n",
    "        if entity:\n",
    "            if date:\n",
    "                distance = abs(entity['start'] - date['start'])\n",
    "                distances.append(distance)\n",
    "                abs_distances.append(distance)\n",
    "            elif rel_date:\n",
    "                distance = abs(entity['start'] - rel_date['start'])\n",
    "                distances.append(distance)\n",
    "                rel_distances.append(distance)\n",
    "    \n",
    "    print(\"\\nAll Relations:\")\n",
    "    print(f\"Total relations: {len(distances)}\")\n",
    "    if distances:\n",
    "        print(f\"Mean distance: {sum(distances)/len(distances):.1f} chars\")\n",
    "        print(f\"Min distance: {min(distances)} chars\")\n",
    "        print(f\"Max distance: {max(distances)} chars\")\n",
    "    \n",
    "    print(\"\\nAbsolute Date Relations:\")\n",
    "    print(f\"Total relations: {len(abs_distances)}\")\n",
    "    if abs_distances:\n",
    "        print(f\"Mean distance: {sum(abs_distances)/len(abs_distances):.1f} chars\")\n",
    "        print(f\"Min distance: {min(abs_distances)} chars\")\n",
    "        print(f\"Max distance: {max(abs_distances)} chars\")\n",
    "    \n",
    "    print(\"\\nRelative Date Relations:\")\n",
    "    print(f\"Total relations: {len(rel_distances)}\")\n",
    "    if rel_distances:\n",
    "        print(f\"Mean distance: {sum(rel_distances)/len(rel_distances):.1f} chars\")\n",
    "        print(f\"Min distance: {min(rel_distances)} chars\")\n",
    "        print(f\"Max distance: {max(rel_distances)} chars\")\n",
    "    \n",
    "    # Show examples of closest and furthest pairs\n",
    "    if distances:\n",
    "        print(\"\\nExample Relations:\")\n",
    "        closest_idx = distances.index(min(distances))\n",
    "        furthest_idx = distances.index(max(distances))\n",
    "        \n",
    "        # Get relation objects\n",
    "        closest_relation = sample['relations_json'][closest_idx]\n",
    "        furthest_relation = sample['relations_json'][furthest_idx]\n",
    "        \n",
    "        # Find entities and dates for these relations\n",
    "        for relation, distance_type in [(closest_relation, \"Closest\"), (furthest_relation, \"Furthest\")]:\n",
    "            entity = next((e for e in sample['entities_list'] if str(e['id']) == str(relation['entity_id'])), None)\n",
    "            date = next((d for d in sample['dates'] if str(d['id']) == str(relation['date_id'])), None)\n",
    "            rel_date = next((rd for rd in sample['relative_dates'] if str(rd['id']) == str(relation['date_id'])), None)\n",
    "            \n",
    "            if entity and (date or rel_date):\n",
    "                date_obj = date if date else rel_date\n",
    "                distance = abs(entity['start'] - date_obj['start'])\n",
    "                print(f\"\\n{distance_type} Pair:\")\n",
    "                print(f\"Distance: {distance} chars\")\n",
    "                print(f\"Entity: {entity['value']} (Position: {entity['start']}-{entity['end']})\")\n",
    "                print(f\"Date: {date_obj['value']} (Position: {date_obj['start']}-{date_obj['end']})\")\n",
    "                \n",
    "test_text_lengths_and_distances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e2d485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 10: Metrics Calculation Analysis ===\n",
      "\n",
      "Position-based Training Pairs:\n",
      "Total pairs: 3744\n",
      "Positive pairs: 349\n",
      "Negative pairs: 3395\n",
      "\n",
      "Unique Entity-Date Pairs:\n",
      "Total unique pairs: 931\n",
      "Unique positive pairs: 29\n",
      "Unique negative pairs: 902\n",
      "\n",
      "Example of position variations for same pair:\n",
      "\n",
      "Positions for pair 'rosuvastatin -> 11/9/2019':\n",
      "- Entity at (3258, 3270), Date at (2561, 2570), Distance: 697 chars\n",
      "- Entity at (3258, 3270), Date at (2735, 2744), Distance: 523 chars\n",
      "- Entity at (3258, 3270), Date at (3150, 3159), Distance: 108 chars\n",
      "- Entity at (3258, 3270), Date at (3247, 3256), Distance: 11 chars\n",
      "\n",
      "Metrics Calculation:\n",
      "\n",
      "Metrics when using all position-based pairs:\n",
      "Precision: 0.897\n",
      "Recall: 0.897\n",
      "F1: 0.897\n",
      "True Positives: 26\n",
      "False Positives: 3\n",
      "False Negatives: 3\n",
      "\n",
      "Metrics when using unique pairs:\n",
      "Precision: 0.897\n",
      "Recall: 0.897\n",
      "F1: 0.897\n",
      "True Positives: 26\n",
      "False Positives: 3\n",
      "False Negatives: 3\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Test Metrics Calculation\n",
    "def test_metrics_calculation(samples):\n",
    "    \"\"\"Compare metrics calculation with position-based vs unique pairs\"\"\"\n",
    "    print(\"=== Test 10: Metrics Calculation Analysis ===\")\n",
    "    \n",
    "    # Get first sample\n",
    "    sample = samples[0]\n",
    "    \n",
    "    # Create training pairs (position-based)\n",
    "    df = create_training_pairs([sample])\n",
    "    \n",
    "    # Analyze position-based predictions\n",
    "    print(\"\\nPosition-based Training Pairs:\")\n",
    "    print(f\"Total pairs: {len(df)}\")\n",
    "    print(f\"Positive pairs: {len(df[df['label'] == 1])}\")\n",
    "    print(f\"Negative pairs: {len(df[df['label'] == 0])}\")\n",
    "    \n",
    "    # Convert to unique entity-date pairs\n",
    "    unique_pairs = set()\n",
    "    unique_positive_pairs = set()\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            # Find all marker positions\n",
    "            e1_start = row['marked_text'].find('[E1]')\n",
    "            e1_end = row['marked_text'].find('[/E1]')\n",
    "            e2_start = row['marked_text'].find('[E2]')\n",
    "            e2_end = row['marked_text'].find('[/E2]')\n",
    "            \n",
    "            # Only process if all markers are found\n",
    "            if all(pos != -1 for pos in [e1_start, e1_end, e2_start, e2_end]):\n",
    "                entity = row['marked_text'][e1_start+4:e1_end].strip()\n",
    "                date = row['marked_text'][e2_start+4:e2_end].strip()\n",
    "                pair = (entity, date)\n",
    "                unique_pairs.add(pair)\n",
    "                if row['label'] == 1:\n",
    "                    unique_positive_pairs.add(pair)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not process row due to {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\nUnique Entity-Date Pairs:\")\n",
    "    print(f\"Total unique pairs: {len(unique_pairs)}\")\n",
    "    print(f\"Unique positive pairs: {len(unique_positive_pairs)}\")\n",
    "    print(f\"Unique negative pairs: {len(unique_pairs) - len(unique_positive_pairs)}\")\n",
    "    \n",
    "    # Show example of how same pair appears in different positions\n",
    "    if unique_positive_pairs:\n",
    "        print(\"\\nExample of position variations for same pair:\")\n",
    "        example_pair = next(iter(unique_positive_pairs))\n",
    "        positions = []\n",
    "        for _, row in df[df['label'] == 1].iterrows():\n",
    "            try:\n",
    "                entity = row['marked_text'][row['marked_text'].find('[E1]')+4:row['marked_text'].find('[/E1]')].strip()\n",
    "                date = row['marked_text'][row['marked_text'].find('[E2]')+4:row['marked_text'].find('[/E2]')].strip()\n",
    "                if (entity, date) == example_pair:\n",
    "                    positions.append({\n",
    "                        'entity_pos': (row['ent1_start'], row['ent1_end']),\n",
    "                        'date_pos': (row['ent2_start'], row['ent2_end']),\n",
    "                        'distance': row['distance']\n",
    "                    })\n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        print(f\"\\nPositions for pair '{example_pair[0]} -> {example_pair[1]}':\")\n",
    "        for pos in positions:\n",
    "            print(f\"- Entity at {pos['entity_pos']}, Date at {pos['date_pos']}, Distance: {pos['distance']} chars\")\n",
    "    \n",
    "    print(\"\\nMetrics Calculation:\")\n",
    "    \n",
    "    # Position-based predictions\n",
    "    position_predictions = [\n",
    "        {'entity_label': row['marked_text'][row['marked_text'].find('[E1]')+4:row['marked_text'].find('[/E1]')].strip(),\n",
    "         'date': row['marked_text'][row['marked_text'].find('[E2]')+4:row['marked_text'].find('[/E2]')].strip()}\n",
    "        for _, row in df[df['label'] == 1].iterrows()\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nMetrics when using all position-based pairs:\")\n",
    "    metrics = calculate_metrics(position_predictions, pd.DataFrame([sample]))\n",
    "    print(f\"Precision: {metrics['precision']:.3f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.3f}\")\n",
    "    print(f\"F1: {metrics['f1']:.3f}\")\n",
    "    print(f\"True Positives: {metrics['tp']}\")\n",
    "    print(f\"False Positives: {metrics['fp']}\")\n",
    "    print(f\"False Negatives: {metrics['fn']}\")\n",
    "    \n",
    "    # Unique pair predictions\n",
    "    unique_predictions = [\n",
    "        {'entity_label': entity, 'date': date}\n",
    "        for entity, date in unique_positive_pairs\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nMetrics when using unique pairs:\")\n",
    "    metrics = calculate_metrics(unique_predictions, pd.DataFrame([sample]))\n",
    "    print(f\"Precision: {metrics['precision']:.3f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.3f}\")\n",
    "    print(f\"F1: {metrics['f1']:.3f}\")\n",
    "    print(f\"True Positives: {metrics['tp']}\")\n",
    "    print(f\"False Positives: {metrics['fp']}\")\n",
    "    print(f\"False Negatives: {metrics['fn']}\")\n",
    "\n",
    "# Run test\n",
    "test_metrics_calculation(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfe47578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset Statistics Comparison ===\n",
      "\n",
      "=== Single Document Analysis ===\n",
      "\n",
      "1. Create Training Dataset Approach:\n",
      "Number of entities: 117\n",
      "Number of absolute dates: 27\n",
      "Number of relative dates: 5\n",
      "Total possible unique pairs: 3744\n",
      "Number of actual relations: 30\n",
      "Percentage positive class: 0.80%\n",
      "\n",
      "2. BERT Training Approach:\n",
      "\n",
      "Position-based pairs:\n",
      "Total pairs: 3744\n",
      "Positive pairs: 349\n",
      "Negative pairs: 3395\n",
      "Percentage positive: 9.32%\n",
      "\n",
      "Unique pairs:\n",
      "Total unique pairs: 931\n",
      "Unique positive pairs: 29\n",
      "Unique negative pairs: 902\n",
      "Percentage positive: 3.11%\n",
      "\n",
      "3. Naive Approach:\n",
      "Total pairs predicted: 39\n",
      "Total possible pairs: 3744\n",
      "\n",
      "4. RelCAT Approach:\n",
      "Total possible pairs: 3744\n",
      "\n",
      "5. LLM Approach:\n",
      "\n",
      "Binary method:\n",
      "Total pairs to evaluate: 3744\n",
      "Total possible pairs: 3744\n",
      "\n",
      "Multi method:\n",
      "Total possible pairs: 3744\n",
      "\n",
      "=== Full Dataset Analysis ===\n",
      "\n",
      "1. Create Training Dataset Approach:\n",
      "Total entities across all documents: 4944\n",
      "Total absolute dates: 620\n",
      "Total relative dates: 342\n",
      "Total possible pairs: 47219\n",
      "Total relations: 777\n",
      "Percentage positive class: 1.65%\n",
      "\n",
      "2. BERT Training Approach:\n",
      "\n",
      "Position-based pairs:\n",
      "Total pairs: 47219\n",
      "Positive pairs: 1838\n",
      "Negative pairs: 45381\n",
      "Percentage positive: 3.89%\n",
      "\n",
      "Unique pairs:\n",
      "Total unique pairs: 25466\n",
      "Unique positive pairs: 606\n",
      "Unique negative pairs: 24860\n",
      "Percentage positive: 2.38%\n",
      "\n",
      "3. Naive Approach:\n",
      "Total pairs predicted: 1211\n",
      "Total possible pairs: 47219\n",
      "\n",
      "4. RelCAT Approach:\n",
      "Total possible pairs: 47219\n",
      "\n",
      "5. LLM Approach:\n",
      "\n",
      "Binary method:\n",
      "Total pairs to evaluate: 47219\n",
      "Total possible pairs: 47219\n",
      "\n",
      "Multi method:\n",
      "Total possible pairs: 47219\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Test Dataset Statistics\n",
    "def test_dataset_statistics(samples):\n",
    "    \"\"\"Compare dataset statistics across different approaches\"\"\"\n",
    "    print(\"=== Dataset Statistics Comparison ===\")\n",
    "    \n",
    "    print(\"\\n=== Single Document Analysis ===\")\n",
    "    sample = samples[0]\n",
    "    \n",
    "    print(\"\\n1. Create Training Dataset Approach:\")\n",
    "    n_entities = len(sample['entities_list'])\n",
    "    n_abs_dates = len(sample['dates'])\n",
    "    n_rel_dates = len(sample['relative_dates'])\n",
    "    n_relations = len(sample['relations_json'])\n",
    "    total_possible = n_entities * (n_abs_dates + n_rel_dates)\n",
    "    \n",
    "    print(f\"Number of entities: {n_entities}\")\n",
    "    print(f\"Number of absolute dates: {n_abs_dates}\")\n",
    "    print(f\"Number of relative dates: {n_rel_dates}\")\n",
    "    print(f\"Total possible unique pairs: {total_possible}\")\n",
    "    print(f\"Number of actual relations: {n_relations}\")\n",
    "    print(f\"Percentage positive class: {(n_relations / total_possible) * 100:.2f}%\")\n",
    "    \n",
    "    print(\"\\n2. BERT Training Approach:\")\n",
    "    df = create_training_pairs([sample])\n",
    "    \n",
    "    print(\"\\nPosition-based pairs:\")\n",
    "    print(f\"Total pairs: {len(df)}\")\n",
    "    print(f\"Positive pairs: {len(df[df['label'] == 1])}\")\n",
    "    print(f\"Negative pairs: {len(df[df['label'] == 0])}\")\n",
    "    print(f\"Percentage positive: {(len(df[df['label'] == 1]) / len(df) * 100):.2f}%\")\n",
    "    \n",
    "    unique_pairs = set()\n",
    "    unique_positive_pairs = set()\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            e1_start = row['marked_text'].find('[E1]')\n",
    "            e1_end = row['marked_text'].find('[/E1]')\n",
    "            e2_start = row['marked_text'].find('[E2]')\n",
    "            e2_end = row['marked_text'].find('[/E2]')\n",
    "            \n",
    "            if all(pos != -1 for pos in [e1_start, e1_end, e2_start, e2_end]):\n",
    "                entity = row['marked_text'][e1_start+4:e1_end].strip()\n",
    "                date = row['marked_text'][e2_start+4:e2_end].strip()\n",
    "                pair = (entity, date)\n",
    "                unique_pairs.add(pair)\n",
    "                if row['label'] == 1:\n",
    "                    unique_positive_pairs.add(pair)\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    print(\"\\nUnique pairs:\")\n",
    "    print(f\"Total unique pairs: {len(unique_pairs)}\")\n",
    "    print(f\"Unique positive pairs: {len(unique_positive_pairs)}\")\n",
    "    print(f\"Unique negative pairs: {len(unique_pairs) - len(unique_positive_pairs)}\")\n",
    "    print(f\"Percentage positive: {(len(unique_positive_pairs) / len(unique_pairs) * 100):.2f}%\")\n",
    "    \n",
    "    print(\"\\n3. Naive Approach:\")\n",
    "    all_dates = sample['dates'] + sample['relative_dates']\n",
    "    naive_pairs = naive_extraction(sample['entities_list'], all_dates, max_distance=25)\n",
    "    print(f\"Total pairs predicted: {len(naive_pairs)}\")\n",
    "    print(f\"Total possible pairs: {len(sample['entities_list']) * len(all_dates)}\")\n",
    "    \n",
    "    print(\"\\n4. RelCAT Approach:\")\n",
    "    relcat_total = n_entities * (n_abs_dates + n_rel_dates)\n",
    "    print(f\"Total possible pairs: {relcat_total}\")\n",
    "    \n",
    "    print(\"\\n5. LLM Approach:\")\n",
    "    print(\"\\nBinary method:\")\n",
    "    pairs = get_entity_date_pairs(sample['entities_list'], sample['dates'], sample['relative_dates'])\n",
    "    print(f\"Total pairs to evaluate: {len(pairs)}\")\n",
    "    print(f\"Total possible pairs: {n_entities * (n_abs_dates + n_rel_dates)}\")\n",
    "    \n",
    "    print(\"\\nMulti method:\")\n",
    "    print(f\"Total possible pairs: {n_entities * (n_abs_dates + n_rel_dates)}\")\n",
    "    \n",
    "    print(\"\\n=== Full Dataset Analysis ===\")\n",
    "    \n",
    "    print(\"\\n1. Create Training Dataset Approach:\")\n",
    "    total_entities = sum(len(s['entities_list']) for s in samples)\n",
    "    total_abs_dates = sum(len(s['dates']) for s in samples)\n",
    "    total_rel_dates = sum(len(s['relative_dates']) for s in samples)\n",
    "    total_relations = sum(len(s['relations_json']) for s in samples)\n",
    "    total_possible_pairs = sum(len(s['entities_list']) * (len(s['dates']) + len(s['relative_dates'])) for s in samples)\n",
    "    \n",
    "    print(f\"Total entities across all documents: {total_entities}\")\n",
    "    print(f\"Total absolute dates: {total_abs_dates}\")\n",
    "    print(f\"Total relative dates: {total_rel_dates}\")\n",
    "    print(f\"Total possible pairs: {total_possible_pairs}\")\n",
    "    print(f\"Total relations: {total_relations}\")\n",
    "    print(f\"Percentage positive class: {(total_relations / total_possible_pairs) * 100:.2f}%\")\n",
    "    \n",
    "    print(\"\\n2. BERT Training Approach:\")\n",
    "    df_full = create_training_pairs(samples)\n",
    "    \n",
    "    print(\"\\nPosition-based pairs:\")\n",
    "    print(f\"Total pairs: {len(df_full)}\")\n",
    "    print(f\"Positive pairs: {len(df_full[df_full['label'] == 1])}\")\n",
    "    print(f\"Negative pairs: {len(df_full[df_full['label'] == 0])}\")\n",
    "    print(f\"Percentage positive: {(len(df_full[df_full['label'] == 1]) / len(df_full) * 100):.2f}%\")\n",
    "    \n",
    "    unique_pairs_full = set()\n",
    "    unique_positive_pairs_full = set()\n",
    "    for _, row in df_full.iterrows():\n",
    "        try:\n",
    "            e1_start = row['marked_text'].find('[E1]')\n",
    "            e1_end = row['marked_text'].find('[/E1]')\n",
    "            e2_start = row['marked_text'].find('[E2]')\n",
    "            e2_end = row['marked_text'].find('[/E2]')\n",
    "            \n",
    "            if all(pos != -1 for pos in [e1_start, e1_end, e2_start, e2_end]):\n",
    "                entity = row['marked_text'][e1_start+4:e1_end].strip()\n",
    "                date = row['marked_text'][e2_start+4:e2_end].strip()\n",
    "                pair = (entity, date)\n",
    "                unique_pairs_full.add(pair)\n",
    "                if row['label'] == 1:\n",
    "                    unique_positive_pairs_full.add(pair)\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    print(\"\\nUnique pairs:\")\n",
    "    print(f\"Total unique pairs: {len(unique_pairs_full)}\")\n",
    "    print(f\"Unique positive pairs: {len(unique_positive_pairs_full)}\")\n",
    "    print(f\"Unique negative pairs: {len(unique_pairs_full) - len(unique_positive_pairs_full)}\")\n",
    "    print(f\"Percentage positive: {(len(unique_positive_pairs_full) / len(unique_pairs_full) * 100):.2f}%\")\n",
    "    \n",
    "    print(\"\\n3. Naive Approach:\")\n",
    "    naive_pairs_full = []\n",
    "    for s in samples:\n",
    "        all_dates = s['dates'] + s['relative_dates']\n",
    "        pairs = naive_extraction(s['entities_list'], all_dates, max_distance=25)\n",
    "        naive_pairs_full.extend(pairs)\n",
    "    print(f\"Total pairs predicted: {len(naive_pairs_full)}\")\n",
    "    print(f\"Total possible pairs: {total_possible_pairs}\")\n",
    "    \n",
    "    print(\"\\n4. RelCAT Approach:\")\n",
    "    relcat_total = total_possible_pairs\n",
    "    print(f\"Total possible pairs: {relcat_total}\")\n",
    "    \n",
    "    print(\"\\n5. LLM Approach:\")\n",
    "    print(\"\\nBinary method:\")\n",
    "    llm_pairs_full = []\n",
    "    for s in samples:\n",
    "        pairs = get_entity_date_pairs(s['entities_list'], s['dates'], s['relative_dates'])\n",
    "        llm_pairs_full.extend(pairs)\n",
    "    print(f\"Total pairs to evaluate: {len(llm_pairs_full)}\")\n",
    "    print(f\"Total possible pairs: {total_possible_pairs}\")\n",
    "    \n",
    "    print(\"\\nMulti method:\")\n",
    "    print(f\"Total possible pairs: {total_possible_pairs}\")\n",
    "\n",
    "# Run test\n",
    "test_dataset_statistics(samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
