{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb4652a",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02c805a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "from openai import OpenAI\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "utils_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'utils'))\n",
    "\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.insert(0, utils_path)\n",
    "\n",
    "from general_utils import load_data, prepare_all_samples, get_entity_date_pairs\n",
    "\n",
    "from llm_extractor_utils import (\n",
    "    make_binary_prompt, \n",
    "    llm_extraction_binary_hf,\n",
    "    llm_extraction_binary_openai,\n",
    "    parse_llm_answer,\n",
    "    make_multi_prompt,\n",
    "    llm_extraction_multi_openai,\n",
    "    llm_extraction_multi_hf,\n",
    "    llm_extraction_multi_structured_openai,\n",
    "    llm_extraction_multi_structured_hf,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e368136f",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b69680b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 101 records\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = load_data(\"../data/inference_dataset.csv\")\n",
    "print(f\"Loaded {len(df)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94d08fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>note_text</th>\n",
       "      <th>entities_json</th>\n",
       "      <th>dates_json</th>\n",
       "      <th>relative_dates_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "      <td>[{'id': 'ent_1', 'value': 'Ultrasound', 'cui':...</td>\n",
       "      <td>[{'id': 'abs_1', 'value': '30nd Jun 2024', 'st...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Labs (27th Sep 2024): anemia. resolving  Skin:...</td>\n",
       "      <td>[{'id': 'ent_1', 'value': 'anemia', 'cui': 'C0...</td>\n",
       "      <td>[{'id': 'abs_1', 'value': '27th Sep 2024', 'st...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>URGENT REVIEW (2024-10-04): cough. suspect ost...</td>\n",
       "      <td>[{'id': 'ent_1', 'value': 'REVIEW', 'cui': 'C1...</td>\n",
       "      <td>[{'id': 'abs_1', 'value': '2024-10-04', 'start...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>URGENT REVIEW (13rd Feb 2025) MRI of the brain...</td>\n",
       "      <td>[{'id': 'ent_1', 'value': 'REVIEW', 'cui': 'C0...</td>\n",
       "      <td>[{'id': 'abs_1', 'value': '13rd Feb 2025', 'st...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>New pt((18/11/24)): pt presents with nausea/vo...</td>\n",
       "      <td>[{'id': 'ent_1', 'value': 'nausea', 'cui': 'C0...</td>\n",
       "      <td>[{'id': 'abs_1', 'value': '18/11/24', 'start':...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                          note_text  \\\n",
       "0       0  Ultrasound (30nd Jun 2024): no significant fin...   \n",
       "1       1  Labs (27th Sep 2024): anemia. resolving  Skin:...   \n",
       "2       2  URGENT REVIEW (2024-10-04): cough. suspect ost...   \n",
       "3       3  URGENT REVIEW (13rd Feb 2025) MRI of the brain...   \n",
       "4       4  New pt((18/11/24)): pt presents with nausea/vo...   \n",
       "\n",
       "                                       entities_json  \\\n",
       "0  [{'id': 'ent_1', 'value': 'Ultrasound', 'cui':...   \n",
       "1  [{'id': 'ent_1', 'value': 'anemia', 'cui': 'C0...   \n",
       "2  [{'id': 'ent_1', 'value': 'REVIEW', 'cui': 'C1...   \n",
       "3  [{'id': 'ent_1', 'value': 'REVIEW', 'cui': 'C0...   \n",
       "4  [{'id': 'ent_1', 'value': 'nausea', 'cui': 'C0...   \n",
       "\n",
       "                                          dates_json relative_dates_json  \n",
       "0  [{'id': 'abs_1', 'value': '30nd Jun 2024', 'st...                  []  \n",
       "1  [{'id': 'abs_1', 'value': '27th Sep 2024', 'st...                  []  \n",
       "2  [{'id': 'abs_1', 'value': '2024-10-04', 'start...                  []  \n",
       "3  [{'id': 'abs_1', 'value': '13rd Feb 2025', 'st...                  []  \n",
       "4  [{'id': 'abs_1', 'value': '18/11/24', 'start':...                  []  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspect df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0fc9f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 101 samples\n"
     ]
    }
   ],
   "source": [
    "# Prepare all samples\n",
    "samples = prepare_all_samples(df)\n",
    "print(f\"Prepared {len(samples)} samples\")\n",
    "#samples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc438d4a",
   "metadata": {},
   "source": [
    "LLM Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d2d4177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose whether to use HuggingFace 'hf' or OpenAI 'openai'\n",
    "#Note if choosing OpenAI need to set OPENAI_API_KEY in .env file\n",
    "provider = 'openai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c696e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose whether to do binary prediction 'binary', multi-prediction 'multi', or multi-structured prediction 'multi_structured'\n",
    "#Binary prediction is where the LLM is passed every possible entity-date pair and asked to predict whether they are related (Yes or No). This requires a lot more LLM calls so can be expensive if using the OpenAI API\n",
    "#Multi prediction is where the LLM is passed each note in turn and asked to extract all correct relations in one go as a json\n",
    "#Multi-structured is the same as multi but using structured outputs\n",
    "method = 'multi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02166ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To see a list of available OpenAI API models\n",
    "#Alternatively visit https://platform.openai.com/docs/models\n",
    "\n",
    "#client = OpenAI(api_key = os.getenv('OPENAI_API_KEY'))\n",
    "#models = client.models.list()\n",
    "#for model in models:\n",
    "    #print(model.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76809e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To see a list of available HuggingFace text generation models\n",
    "#Alternatively visit https://huggingface.co/models?pipeline_tag=text-generation\n",
    "\n",
    "#Uncomment the below code to see the full list. Note this list is long and can take a couple of mins to run\n",
    "#api = HfApi()\n",
    "#text_gen_models = api.list_models(filter=\"text-generation\")\n",
    "#for model_info in text_gen_models:\n",
    "    #print(model_info.modelId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb3c078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LLM to use - this should be the model id from OpenAI or HuggingFace\n",
    "model = 'gpt-3.5-turbo'\n",
    "\n",
    "#Examples of OpenAI models\n",
    "#model = 'gpt-3.5-turbo' #cheap option for binary method\n",
    "#model = 'o4-mini'\n",
    "#model = 'gpt-5-mini' #best reasoning option\n",
    "\n",
    "#Examples of HF models\n",
    "#model = 'gpt2'\n",
    "#model = 'google/gemma-3-270m'\n",
    "#model= 'Qwen/Qwen3-0.6B'\n",
    "#model= 'roneneldan/TinyStories-1M' #fast option even on CPU, good for binary method\n",
    "#model = 'EleutherAI/gpt-neo-125m'\n",
    "#model = 'microsoft/phi-1_5'\n",
    "#model = 'TinyLlama/TinyLlama-1.1B-chat-v1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81853642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define generator if using HF option\n",
    "if provider == 'hf':\n",
    "    if method == 'multi_structured':\n",
    "        generator = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=model,\n",
    "            device=-1, #-1 for CPU, 0 for GPU\n",
    "            trust_remote_code=True,  # Needed for Qwen models\n",
    "            model_kwargs={\"chat_format\": \"chatml\"}  # For chat completion format\n",
    "        )\n",
    "    else:\n",
    "        # Regular text generation for non-structured methods\n",
    "        generator = pipeline(\"text-generation\", model=model, device=-1) #-1 for CPU, 0 for GPU\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "462d4d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt to use\n",
    "if method == 'binary':\n",
    "    prompt_to_use = 'binary_prompt.txt'\n",
    "elif method == 'multi':\n",
    "    prompt_to_use = 'multi_prompt.txt'\n",
    "elif method == 'multi_structured':\n",
    "    prompt_to_use = 'multi_prompt_structured.txt'       \n",
    "else:\n",
    "    raise ValueError(f\"Invalid method: {method}. Must be either 'binary', 'multi' or 'multi-structured'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7906c3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing notes:   7%|â–‹         | 7/101 [00:29<06:36,  4.22s/it]"
     ]
    }
   ],
   "source": [
    "#Process samples, make prompt, do llm extraction and make predictions\n",
    "predictions = []\n",
    "\n",
    "if method == 'binary':\n",
    "    for sample in samples:\n",
    "        \n",
    "        # Get absolute date pairs\n",
    "        absolute_pairs = get_entity_date_pairs(sample['entities_list'], sample['dates'])\n",
    "        \n",
    "        # Get relative date pairs if available\n",
    "        if sample.get('relative_dates') and len(sample['relative_dates']) > 0:\n",
    "            relative_pairs = get_entity_date_pairs(sample['entities_list'], [], sample['relative_dates'])\n",
    "            pairs = absolute_pairs + relative_pairs\n",
    "        else:\n",
    "            pairs = absolute_pairs\n",
    "        \n",
    "        for pair in tqdm(pairs, desc=\"Pairs\"):\n",
    "            #Create binary prompt\n",
    "            prompt = make_binary_prompt(pair['entity'], pair['date_info'], sample['note_text'], prompt_to_use)\n",
    "            \n",
    "            #Get response based on the method chosen\n",
    "            if provider == 'openai':\n",
    "                response = llm_extraction_binary_openai(prompt, model=model)\n",
    "            elif provider == 'hf':\n",
    "                response = llm_extraction_binary_hf(prompt, generator)\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid provider: {provider}. Must be either 'openai' or 'hf'.\")\n",
    "            \n",
    "            #Parse response into binary prediction\n",
    "            pred, conf = parse_llm_answer(response)\n",
    "            if pred == 1:\n",
    "                predictions.append({\n",
    "                    'entity_label': pair['entity_label'],\n",
    "                    'date': pair['date'],\n",
    "                    'confidence': conf\n",
    "                })\n",
    "\n",
    "elif method in ['multi', 'multi_structured']:\n",
    "    for sample in tqdm(samples, desc=\"Processing notes\"):\n",
    "        \n",
    "        # Create multi-extraction prompt\n",
    "        prompt = make_multi_prompt(\n",
    "            note_text=sample['note_text'],\n",
    "            prompt_filename=prompt_to_use,\n",
    "            entities_list=sample['entities_list'],  # optional - does not need to be passed\n",
    "            dates=sample['dates']  # optional - does not need to be passed\n",
    "        )\n",
    "        \n",
    "        # Get all relationships in one call\n",
    "        if method == 'multi':\n",
    "            if provider == 'openai':\n",
    "                relationships = llm_extraction_multi_openai(prompt, model=model)\n",
    "            elif provider == 'hf':\n",
    "                relationships = llm_extraction_multi_hf(prompt, generator)\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid provider: {provider}. Must be either 'openai' or 'hf'.\")\n",
    "        \n",
    "        elif method == 'multi_structured':\n",
    "            if provider == 'openai':\n",
    "                relationships = llm_extraction_multi_structured_openai(prompt, model=model)\n",
    "            elif provider == 'hf':\n",
    "                relationships = llm_extraction_multi_structured_hf(prompt, generator)  # To be implemented\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid provider: {provider}. Must be either 'openai' or 'hf'.\")\n",
    "        \n",
    "        # Add to predictions\n",
    "        predictions.extend(relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51463dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at prediction\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
