{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61b2cc81",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17372f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from medcat.cdb import CDB\n",
    "from medcat.config_rel_cat import ConfigRelCAT\n",
    "from medcat.rel_cat import RelCAT\n",
    "\n",
    "utils_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'utils'))\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.insert(0, utils_path)\n",
    "\n",
    "from general_utils import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb0cbab",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bdbf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = load_data(\"../data/inference_dataset.csv\")\n",
    "print(f\"Loaded {len(df)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd82f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332aa3d6",
   "metadata": {},
   "source": [
    "RelCAT Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2d6c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load trained RelCAT model\n",
    "relCAT = RelCAT.load(\"../models/relcat_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603e9141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define cuis for absolute and relative dates (these should align with the cuis that were used to add these terms in MedCAT Trainer)\n",
    "DATE_CUI = \"410671006\"\n",
    "RELATIVE_DATE_CUI = \"118578006\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06194e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = []\n",
    "\n",
    "doc_ids = df['doc_id'].unique()\n",
    "\n",
    "for doc_id in doc_ids:\n",
    "    # Get the row\n",
    "    row = df[df['doc_id'] == doc_id].iloc[0]\n",
    "    \n",
    "    # Parse the JSON columns\n",
    "    entities = row[\"entities_json\"] if isinstance(row[\"entities_json\"], list) else json.loads(row[\"entities_json\"])\n",
    "    dates = row[\"dates_json\"] if isinstance(row[\"dates_json\"], list) else json.loads(row[\"dates_json\"])\n",
    "    relative_dates = row[\"relative_dates_json\"] if isinstance(row[\"relative_dates_json\"], list) else json.loads(row[\"relative_dates_json\"]) if \"relative_dates_json\" in row else []\n",
    "    \n",
    "    # Create lookup maps\n",
    "    entity_map = {entity['value']: (entity['id'], entity.get('preferred_name', entity['value'])) for entity in entities}\n",
    "    date_map = {date['value']: (date['id'], 'absolute') for date in dates}\n",
    "    date_map.update({date['value']: (date['id'], 'relative') for date in relative_dates})\n",
    "    \n",
    "    # Create annotations in the same format as training\n",
    "    annotations = []\n",
    "    for entity in entities:\n",
    "        annotations.append({\n",
    "            \"value\": entity[\"value\"],\n",
    "            \"cui\": entity.get(\"cui\"),\n",
    "            \"start\": entity.get(\"start\"),\n",
    "            \"end\": entity.get(\"end\")\n",
    "        })\n",
    "    for date in dates:\n",
    "        annotations.append({\n",
    "            \"value\": date[\"value\"],\n",
    "            \"cui\": DATE_CUI,\n",
    "            \"start\": date.get(\"start\"),\n",
    "            \"end\": date.get(\"end\")\n",
    "        })\n",
    "    for date in relative_dates:\n",
    "        annotations.append({\n",
    "            \"value\": date[\"value\"],\n",
    "            \"cui\": RELATIVE_DATE_CUI,\n",
    "            \"start\": date.get(\"start\"),\n",
    "            \"end\": date.get(\"end\")\n",
    "        })\n",
    "    \n",
    "    try:\n",
    "        # Run inference\n",
    "        output_doc_with_relations = relCAT.predict_text_with_anns(\n",
    "            text=row[\"note_text\"], \n",
    "            annotations=annotations\n",
    "        )\n",
    "        \n",
    "        # Collect results - only keep date-entity pairs\n",
    "        for relation in output_doc_with_relations._.relations:\n",
    "            # Check if this is a date-entity pair (not entity-entity)\n",
    "            date_text = None\n",
    "            entity_text = None\n",
    "            \n",
    "            if relation['ent1_text'] in date_map and relation['ent2_text'] in entity_map:\n",
    "                date_text = relation['ent1_text']\n",
    "                entity_text = relation['ent2_text']\n",
    "            elif relation['ent2_text'] in date_map and relation['ent1_text'] in entity_map:\n",
    "                date_text = relation['ent2_text']\n",
    "                entity_text = relation['ent1_text']\n",
    "                \n",
    "            if date_text and entity_text:\n",
    "                date_id, date_type = date_map[date_text]\n",
    "                entity_id, preferred_name = entity_map[entity_text]\n",
    "                \n",
    "                predictions.append({\n",
    "                    'doc_id': doc_id,\n",
    "                    'date_id': date_id,\n",
    "                    'date': date_text,\n",
    "                    'date_type': date_type,\n",
    "                    'entity_id': entity_id,\n",
    "                    'entity_label': entity_text,\n",
    "                    'entity_preferred_name': preferred_name\n",
    "                })\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing document {doc_id}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Processed {len(doc_ids)} documents\")\n",
    "print(f\"Total predictions: {len(predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659000d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at predictions\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3391a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "with open('../outputs/relcat_predictions.json', 'w') as f:\n",
    "    json.dump(predictions, f, indent=2)\n",
    "\n",
    "print(\"Saved predictions to outputs/relcat_predictions.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
