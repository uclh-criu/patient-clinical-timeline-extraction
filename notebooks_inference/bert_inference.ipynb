{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb4652a",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c805a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from transformers import AutoTokenizer, set_seed\n",
    "from safetensors.torch import load_file\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import our modules\n",
    "import sys\n",
    "import os\n",
    "\n",
    "utils_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'utils'))\n",
    "models_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'models'))\n",
    "\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.insert(0, utils_path)\n",
    "if models_path not in sys.path:\n",
    "    sys.path.insert(0, models_path)\n",
    "\n",
    "from general_utils import load_data, prepare_all_samples, get_entity_date_pairs\n",
    "from bert_training_utils import add_special_tokens\n",
    "from bert_extractor_utils import preprocess_input, bert_extraction, mark_entities_full_text\n",
    "from bert_model import BertRC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e368136f",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b69680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = load_data(\"../data/inference_dataset.csv\")\n",
    "print(f\"Loaded {len(df)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54df7365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fc9f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare all samples\n",
    "samples = prepare_all_samples(df)\n",
    "print(f\"Prepared {len(samples)} samples\")\n",
    "#samples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128c81f2",
   "metadata": {},
   "source": [
    "BERT Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11a1e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eda645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set path to load model from\n",
    "model_path = '../models/bert_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0f8eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set model name - this should be the same as the base model used for training\n",
    "model_name = \"google/bert_uncased_L-2_H-128_A-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb35627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "#Load trained model\n",
    "model = BertRC(model_name=model_name, tokenizer=tokenizer, num_labels=2)\n",
    "\n",
    "#Load saved weights\n",
    "state_dict = load_file(f\"{model_path}/model.safetensors\", device=\"cpu\") # Or \"cuda\"\n",
    "\n",
    "#Apply the weights to the model instance\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "#Set the model to evaluation mode\n",
    "model.eval()\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d6298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = []\n",
    "\n",
    "for sample in tqdm(samples, desc=\"Samples\"):\n",
    "    # Get absolute date pairs\n",
    "    absolute_pairs = get_entity_date_pairs(sample['entities_list'], sample['dates'])\n",
    "    \n",
    "    # Get relative date pairs if available\n",
    "    if sample.get('relative_dates') and len(sample['relative_dates']) > 0:\n",
    "        relative_pairs = get_entity_date_pairs(sample['entities_list'], [], sample['relative_dates'])\n",
    "        pairs = absolute_pairs + relative_pairs\n",
    "    else:\n",
    "        pairs = absolute_pairs\n",
    "    \n",
    "    for pair in pairs:\n",
    "        entity = pair['entity']\n",
    "        date = pair['date_info']\n",
    "        pred, conf = bert_extraction(sample['note_text'], entity, date, model, tokenizer)\n",
    "        if pred == 1:\n",
    "            predictions.append({\n",
    "                'doc_id': sample['doc_id'],\n",
    "                'date_id': date['id'],\n",
    "                'date': date['value'],\n",
    "                'date_type': pair['date_type'],\n",
    "                'entity_id': entity['id'],\n",
    "                'entity_label': entity['value'],\n",
    "                'entity_preferred_name': entity.get('preferred_name', entity['value'])\n",
    "            })\n",
    "\n",
    "print(f\"Total predictions: {len(predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13064391",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at prediction\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3783ea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "with open('../outputs/bert_predictions.json', 'w') as f:\n",
    "    json.dump(predictions, f, indent=2)\n",
    "\n",
    "print(\"Saved predictions to outputs/bert_predictions.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
