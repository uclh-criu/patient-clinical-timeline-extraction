{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4776fa0",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1189d1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from medcat.cdb import CDB\n",
    "from medcat.vocab import Vocab\n",
    "from medcat.cat import CAT\n",
    "from medcat.config import Config\n",
    "import spacy\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "import os\n",
    "utils_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'utils'))\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.insert(0, utils_path)\n",
    "\n",
    "from general_utils import load_data, create_non_empty_filter\n",
    "from date_extractor_utils import extract_absolute_dates, extract_relative_dates\n",
    "from bert_relative_date_utils import predict_relative_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fafbc6",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80517819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "df = pd.read_csv(\"../data/dataset_synthetic1.csv\")\n",
    "print(f\"Loaded {len(df)} records for {df['patient_id'].nunique()} patients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bff4908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9d35ca",
   "metadata": {},
   "source": [
    "MedCAT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e388afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load finetuned cdb - this should be the one that was finetuned in MedCAT Trainer\n",
    "cdb = CDB.load(\"../models/cdb_AewJ3qR.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb64b7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load vocab - again the one that was used in MedCAT Trainer\n",
    "vocab = Vocab.load(\"../models/vocab.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9f88ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the model (note you will need en_core_web_md downloaded, you can run python -m spacy download en_core_web_md)\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "cat = CAT(cdb=cdb, config=cdb.config, vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8018644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained MedCAT model from modelpack (you'll need to provide the path)\n",
    "# This is a bit hacky but for the purpose of getting meta-annotations that are not available from MedCAT Trainer models\n",
    "cat_2 = CAT.load_model_pack(\"../models/20230227__kch_gstt_trained_model_494c3717f637bb89.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2f6440",
   "metadata": {},
   "source": [
    "Relative Date Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4393546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set relative date method - can be bert or regex\n",
    "relative_date_method = 'regex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3b8466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model load path\n",
    "if relative_date_method == 'bert':\n",
    "    model_load_path = '../models/bert_model_relative_dates/'\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e287516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned relative date extractor\n",
    "if relative_date_method == 'bert':\n",
    "    relative_model_path = model_load_path\n",
    "    tokenizer_rel = AutoTokenizer.from_pretrained(relative_model_path)\n",
    "    model_rel = AutoModelForTokenClassification.from_pretrained(relative_model_path)\n",
    "    model_rel.eval()\n",
    "\n",
    "    print(\"Relative date model loaded successfully!\")\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616ac0c2",
   "metadata": {},
   "source": [
    "Add Entities & Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762df650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each document\n",
    "results = []\n",
    "\n",
    "# Define the set of categories you want to keep\n",
    "keep_categories = {'disorder', 'substance', 'finding'}\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), desc='row'):\n",
    "    patient_id = row['patient_id']\n",
    "    doc_id = row['doc_id']\n",
    "    text = row['note_text']\n",
    "\n",
    "    # Extract entities and meta-annotations using cat_2\n",
    "    doc_2 = cat_2(text)\n",
    "    meta_anns_lookup = {} # Dictionary to store meta-anns keyed by (start, end)\n",
    "    for ent_2 in doc_2.ents:\n",
    "        if ent_2._.cui != -1:\n",
    "            # Extract Negation Status\n",
    "            negated = False\n",
    "            if hasattr(ent_2._, 'meta_anns') and ent_2._.meta_anns and 'Presence' in ent_2._.meta_anns:\n",
    "                if ent_2._.meta_anns['Presence'].get('value') == 'False':\n",
    "                    negated = True\n",
    "            # Extract Subject\n",
    "            subject = None\n",
    "            if hasattr(ent_2._, 'meta_anns') and ent_2._.meta_anns and 'Subject' in ent_2._.meta_anns:\n",
    "                subject = ent_2._.meta_anns['Subject'].get('value')\n",
    "\n",
    "            # Store in lookup table\n",
    "            meta_anns_lookup[(ent_2.start_char, ent_2.end_char)] = {'negated': negated, 'subject': subject}\n",
    "\n",
    "    # Extract entities using cat\n",
    "    doc = cat(text)\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        # Check for valid CUI\n",
    "        if ent._.cui != -1:\n",
    "\n",
    "            # Get preferred name string from cat\n",
    "            preferred_name_str = cat.cdb.cui2preferred_name.get(ent._.cui)\n",
    "\n",
    "            # Parse category from cat's preferred name\n",
    "            preferred_name = preferred_name_str\n",
    "            category_name = None\n",
    "            if preferred_name_str and preferred_name_str.endswith(')') and ' (' in preferred_name_str:\n",
    "                parts = preferred_name_str.rsplit(' (', 1)\n",
    "                if len(parts) == 2:\n",
    "                    preferred_name = parts[0]\n",
    "                    category_name = parts[1].rstrip(')')\n",
    "\n",
    "            # Apply category filter\n",
    "            if category_name in keep_categories:\n",
    "\n",
    "                # Look up meta-annotations from cat_2\n",
    "                span_key = (ent.start_char, ent.end_char)\n",
    "                meta_anns = meta_anns_lookup.get(span_key)\n",
    "\n",
    "                if meta_anns: # Check if cat_2 found a matching entity\n",
    "                    negated_val = meta_anns['negated']\n",
    "                    subject_val = meta_anns['subject']\n",
    "\n",
    "                    # Apply meta-annotation filters\n",
    "                    # Keep only if NOT negated\n",
    "                    if not negated_val:\n",
    "                        entities.append({\n",
    "                            'id': f\"ent_{len(entities) + 1}\",\n",
    "                            'value': ent.text,\n",
    "                            'preferred_name': preferred_name,\n",
    "                            'cui': ent._.cui,\n",
    "                            'category': category_name,\n",
    "                            'negated': negated_val,\n",
    "                            'subject': subject_val,\n",
    "                            'start': ent.start_char,\n",
    "                            'end': ent.end_char\n",
    "                        })\n",
    "\n",
    "    # Extract dates\n",
    "    dates = extract_absolute_dates(text)\n",
    "    if relative_date_method == 'bert':\n",
    "        relative_dates = predict_relative_dates(text, model_rel, tokenizer_rel)\n",
    "    elif relative_date_method == 'regex':\n",
    "        relative_dates = extract_relative_dates(text)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid method: {relative_date_method}. Must be either 'bert' or 'regex'.\")\n",
    "\n",
    "    # Create final result row\n",
    "    results.append({\n",
    "        'patient_id': patient_id,\n",
    "        'doc_id': doc_id,\n",
    "        'note_text': text,\n",
    "        'entities_json': json.dumps(entities),\n",
    "        'dates_json': json.dumps(dates),\n",
    "        'relative_dates_json': json.dumps(relative_dates)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997087ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to df\n",
    "inference_df = pd.DataFrame(results)\n",
    "print(f\"Created inference dataset with {len(inference_df)} records and {inference_df['patient_id'].nunique()} patients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ce616",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect df\n",
    "inference_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bad4f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save csv\n",
    "inference_df.to_csv(\"../data/inference_dataset_synthetic1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74f6510",
   "metadata": {},
   "source": [
    "Basic Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a2a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "#inference_df = load_data(\"../data/inference_dataset_synthetic1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0915be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check length\n",
    "print(f\"Loaded {len(inference_df)} records for {inference_df['patient_id'].nunique()} patients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fdb42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check data types\n",
    "print(\"--- Data type distribution for 'entities_json' ---\")\n",
    "print(inference_df['entities_json'].apply(type).value_counts())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"--- Data type distribution for 'dates_json' ---\")\n",
    "print(inference_df['dates_json'].apply(type).value_counts())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"--- Data type distribution for 'relative_dates_json' ---\")\n",
    "print(inference_df['relative_dates_json'].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e68a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filters dynamically for each column\n",
    "has_entities = create_non_empty_filter(inference_df['entities_json'])\n",
    "has_absolute_dates = create_non_empty_filter(inference_df['dates_json'])\n",
    "has_relative_dates = create_non_empty_filter(inference_df['relative_dates_json'])\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 1. How many rows have entities\n",
    "rows_with_entities_count = has_entities.sum()\n",
    "print(f\"Number of rows with entities: {rows_with_entities_count}\")\n",
    "\n",
    "# 2. How many rows have absolute dates\n",
    "rows_with_absolute_dates_count = has_absolute_dates.sum()\n",
    "print(f\"Number of rows with absolute dates: {rows_with_absolute_dates_count}\")\n",
    "\n",
    "# 3. How many rows have relative dates\n",
    "rows_with_relative_dates_count = has_relative_dates.sum()\n",
    "print(f\"Number of rows with relative dates: {rows_with_relative_dates_count}\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 4. How many distinct patients have entities\n",
    "patients_with_entities_count = inference_df.loc[has_entities, 'patient_id'].nunique()\n",
    "print(f\"Number of distinct patients with entities: {patients_with_entities_count}\")\n",
    "\n",
    "# 5. How many distinct patients have absolute dates\n",
    "patients_with_absolute_dates_count = inference_df.loc[has_absolute_dates, 'patient_id'].nunique()\n",
    "print(f\"Number of distinct patients with absolute dates: {patients_with_absolute_dates_count}\")\n",
    "\n",
    "# 6. How many distinct patients have relative dates\n",
    "patients_with_relative_dates_count = inference_df.loc[has_relative_dates, 'patient_id'].nunique()\n",
    "print(f\"Number of distinct patients with relative dates: {patients_with_relative_dates_count}\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 7. Number of distinct patients with entities AND (absolute dates OR relative dates)\n",
    "has_any_date = has_absolute_dates | has_relative_dates\n",
    "combined_filter = has_entities & has_any_date\n",
    "\n",
    "patients_with_entities_and_dates_count = inference_df.loc[combined_filter, 'patient_id'].nunique()\n",
    "print(f\"Number of distinct patients with entities AND (absolute OR relative dates): {patients_with_entities_and_dates_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
