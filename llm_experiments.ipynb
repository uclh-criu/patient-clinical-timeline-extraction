{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb4652a",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c805a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "from utils import load_data, prepare_all_samples, get_entity_date_pairs, calculate_metrics\n",
    "from llm_extractor import load_prompt_template, make_binary_prompt, llm_extraction, parse_llm_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e368136f",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b69680b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 101 records\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = load_data(\"data/synthetic.csv\")\n",
    "print(f\"Loaded {len(df)} records\")\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0fc9f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 101 samples\n"
     ]
    }
   ],
   "source": [
    "# Prepare all samples\n",
    "samples = prepare_all_samples(df)\n",
    "print(f\"Prepared {len(samples)} samples\")\n",
    "#samples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc438d4a",
   "metadata": {},
   "source": [
    "LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81853642",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Define generator\n",
    "#generator = pipeline(\"text-generation\", model=\"../Llama-3.2-3B-Instruct\", device=-1)\n",
    "generator = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\", device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "735f60be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n"
     ]
    }
   ],
   "source": [
    "# Test simple prompt using generator\n",
    "prompt = \"Does the following text indicate a relationship between 'asthma' and '2024-08-02'? Answer YES or NO. Text: Patient diagnosed with asthma on 2024-08-02.\"\n",
    "result = generator(prompt)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4af851f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test simple prompt using llm_extraction() function\n",
    "prompt = \"Does the following text indicate a relationship between 'asthma' and '2024-08-02'? Answer YES or NO. Text: Patient diagnosed with asthma on 2024-08-02.\"\n",
    "response = llm_extraction(prompt, generator)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "462d4d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt to use\n",
    "prompt_to_use = 'prompt.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7906c3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Samples:  25%|██▍       | 25/101 [05:14<15:16, 12.06s/it]"
     ]
    }
   ],
   "source": [
    "#Process all date-entity pairs, make prompt, do llm extraction and make prediction\n",
    "predictions = []\n",
    "\n",
    "for sample in tqdm(samples, desc=\"Samples\"):\n",
    "    pairs = get_entity_date_pairs(sample['entities_list'], sample['dates'])\n",
    "    #for pair in pairs[:1]:\n",
    "    for pair in pairs:\n",
    "        #print(pair)\n",
    "        prompt = make_binary_prompt(pair['entity'], pair['date_info'], sample['note_text'], prompt_to_use)\n",
    "        #print(prompt)\n",
    "        response = llm_extraction(prompt, generator)\n",
    "        #print(response)\n",
    "        pred, conf = parse_llm_answer(response)\n",
    "        #print(pred, conf)\n",
    "        if pred == 1:\n",
    "            predictions.append({\n",
    "                'entity_label': pair['entity_label'],\n",
    "                'date': pair['date'],\n",
    "                'confidence': conf\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51463dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at prediction\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dbefd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculcate metrics\n",
    "metrics = calculate_metrics(predictions, df)\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
