{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "893e4d71",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf36ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "utils_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'utils'))\n",
    "\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.insert(0, utils_path)\n",
    "\n",
    "from llm_extractor_utils import make_multi_prompt, llm_extraction_multi_openai\n",
    "from general_utils import load_data, prepare_all_samples, calculate_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf22572",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cfef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = load_data(\"../data/training_dataset_synthetic.csv\")\n",
    "print(f\"Loaded {len(df)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66275146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db541e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare all samples\n",
    "samples = prepare_all_samples(df)\n",
    "print(f\"Prepared {len(samples)} samples\")\n",
    "#samples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b088abe",
   "metadata": {},
   "source": [
    "LLM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3a69b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose whether to use HuggingFace 'hf' or OpenAI 'openai'\n",
    "#Note if choosing OpenAI need to set OPENAI_API_KEY in .env file\n",
    "method = 'openai' #options are 'hf' or 'openai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1748a3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LLM to use \n",
    "# If using HF any text generation model from HuggingFace can be used, see: https://huggingface.co/models?pipeline_tag=text-generation)\n",
    "# If using OpenAI you can use any model from OpenAI provided it supports text generation, see: https://platform.openai.com/docs/models\n",
    "model = 'gpt-4o'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb90877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define generator if using HF option\n",
    "#generator = pipeline(\"text-generation\", model=model, device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a4fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt to use\n",
    "prompt_to_use = 'multi_prompt.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837f0ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process all samples, make prompt, do llm extraction and make prediction\n",
    "predictions = []\n",
    "\n",
    "for sample in tqdm(samples, desc=\"Processing notes\"):\n",
    "    # Create multi-extraction prompt\n",
    "    prompt = make_multi_prompt(\n",
    "        note_text=sample['note_text'],\n",
    "        prompt_filename=prompt_to_use,\n",
    "        entities_list=sample['entities_list'], #optinal - does not need to be passed\n",
    "        dates=sample['dates'] #optional - does not need to be passed\n",
    "    )\n",
    "    \n",
    "    # Get all relationships in one call\n",
    "    relationships = llm_extraction_multi_openai(prompt, model=model)\n",
    "    \n",
    "    # Add to predictions\n",
    "    predictions.extend(relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c106dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at prediction\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3986fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculcate metrics\n",
    "metrics = calculate_metrics(predictions, df)\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
