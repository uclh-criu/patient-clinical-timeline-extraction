{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "893e4d71",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf36ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline, BitsAndBytesConfig\n",
    "from openai import OpenAI\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "utils_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'utils'))\n",
    "\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.insert(0, utils_path)\n",
    "\n",
    "from general_utils import load_data, prepare_all_samples, get_entity_date_pairs, calculate_metrics\n",
    "\n",
    "from llm_extractor_utils import (\n",
    "    make_binary_prompt, \n",
    "    llm_extraction_binary_hf,\n",
    "    llm_extraction_binary_openai,\n",
    "    parse_llm_answer,\n",
    "    make_multi_prompt,\n",
    "    llm_extraction_multi_openai,\n",
    "    llm_extraction_multi_hf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf22572",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cfef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = load_data(\"../data/training_dataset_synthetic1.csv\")\n",
    "print(f\"Loaded {len(df)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66275146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect df\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db541e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare all samples\n",
    "samples = prepare_all_samples(df)\n",
    "print(f\"Prepared {len(samples)} samples\")\n",
    "#samples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b088abe",
   "metadata": {},
   "source": [
    "LLM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3a69b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose whether to use HuggingFace 'hf' or OpenAI 'openai'\n",
    "#Note if choosing OpenAI need to set OPENAI_API_KEY in .env file\n",
    "provider = 'openai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195fcbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set device\n",
    "device = -1  # Set to -1 for CPU, 0 for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e8a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose whether to do binary prediction 'binary' or multi-prediction 'multi'\n",
    "#Binary prediction is where the LLM is passed every possible entity-date pair and asked to predict whether they are related (Yes or No). This requires a lot more LLM calls so can be expensive if using the OpenAI API\n",
    "#Multi prediction is where the LLM is passed each note in turn and asked to extract all correct relations in one go as a json\n",
    "method = 'multi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c6298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose whether to use zero-shot 'zero' or few-shot prompt 'few'\n",
    "prompt_type = 'few'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ba25d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To see a list of available OpenAI API models\n",
    "#Alternatively visit https://platform.openai.com/docs/models\n",
    "\n",
    "#client = OpenAI(api_key = os.getenv('OPENAI_API_KEY'))\n",
    "#models = client.models.list()\n",
    "#for model in models:\n",
    "    #print(model.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4f163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To see a list of available HuggingFace text generation models\n",
    "#Alternatively visit https://huggingface.co/models?pipeline_tag=text-generation\n",
    "\n",
    "#Uncomment the below code to see the full list. Note this list is long and can take a couple of mins to run\n",
    "#api = HfApi()\n",
    "#text_gen_models = api.list_models(filter=\"text-generation\")\n",
    "#for model_info in text_gen_models:\n",
    "    #print(model_info.modelId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1748a3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LLM to use - this should be the model id from OpenAI or HuggingFace\n",
    "model = 'gpt-3.5-turbo'\n",
    "\n",
    "#Examples of OpenAI models\n",
    "#model = 'gpt-3.5-turbo' #cheap option for binary method\n",
    "#model = 'o4-mini'\n",
    "#model = 'gpt-5-mini' #cost-effective reasoning model, good for multi method\n",
    "\n",
    "#Examples of HF models\n",
    "#model = 'gpt2'\n",
    "#model = 'google/gemma-3-270m'\n",
    "#model= 'Qwen/Qwen3-0.6B'\n",
    "#model= 'roneneldan/TinyStories-1M' #fast option even on CPU, good for binary method\n",
    "#model = 'EleutherAI/gpt-neo-125m'\n",
    "#model = 'microsoft/phi-1_5'\n",
    "#model = 'TinyLlama/TinyLlama-1.1B-chat-v1.0'\n",
    "#model = '../Llama-3.1-8B-Instruct' #lcoal folder example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066d02ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure quantization if using HF opion\n",
    "if provider == 'hf':\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_8bit=True,\n",
    "        llm_int8_enable_fp32_cpu_offload=True\n",
    "    )\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb90877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define generator if using HF option\n",
    "if provider == 'hf':\n",
    "    if method == 'multi':\n",
    "        generator = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=model,\n",
    "            #device=device,\n",
    "            model_kwargs={\"quantization_config\": quantization_config},\n",
    "            max_new_tokens=1000,\n",
    "            do_sample=False,\n",
    "            #pad_token_id=2,  # Common pad token ID for Llama models\n",
    "            #eos_token_id=2,  # End of sequence token\n",
    "            return_full_text=False  # Only return the newly generated text\n",
    "        )\n",
    "    else:\n",
    "        # Regular text generation for binary method\n",
    "        generator = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=model,\n",
    "            #device=device,\n",
    "            model_kwargs={\"quantization_config\": quantization_config}\n",
    "        )\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a4fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt to use\n",
    "if method == 'binary' and prompt_type == 'zero':\n",
    "    prompt_to_use = 'binary_prompt_zero_shot.txt'\n",
    "elif method == 'binary' and prompt_type == 'few':\n",
    "    prompt_to_use = 'binary_prompt_few_shot.txt'\n",
    "elif method == 'multi' and prompt_type == 'zero':\n",
    "    prompt_to_use = 'multi_prompt_zero_shot.txt'\n",
    "elif method == 'multi' and prompt_type == 'few':\n",
    "    prompt_to_use = 'multi_prompt_few_shot.txt'\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f\"Invalid method: {method} or prompt type {prompt_type}. \"\n",
    "        \"Method must be either 'binary' or 'multi' and prompt type must be either 'zero' or 'few'.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8637ca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process samples, make prompt, do llm extraction and make predictions\n",
    "predictions = []\n",
    "\n",
    "if method == 'binary':\n",
    "    for sample in tqdm(samples, desc=\"Samples\"):\n",
    "        \n",
    "        # Get absolute date pairs\n",
    "        absolute_pairs = get_entity_date_pairs(sample['entities_list'], sample['dates'])\n",
    "        \n",
    "        # Get relative date pairs if available\n",
    "        if sample.get('relative_dates') and len(sample['relative_dates']) > 0:\n",
    "            relative_pairs = get_entity_date_pairs(sample['entities_list'], [], sample['relative_dates'])\n",
    "            pairs = absolute_pairs + relative_pairs\n",
    "        else:\n",
    "            pairs = absolute_pairs\n",
    "        \n",
    "        for pair in pairs:\n",
    "            #Create binary prompt\n",
    "            prompt = make_binary_prompt(pair['entity'], pair['date_info'], sample['note_text'], prompt_to_use)\n",
    "            \n",
    "            #Get response based on the method chosen\n",
    "            if provider == 'openai':\n",
    "                response = llm_extraction_binary_openai(prompt, model=model)\n",
    "            elif provider == 'hf':\n",
    "                response = llm_extraction_binary_hf(prompt, generator)\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid provider: {provider}. Must be either 'openai' or 'hf'.\")\n",
    "            \n",
    "            #Parse response into binary prediction\n",
    "            pred, conf = parse_llm_answer(response)\n",
    "            if pred == 1:\n",
    "                predictions.append({\n",
    "                    'entity_label': pair['entity_label'],\n",
    "                    'date': pair['date'],\n",
    "                    'confidence': conf\n",
    "                })\n",
    "\n",
    "elif method == 'multi':\n",
    "    for sample in tqdm(samples, desc=\"Processing notes\"):\n",
    "        \n",
    "        # Create multi-extraction prompt\n",
    "        prompt = make_multi_prompt(\n",
    "            note_text=sample['note_text'],\n",
    "            prompt_filename=prompt_to_use,\n",
    "            entities_list=sample['entities_list'],\n",
    "            dates=sample['dates']\n",
    "        )\n",
    "        \n",
    "        # Get all relationships in one call\n",
    "        if provider == 'openai':\n",
    "            relationships = llm_extraction_multi_openai(prompt, model=model)\n",
    "        elif provider == 'hf':\n",
    "            relationships = llm_extraction_multi_hf(prompt, generator)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid provider: {provider}. Must be either 'openai' or 'hf'.\")\n",
    "        \n",
    "        # Add to predictions\n",
    "        predictions.extend(relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c106dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at predictions\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3986fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculcate metrics\n",
    "metrics = calculate_metrics(predictions, df)\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
