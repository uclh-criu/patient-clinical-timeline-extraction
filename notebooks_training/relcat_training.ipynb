{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61b2cc81",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17372f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import logging\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from medcat.cdb import CDB\n",
    "from medcat.config_rel_cat import ConfigRelCAT\n",
    "from medcat.rel_cat import RelCAT\n",
    "from medcat.utils.relation_extraction.base_component import BaseComponent_RelationExtraction\n",
    "from medcat.utils.relation_extraction.bert.model import BaseModel_RelationExtraction\n",
    "from medcat.utils.relation_extraction.bert.config import BaseConfig_RelationExtraction\n",
    "from medcat.utils.relation_extraction.tokenizer import BaseTokenizerWrapper_RelationExtraction\n",
    "\n",
    "import sys, os\n",
    "utils_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'utils'))\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.insert(0, utils_path)\n",
    "\n",
    "from general_utils import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ca0d6c",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bdbf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = load_data(\"../data/training_dataset.csv\")\n",
    "print(f\"Loaded {len(df)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dd5532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf812a8",
   "metadata": {},
   "source": [
    "Create Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61acc0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert marker function\n",
    "def insert_marker(txt, start, end, tag_open, tag_close):\n",
    "                    return txt[:start] + tag_open + txt[start:end] + tag_close + txt[end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e2fe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset for training\n",
    "rows = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    doc_id = row[\"doc_id\"]\n",
    "    text = row[\"note_text\"]\n",
    "    \n",
    "    # Parse the JSON columns - handle both string and already-parsed cases\n",
    "    entities = row[\"entities_json\"] if isinstance(row[\"entities_json\"], list) else json.loads(row[\"entities_json\"])\n",
    "    dates = row[\"dates_json\"] if isinstance(row[\"dates_json\"], list) else json.loads(row[\"dates_json\"])\n",
    "    relative_dates = row[\"relative_dates_json\"] if isinstance(row[\"relative_dates_json\"], list) else json.loads(row[\"relative_dates_json\"]) if \"relative_dates_json\" in row else []\n",
    "    \n",
    "    # Combine absolute and relative dates\n",
    "    all_dates = dates + relative_dates\n",
    "    \n",
    "    # Get original relations for labeling\n",
    "    relations = row[\"relations_json\"] if isinstance(row[\"relations_json\"], list) else json.loads(row[\"relations_json\"])\n",
    "    \n",
    "    # Build relation pairs from validated relations - match by IDs\n",
    "    relation_pairs = {tuple(sorted([str(L[\"date_id\"]), str(L[\"entity_id\"])])) for L in relations}\n",
    "    \n",
    "    # Create pairs for all date-entity combinations\n",
    "    for date in all_dates:\n",
    "        for entity in entities:\n",
    "            # Use IDs for matching\n",
    "            date_id = str(date[\"id\"])\n",
    "            entity_id = str(entity[\"id\"])\n",
    "            \n",
    "            # Determine label\n",
    "            if tuple(sorted([date_id, entity_id])) in relation_pairs:\n",
    "                label, label_id = \"RELATION\", 1\n",
    "            else:\n",
    "                label, label_id = \"NO_RELATION\", 0\n",
    "            \n",
    "            # Insert markers\n",
    "            s1, e1 = date.get(\"start\"), date.get(\"end\")\n",
    "            s2, e2 = entity.get(\"start\"), entity.get(\"end\")\n",
    "            \n",
    "            if s1 is not None and s2 is not None:\n",
    "                if s1 < s2:\n",
    "                    marked = insert_marker(text, s2, e2, \"[s2]\", \"[e2]\")\n",
    "                    marked = insert_marker(marked, s1, e1, \"[s1]\", \"[e1]\")\n",
    "                else:\n",
    "                    marked = insert_marker(text, s1, e1, \"[s2]\", \"[e2]\")\n",
    "                    marked = insert_marker(marked, s2, e2, \"[s1]\", \"[e1]\")\n",
    "            else:\n",
    "                marked = text\n",
    "            \n",
    "            rows.append({\n",
    "                \"relation_token_span_ids\": None,\n",
    "                \"ent1_ent2_start\": (s1, s2),\n",
    "                \"ent1\": date.get(\"value\", \"\"),\n",
    "                \"ent2\": entity.get(\"value\", \"\"),\n",
    "                \"label\": label,\n",
    "                \"label_id\": label_id,\n",
    "                \"ent1_type\": \"DATE\",\n",
    "                \"ent2_type\": \"ENTITY\",\n",
    "                \"ent1_id\": date_id,\n",
    "                \"ent2_id\": entity_id,\n",
    "                \"ent1_cui\": None,\n",
    "                \"ent2_cui\": None,\n",
    "                \"doc_id\": doc_id,\n",
    "                \"text\": marked\n",
    "            })\n",
    "\n",
    "training_df = pd.DataFrame(rows)\n",
    "print(f\"Created {len(training_df)} date-entity pairs (including relative dates)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be91d40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect data\n",
    "print(f\"Dataset: {len(training_df)} samples\")\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(training_df[\"label\"].value_counts())\n",
    "\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16571e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-document summary from original data\n",
    "summary = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    ## Parse the JSON columns - handle both string and already-parsed cases\n",
    "    entities = row[\"entities_json\"] if isinstance(row[\"entities_json\"], list) else json.loads(row[\"entities_json\"])\n",
    "    dates = row[\"dates_json\"] if isinstance(row[\"dates_json\"], list) else json.loads(row[\"dates_json\"])\n",
    "    relative_dates = row[\"relative_dates_json\"] if isinstance(row[\"relative_dates_json\"], list) else json.loads(row[\"relative_dates_json\"]) if \"relative_dates_json\" in row else []\n",
    "    relations = row[\"relations_json\"] if isinstance(row[\"relations_json\"], list) else json.loads(row[\"relations_json\"])\n",
    "    \n",
    "    summary.append({\n",
    "        \"doc_id\": row[\"doc_id\"],\n",
    "        \"n_entities\": len(entities),\n",
    "        \"n_dates\": len(dates),\n",
    "        \"n_relative_dates\": len(relative_dates),\n",
    "        \"n_relations\": len(relations),\n",
    "    })\n",
    "\n",
    "doc_level = pd.DataFrame(summary)\n",
    "doc_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d00e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair-based stats from the generated df\n",
    "pair_stats = (\n",
    "    training_df.groupby(\"doc_id\")\n",
    "      .agg(\n",
    "          total_pairs=(\"label\", \"size\"),\n",
    "          relation_pairs=(\"label\", lambda s: (s == \"RELATION\").sum()),\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "pair_stats[\"relation_pct\"] = (100 * pair_stats[\"relation_pairs\"] / pair_stats[\"total_pairs\"]).round(1)\n",
    "pair_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce540151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge stats with doc_level summary\n",
    "doc_level = (\n",
    "    doc_level.merge(pair_stats[[\"doc_id\", \"total_pairs\", \"relation_pct\"]], on=\"doc_id\", how=\"left\")\n",
    "             .sort_values(\"doc_id\")\n",
    "             .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Calculate additional metrics\n",
    "total_pairs_overall = len(training_df)\n",
    "relation_total = (training_df[\"label\"] == \"RELATION\").sum()\n",
    "relation_pct_overall = 100 * (training_df[\"label\"] == \"RELATION\").mean()\n",
    "\n",
    "print(f\"total number of date-entity pairs is {total_pairs_overall}\")\n",
    "print(f\"total number of relations: {relation_total}\")\n",
    "print(f\"percentage positive class: {relation_pct_overall:.1f}%\")\n",
    "\n",
    "#Look at overall doc level summary\n",
    "doc_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b1d11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training dataset\n",
    "training_df.to_csv(\"../data/relcat_training_data.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b97b1e3",
   "metadata": {},
   "source": [
    "Training & Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c83c4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose model to use - any BERT model from HuggingFace can be used, see: https://huggingface.co/google-bert\n",
    "model = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff10b6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set path to save trained model and checkpoints to\n",
    "model_save_path = '../models/relcat_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190063fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create RelCAT config and set parameters\n",
    "config = ConfigRelCAT()\n",
    "config.general.log_level = logging.INFO\n",
    "config.general.model_name = model\n",
    "#logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404b03da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hidden size, model size and hidden layers\n",
    "config.model.hidden_size= 256\n",
    "config.model.model_size = 2304 # 4096 for llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f98025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further config\n",
    "config.general.cntx_left = 15\n",
    "config.general.cntx_right = 15\n",
    "config.general.window_size = 400\n",
    "config.train.nclasses = 2\n",
    "config.train.nepochs = 3\n",
    "config.model.freeze_layers = False\n",
    "config.general.limit_samples_per_class = 300\n",
    "config.train.batch_size = 32\n",
    "config.train.lr = 3e-5\n",
    "config.train.adam_epsilon = 1e-8\n",
    "config.train.adam_weight_decay = 0.0005\n",
    "config.train.class_weights = [0.3027, 1.6973]\n",
    "config.train.enable_class_weights = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646e1fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create CDB\n",
    "cdb = CDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a25fb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create tokenizer\n",
    "tokenizer = BaseTokenizerWrapper_RelationExtraction.load(tokenizer_path=config.general.model_name,\n",
    "                                                       relcat_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28ce90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add special tokens\n",
    "special_ent_tokens = [\"[s1]\", \"[e1]\", \"[s2]\", \"[e2]\"]\n",
    "tokenizer.hf_tokenizers.add_tokens(special_ent_tokens, special_tokens=True)\n",
    "tokenizer.hf_tokenizers.add_special_tokens({'pad_token': '[PAD]'}) # used in llama tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a46f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add tokens to config\n",
    "config.general.tokenizer_relation_annotation_special_tokens_tags = special_ent_tokens\n",
    "config.general.annotation_schema_tag_ids = tokenizer.hf_tokenizers.convert_tokens_to_ids(special_ent_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11e8338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create RelCAT object\n",
    "relCAT = RelCAT(cdb, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc437ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model configuration\n",
    "model_config = BaseConfig_RelationExtraction.load(pretrained_model_name_or_path=config.general.model_name,\n",
    "                                                 relcat_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2ee74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update vocab size in model config to match tokenizer\n",
    "model_config.hf_model_config.vocab_size = tokenizer.get_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657d3f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the padding idx in the model config and relcat config, this is necesasry as it depends on what tokenizer you use\n",
    "config.model.padding_idx = model_config.pad_token_id = tokenizer.get_pad_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b81f863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = BaseModel_RelationExtraction.load(pretrained_model_name_or_path=config.general.model_name,\n",
    "                                         model_config=model_config,\n",
    "                                         relcat_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4db06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize embeddings to match tokenizer\n",
    "model.hf_model.resize_token_embeddings(len(tokenizer.hf_tokenizers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83084dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RelCAT component\n",
    "component = BaseComponent_RelationExtraction(tokenizer=tokenizer, config=config)\n",
    "component.model = model\n",
    "component.model_config = model_config\n",
    "component.relcat_config = config\n",
    "component.tokenizer = tokenizer\n",
    "relCAT.component = component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f38d7ea",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c0514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the dataset we created earlier\n",
    "relCAT.train(\n",
    "    train_csv_path=\"../data/relcat_training_data.tsv\",  \n",
    "    checkpoint_path=model_save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4343546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "relCAT.save(save_path=model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
