{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb4652a",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02c805a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback, set_seed\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import our modules\n",
    "import sys\n",
    "import os\n",
    "\n",
    "utils_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'utils'))\n",
    "models_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'models'))\n",
    "\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.insert(0, utils_path)\n",
    "if models_path not in sys.path:\n",
    "    sys.path.insert(0, models_path)\n",
    "\n",
    "from general_utils import load_data, prepare_all_samples, get_entity_date_pairs, calculate_metrics\n",
    "from bert_training_utils import create_training_pairs, handle_class_imbalance, add_special_tokens, tokenize_function, compute_metrics, build_gold_lookup, get_label_for_pair\n",
    "from bert_extractor_utils import preprocess_input, bert_extraction, mark_entities_full_text\n",
    "from bert_model import BertRC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e368136f",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b69680b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 records\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = load_data(\"../data/training_dataset.csv\")\n",
    "print(f\"Loaded {len(df)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ef7e0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>note_text</th>\n",
       "      <th>entities_json</th>\n",
       "      <th>dates_json</th>\n",
       "      <th>relative_dates_json</th>\n",
       "      <th>relations_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26461</td>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "      <td>[{'id': 308244, 'value': 'history of meningiti...</td>\n",
       "      <td>[{'id': 308320, 'value': '30nd Jun 2024', 'sta...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'date': '12nd Sep 2024', 'entity': 'pituitar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26462</td>\n",
       "      <td>Labs (27th Sep 2024): anemia. resolving  Skin:...</td>\n",
       "      <td>[{'id': 308371, 'value': 'lesions', 'cui': '52...</td>\n",
       "      <td>[{'id': 308581, 'value': '22/11/24', 'start': ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'date': '27th Sep 2024', 'entity': 'anemia',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26463</td>\n",
       "      <td>URGENT REVIEW (2024-10-04): cough. suspect ost...</td>\n",
       "      <td>[{'id': 308886, 'value': 'frequent urination',...</td>\n",
       "      <td>[{'id': 308940, 'value': '2024-10-04', 'start'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'date': '2024-10-04', 'entity': 'cough', 'da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26464</td>\n",
       "      <td>URGENT REVIEW (13rd Feb 2025) MRI of the brain...</td>\n",
       "      <td>[{'id': 308951, 'value': 'multiple_sclerosis',...</td>\n",
       "      <td>[{'id': 308996, 'value': '05-03-2025', 'start'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'date': '13rd Feb 2025', 'entity': 'visual',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26465</td>\n",
       "      <td>New pt((18/11/24)): pt presents with nausea/vo...</td>\n",
       "      <td>[{'id': 308998, 'value': 'history of neoplasm ...</td>\n",
       "      <td>[{'id': 309070, 'value': '18/11/24', 'start': ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'date': '18/11/24', 'entity': 'nausea/vomiti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                          note_text  \\\n",
       "0   26461  Ultrasound (30nd Jun 2024): no significant fin...   \n",
       "1   26462  Labs (27th Sep 2024): anemia. resolving  Skin:...   \n",
       "2   26463  URGENT REVIEW (2024-10-04): cough. suspect ost...   \n",
       "3   26464  URGENT REVIEW (13rd Feb 2025) MRI of the brain...   \n",
       "4   26465  New pt((18/11/24)): pt presents with nausea/vo...   \n",
       "\n",
       "                                       entities_json  \\\n",
       "0  [{'id': 308244, 'value': 'history of meningiti...   \n",
       "1  [{'id': 308371, 'value': 'lesions', 'cui': '52...   \n",
       "2  [{'id': 308886, 'value': 'frequent urination',...   \n",
       "3  [{'id': 308951, 'value': 'multiple_sclerosis',...   \n",
       "4  [{'id': 308998, 'value': 'history of neoplasm ...   \n",
       "\n",
       "                                          dates_json relative_dates_json  \\\n",
       "0  [{'id': 308320, 'value': '30nd Jun 2024', 'sta...                  []   \n",
       "1  [{'id': 308581, 'value': '22/11/24', 'start': ...                  []   \n",
       "2  [{'id': 308940, 'value': '2024-10-04', 'start'...                  []   \n",
       "3  [{'id': 308996, 'value': '05-03-2025', 'start'...                  []   \n",
       "4  [{'id': 309070, 'value': '18/11/24', 'start': ...                  []   \n",
       "\n",
       "                                      relations_json  \n",
       "0  [{'date': '12nd Sep 2024', 'entity': 'pituitar...  \n",
       "1  [{'date': '27th Sep 2024', 'entity': 'anemia',...  \n",
       "2  [{'date': '2024-10-04', 'entity': 'cough', 'da...  \n",
       "3  [{'date': '13rd Feb 2025', 'entity': 'visual',...  \n",
       "4  [{'date': '18/11/24', 'entity': 'nausea/vomiti...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspect df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0fc9f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 5 samples\n"
     ]
    }
   ],
   "source": [
    "# Prepare all samples\n",
    "samples = prepare_all_samples(df)\n",
    "print(f\"Prepared {len(samples)} samples\")\n",
    "#samples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094065cf",
   "metadata": {},
   "source": [
    "Model & Data Preparation for Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e11a1e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16f5eddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set path to save model\n",
    "model_save_path = '../models/bert_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "382400c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose model to use - any BERT model from HuggingFace can be used, see: https://huggingface.co/google-bert\n",
    "model_name = \"google/bert_uncased_L-2_H-128_A-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "597c91cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load base model and tokenizer\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba264bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created 741 training pairs\n"
     ]
    }
   ],
   "source": [
    "# Create training pairs\n",
    "processed_df = create_training_pairs(samples)\n",
    "print(f\"\\nCreated {len(processed_df)} training pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30358a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: tensor([0.1188, 1.8812])\n"
     ]
    }
   ],
   "source": [
    "# Handle class imbalance\n",
    "balanced_df, class_weights = handle_class_imbalance(processed_df, method='weighted')\n",
    "print(f\"Class weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d411c840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 592, Test: 149\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "train_df, test_df = train_test_split(balanced_df, test_size=0.2, random_state=42, stratify=balanced_df['label'])\n",
    "print(f\"Train: {len(train_df)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1d9cd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup tokenizer with special tokens\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer = add_special_tokens(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c56d3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(30526, 128, padding_idx=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resize model embeddings to match new tokenizer size\n",
    "base_model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e04f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare PyTorch datasets\n",
    "train_dataset = Dataset.from_pandas(train_df[['marked_text', 'label']])\n",
    "test_dataset = Dataset.from_pandas(test_df[['marked_text', 'label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd55b726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da278e11bae2479ba25811dc9a99ecd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/592 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d2cd95220a4febaa8c23039b5fa148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/149 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize\n",
    "train_tokenized = train_dataset.map(lambda x: tokenize_function(x, tokenizer, max_length=256), batched=True)\n",
    "test_tokenized = test_dataset.map(lambda x: tokenize_function(x, tokenizer, max_length=256), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1ed086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set format for PyTorch\n",
    "train_tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50803ee7",
   "metadata": {},
   "source": [
    "BERT Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0ae50e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom model with span pooling\n",
    "model = BertRC(\n",
    "    model_name=model_name,\n",
    "    tokenizer=tokenizer,\n",
    "    num_labels=2,\n",
    "    class_weights=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9698dc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30526, 128, padding_idx=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resize model embeddings to match new tokenizer size\n",
    "model.backbone.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00d7bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_save_path,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    greater_is_better=True,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to=[],\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2fb7e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Satyam\\AppData\\Local\\Temp\\ipykernel_10652\\2186443392.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=test_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93471464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Satyam\\Downloads\\pituitary_adenoma\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='222' max='222' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [222/222 00:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.629100</td>\n",
       "      <td>1.053537</td>\n",
       "      <td>0.939597</td>\n",
       "      <td>0.484429</td>\n",
       "      <td>0.939597</td>\n",
       "      <td>0.910336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.773500</td>\n",
       "      <td>1.372565</td>\n",
       "      <td>0.939597</td>\n",
       "      <td>0.484429</td>\n",
       "      <td>0.939597</td>\n",
       "      <td>0.910336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.917000</td>\n",
       "      <td>1.504516</td>\n",
       "      <td>0.939597</td>\n",
       "      <td>0.484429</td>\n",
       "      <td>0.939597</td>\n",
       "      <td>0.910336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Satyam\\Downloads\\pituitary_adenoma\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Satyam\\Downloads\\pituitary_adenoma\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=222, training_loss=0.7861502449791711, metrics={'train_runtime': 36.6479, 'train_samples_per_second': 48.461, 'train_steps_per_second': 6.058, 'total_flos': 0.0, 'train_loss': 0.7861502449791711, 'epoch': 3.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9c2fedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Satyam\\Downloads\\pituitary_adenoma\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results:\n",
      "loss: 1.0535\n",
      "accuracy: 0.9396\n",
      "f1_macro: 0.4844\n",
      "f1_micro: 0.9396\n",
      "f1_weighted: 0.9103\n",
      "runtime: 0.5829\n",
      "samples_per_second: 255.5970\n",
      "steps_per_second: 17.1540\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "eval_results = trainer.evaluate(test_tokenized)\n",
    "print(\"\\nTest Results:\")\n",
    "for metric, value in eval_results.items():\n",
    "    if not metric.startswith('eval_'):\n",
    "        continue\n",
    "    clean_metric = metric.replace('eval_', '')\n",
    "    print(f\"{clean_metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7cd035a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved to ../models/bert_models/\n"
     ]
    }
   ],
   "source": [
    "# Save the final model\n",
    "trainer.save_model(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "print(f\"\\nModel saved to {model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
