{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb4652a",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c805a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback, set_seed\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import our modules\n",
    "import sys\n",
    "import os\n",
    "\n",
    "utils_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'utils'))\n",
    "models_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'models'))\n",
    "\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.insert(0, utils_path)\n",
    "if models_path not in sys.path:\n",
    "    sys.path.insert(0, models_path)\n",
    "\n",
    "from utils import load_data, prepare_all_samples, get_entity_date_pairs, calculate_metrics\n",
    "from bert_training import create_training_pairs, handle_class_imbalance, add_special_tokens, tokenize_function, compute_metrics, build_gold_lookup, get_label_for_pair\n",
    "from bert_extractor import preprocess_input, bert_extraction, mark_entities_full_text\n",
    "from bert_model import BertRC\n",
    "from relative_date_extractor import add_relative_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e11a1e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e368136f",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b69680b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 records\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = load_data(\"../data/medcat_trainer_dataset.csv\")\n",
    "print(f\"Loaded {len(df)} records\")\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af8e36d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added relative dates\n"
     ]
    }
   ],
   "source": [
    "#Add relative dates if not already added via MedCAT trainer \n",
    "if 'relative_dates_json' not in df.columns:\n",
    "    df = add_relative_dates(df)\n",
    "    print(\"Added relative dates\")\n",
    "else:\n",
    "    print(\"Relative dates already present, skipping extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54df7365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect df to check that relative dates have been added\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0fc9f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 5 samples\n"
     ]
    }
   ],
   "source": [
    "# Prepare all samples\n",
    "samples = prepare_all_samples(df)\n",
    "print(f\"Prepared {len(samples)} samples\")\n",
    "#samples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094065cf",
   "metadata": {},
   "source": [
    "Model & Data Preparation for Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "597c91cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load base model and tokenizer\n",
    "model_name = \"google/bert_uncased_L-2_H-128_A-2\"\n",
    "#model_name = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba264bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created 756 training pairs\n"
     ]
    }
   ],
   "source": [
    "# Create training pairs using best approach\n",
    "processed_df = create_training_pairs(samples)\n",
    "print(f\"\\nCreated {len(processed_df)} training pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30358a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: tensor([0.1164, 1.8836])\n"
     ]
    }
   ],
   "source": [
    "# Handle class imbalance\n",
    "balanced_df, class_weights = handle_class_imbalance(processed_df, method='weighted')\n",
    "print(f\"Class weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d411c840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 604, Test: 152\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "train_df, test_df = train_test_split(balanced_df, test_size=0.2, random_state=42, stratify=balanced_df['label'])\n",
    "print(f\"Train: {len(train_df)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1d9cd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup tokenizer with special tokens\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer = add_special_tokens(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c56d3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(30526, 128, padding_idx=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resize model embeddings to match new tokenizer size\n",
    "base_model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e04f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare PyTorch datasets\n",
    "train_dataset = Dataset.from_pandas(train_df[['marked_text', 'label']])\n",
    "test_dataset = Dataset.from_pandas(test_df[['marked_text', 'label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd55b726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e34efae1ad42c39cc411d2792574db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/604 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac5726ddbd14b9fa03c4b7c4c9fa793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize\n",
    "train_tokenized = train_dataset.map(lambda x: tokenize_function(x, tokenizer, max_length=256), batched=True)\n",
    "test_tokenized = test_dataset.map(lambda x: tokenize_function(x, tokenizer, max_length=256), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1ed086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set format for PyTorch\n",
    "train_tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50803ee7",
   "metadata": {},
   "source": [
    "BERT Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0ae50e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom model with span pooling\n",
    "model = BertRC(\n",
    "    model_name=model_name,\n",
    "    tokenizer=tokenizer,\n",
    "    num_labels=2,\n",
    "    class_weights=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9698dc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30526, 128, padding_idx=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resize model embeddings to match new tokenizer size\n",
    "model.backbone.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00d7bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert_rc_results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    greater_is_better=True,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to=[],\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2fb7e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Satyam\\AppData\\Local\\Temp\\ipykernel_22296\\2186443392.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=test_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93471464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Satyam\\Downloads\\pituitary_adenoma\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='228' max='228' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [228/228 00:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.599000</td>\n",
       "      <td>0.985021</td>\n",
       "      <td>0.940789</td>\n",
       "      <td>0.484746</td>\n",
       "      <td>0.940789</td>\n",
       "      <td>0.912087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.723700</td>\n",
       "      <td>1.422796</td>\n",
       "      <td>0.940789</td>\n",
       "      <td>0.484746</td>\n",
       "      <td>0.940789</td>\n",
       "      <td>0.912087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.940500</td>\n",
       "      <td>1.560878</td>\n",
       "      <td>0.940789</td>\n",
       "      <td>0.484746</td>\n",
       "      <td>0.940789</td>\n",
       "      <td>0.912087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Satyam\\Downloads\\pituitary_adenoma\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Satyam\\Downloads\\pituitary_adenoma\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=228, training_loss=0.740918937482332, metrics={'train_runtime': 35.7328, 'train_samples_per_second': 50.71, 'train_steps_per_second': 6.381, 'total_flos': 0.0, 'train_loss': 0.740918937482332, 'epoch': 3.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9c2fedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Satyam\\Downloads\\pituitary_adenoma\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results:\n",
      "loss: 0.9850\n",
      "accuracy: 0.9408\n",
      "f1_macro: 0.4847\n",
      "f1_micro: 0.9408\n",
      "f1_weighted: 0.9121\n",
      "runtime: 0.4319\n",
      "samples_per_second: 351.9570\n",
      "steps_per_second: 23.1550\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "eval_results = trainer.evaluate(test_tokenized)\n",
    "print(\"\\nTest Results:\")\n",
    "for metric, value in eval_results.items():\n",
    "    if not metric.startswith('eval_'):\n",
    "        continue\n",
    "    clean_metric = metric.replace('eval_', '')\n",
    "    print(f\"{clean_metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cd035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "trainer.save_model(\"./bert_rc_final_model\")\n",
    "tokenizer.save_pretrained(\"./bert_rc_final_model\")\n",
    "print(\"\\nModel saved to ./bert_rc_final_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
