{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb4652a",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c805a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback, set_seed\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import our modules\n",
    "import sys\n",
    "import os\n",
    "\n",
    "utils_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'utils'))\n",
    "models_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'models'))\n",
    "\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.insert(0, utils_path)\n",
    "if models_path not in sys.path:\n",
    "    sys.path.insert(0, models_path)\n",
    "\n",
    "from general_utils import load_data, prepare_all_samples, get_entity_date_pairs, calculate_metrics\n",
    "from bert_training_utils import create_training_pairs, handle_class_imbalance, add_special_tokens, tokenize_function, compute_metrics, build_gold_lookup, get_label_for_pair\n",
    "from bert_extractor_utils import preprocess_input, mark_entities_full_text\n",
    "from bert_model import BertRC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e368136f",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b69680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = load_data(\"../data/training_dataset_synthetic.csv\")\n",
    "print(f\"Loaded {len(df)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef7e0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fc9f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare all samples\n",
    "samples = prepare_all_samples(df)\n",
    "print(f\"Prepared {len(samples)} samples\")\n",
    "#samples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094065cf",
   "metadata": {},
   "source": [
    "Model & Data Preparation for Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11a1e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f5eddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set path to save model\n",
    "model_save_path = '../models/bert_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382400c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose model to use - any BERT model from HuggingFace can be used, see: https://huggingface.co/google-bert\n",
    "\n",
    "model_name = \"google/bert_uncased_L-2_H-128_A-2\" #2 layers, 128 hidden dim, 2 attention heads\n",
    "#model_name = \"google-bert/bert-base-uncased\" #12 layers, 768 hidden dim, 12 attention heads\n",
    "#model_name = \"google-bert/bert-base-cased\" #12 layers, 768 hidden dim, 12 attention heads\n",
    "#model_name = \"prajjwal1/bert-tiny\"  # 4.4M parameters, 2 layers, 128 hidden dim\n",
    "#model_name = \"distilroberta-base\"  # ~82M parameters, 6 layers, 768 hidden dim\n",
    "#model_name = \"boltuix/EntityBERT\"\n",
    "#model_name - \"yikuan8/Clinical-Longformer\"\n",
    "#model_name = \"SpanBERT/spanbert-base-cased\"  # 110M parameters, 12 layers, 768 hidden dim\n",
    "#model_name = \"allenai/biomed_roberta_base\"  # 125M parameters, 12 layers, 768 hidden dim\n",
    "#model_name = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"  # 125M parameters, 12 layers, 768 hidden dim\n",
    "#model_name = \"../models/PubmedBERTbase-MimicSmall-EntityBERT/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba264bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training pairs\n",
    "processed_df = create_training_pairs(samples)\n",
    "print(f\"\\nCreated {len(processed_df)} training pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30358a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle class imbalance\n",
    "balanced_df, class_weights = handle_class_imbalance(processed_df, method='weighted')\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "\n",
    "print(\"\\nAfter balancing:\")\n",
    "print(balanced_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d411c840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "train_df, test_df = train_test_split(balanced_df, test_size=0.2, random_state=42, stratify=balanced_df['label'])\n",
    "print(f\"Train: {len(train_df)}, Test: {len(test_df)}\")\n",
    "\n",
    "print(\"\\nTrain set distribution:\")\n",
    "print(train_df['label'].value_counts())\n",
    "print(\"\\nTest set distribution:\") \n",
    "print(test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d9cd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup tokenizer with special tokens\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer = add_special_tokens(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e04f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare PyTorch datasets\n",
    "train_dataset = Dataset.from_pandas(train_df[['marked_text', 'label']])\n",
    "test_dataset = Dataset.from_pandas(test_df[['marked_text', 'label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd55b726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "train_tokenized = train_dataset.map(lambda x: tokenize_function(x, tokenizer, max_length=256), batched=True)\n",
    "test_tokenized = test_dataset.map(lambda x: tokenize_function(x, tokenizer, max_length=256), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ed086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set format for PyTorch\n",
    "train_tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50803ee7",
   "metadata": {},
   "source": [
    "BERT Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ae50e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom model with span pooling\n",
    "# Note embeddings are re-sized within bert_model.py so doesn't need to be manually done here\n",
    "model = BertRC(\n",
    "    model_name=model_name,\n",
    "    tokenizer=tokenizer,\n",
    "    num_labels=2,\n",
    "    class_weights=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8380545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or alternatively use the BERT model as is - note you should only use one of these options\n",
    "#model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "#model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20ceb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm model type\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d7bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_save_path,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    metric_for_best_model=\"eval_positive_f1\",\n",
    "    greater_is_better=True,\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_ratio=0.05,\n",
    "    weight_decay=0.01,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to=[],\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fb7e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=test_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93471464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04a79a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss and training curves\n",
    "logs = pd.DataFrame(trainer.state.log_history)\n",
    "\n",
    "# Training loss per step\n",
    "train_loss = logs[logs.loss.notna()][[\"step\",\"loss\"]]\n",
    "train_loss.plot(x=\"step\", y=\"loss\", title=\"Training Loss\"); plt.show()\n",
    "\n",
    "# Eval loss/metrics per eval\n",
    "eval_logs = logs[logs.eval_loss.notna()]\n",
    "# Plot loss and overall metrics\n",
    "eval_logs.plot(x=\"epoch\", y=[\"eval_loss\",\"eval_f1_macro\",\"eval_f1_weighted\"], \n",
    "               title=\"Overall Metrics\"); plt.show()\n",
    "\n",
    "# Plot positive class metrics separately\n",
    "eval_logs.plot(x=\"epoch\", \n",
    "               y=[\"eval_positive_precision\",\"eval_positive_recall\",\"eval_positive_f1\"],\n",
    "               title=\"Positive Class Metrics\"); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd8869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "eval_results = trainer.evaluate(test_tokenized)\n",
    "print(\"\\nTest Results:\")\n",
    "print(\"\\nOverall Metrics:\")\n",
    "for metric in ['loss', 'accuracy', 'f1_macro', 'f1_weighted', 'f1_micro']:\n",
    "    print(f\"{metric}: {eval_results[f'eval_{metric}']:.4f}\")\n",
    "\n",
    "print(\"\\nPositive Class Metrics:\")\n",
    "for metric in ['positive_precision', 'positive_recall', 'positive_f1']:\n",
    "    print(f\"{metric}: {eval_results[f'eval_{metric}']:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(f\"True Positives: {eval_results['eval_true_positives']}\")\n",
    "print(f\"False Positives: {eval_results['eval_false_positives']}\")\n",
    "print(f\"True Negatives: {eval_results['eval_true_negatives']}\")\n",
    "print(f\"False Negatives: {eval_results['eval_false_negatives']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cd035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "trainer.save_model(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "print(f\"\\nModel saved to {model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
