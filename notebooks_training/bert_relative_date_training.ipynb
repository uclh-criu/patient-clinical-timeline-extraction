{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba582cea",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce83b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments, set_seed\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# Import our modules\n",
    "utils_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'utils'))\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.insert(0, utils_path)\n",
    "\n",
    "from general_utils import load_data\n",
    "from bert_training_utils import handle_class_imbalance\n",
    "from bert_relative_date_utils import create_token_label_dataset, upsample_relative_date_sequences, compute_token_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952dba0d",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ded0f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = load_data(\"../data/training_dataset.csv\")\n",
    "print(f\"Loaded {len(df)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94f4980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect df\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ff494",
   "metadata": {},
   "source": [
    "Model & Data Preparation for Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22625780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f8b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set path to save model\n",
    "model_save_path = '../models/bert_model_relative_dates/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab91fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose model to use - any BERT model from HuggingFace can be used, see: https://huggingface.co/google-bert\n",
    "\n",
    "model_name = \"google/bert_uncased_L-2_H-128_A-2\" #2 layers, 128 hidden dim, 2 attention heads\n",
    "#model_name = \"distilbert/distilroberta-base\"  # ~82M parameters, 6 layers, 768 hidden dim\n",
    "#model_name = \"SpanBERT/spanbert-base-cased\"  # 110M parameters, 12 layers, 768 hidden dim\n",
    "#model_name = \"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext\"  # 125M parameters, 12 layers, 768 hidden dim\n",
    "\n",
    "\n",
    "#model_name = \"google-bert/bert-base-uncased\" #12 layers, 768 hidden dim, 12 attention heads\n",
    "#model_name = \"google-bert/bert-base-cased\" #12 layers, 768 hidden dim, 12 attention heads\n",
    "#model_name = \"prajjwal1/bert-tiny\"  # 4.4M parameters, 2 layers, 128 hidden dim\n",
    "#model_name = \"boltuix/EntityBERT\"\n",
    "#model_name - \"yikuan8/Clinical-Longformer\"\n",
    "#model_name = \"allenai/biomed_roberta_base\"  # 125M parameters, 12 layers, 768 hidden dim\n",
    "#model_name = \"../models/PubmedBERTbase-MimicSmall-EntityBERT/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3553a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#tokenizer = add_special_tokens(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0c24e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Token-Level Dataset\n",
    "print(\"Creating token-level dataset...\")\n",
    "examples = create_token_label_dataset(df, tokenizer)\n",
    "dataset = Dataset.from_list(examples)\n",
    "\n",
    "print(f\"Prepared {len(dataset)} samples\")\n",
    "\n",
    "counts = Counter([l for ex in examples for l in ex[\"labels\"]])\n",
    "print(f\"Counts of labels: {counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364a3282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample positive examples\n",
    "examples = upsample_relative_date_sequences(examples, factor=3)\n",
    "\n",
    "counts = Counter([l for ex in examples for l in ex[\"labels\"]])\n",
    "print(f\"Counts of labels: {counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d709cad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to huggingFace dataset\n",
    "dataset = Dataset.from_list(examples)\n",
    "print(f\"Prepared {len(dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330fd93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting\n",
    "train_dataset, temp_dataset = dataset.train_test_split(test_size=0.2, seed=42).values()\n",
    "val_dataset, test_dataset = temp_dataset.train_test_split(test_size=0.5, seed=42).values()\n",
    "\n",
    "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f5a6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "num_labels = 3  # O, B-RELDATE, I-RELDATE\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d333642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_save_path,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    num_train_epochs=6,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_ratio=0.05,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to=[],\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c004cd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_token_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762ce283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "print(\"Starting training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76084933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"Evaluating on test set...\")\n",
    "results = trainer.evaluate(test_dataset)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f434382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "trainer.save_model(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "print(f\"\\nModel saved to {model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
