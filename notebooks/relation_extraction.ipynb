{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42bf8839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import math\n",
    "import random\n",
    "from collections import Counter\n",
    "from typing import List, Dict\n",
    "import ast\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    "    set_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef260553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set seeds\n",
    "set_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f61b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "data = pd.read_csv(\"../data/synthetic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8574e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data formatting function\n",
    "\n",
    "def process_row(row):\n",
    "    text = row[\"note\"]\n",
    "\n",
    "    disorders = ast.literal_eval(row[\"extracted_disorders\"])\n",
    "    dates = ast.literal_eval(row[\"formatted_dates\"])\n",
    "    gold = ast.literal_eval(row[\"relationship_gold\"])\n",
    "\n",
    "    # Build lookup for gold relations: (disorder_pos, date_pos) -> relation_type\n",
    "    gold_map = {}\n",
    "    for g in gold:\n",
    "        date_pos = g[\"date_position\"]\n",
    "        for diag in g.get(\"diagnoses\", []):\n",
    "            gold_map[(diag[\"position\"], date_pos)] = \"diagnosis_date\"  # <-- adjust relation type if multiple types\n",
    "\n",
    "    samples = []\n",
    "    for d in disorders:\n",
    "        d_start, d_end = d[\"start\"], d[\"end\"]\n",
    "        disorder_text = text[d_start:d_end]\n",
    "\n",
    "        for dt in dates:\n",
    "            dt_start = dt.get(\"start\", None)\n",
    "            if dt_start is None:\n",
    "                dt_start = text.find(dt[\"original\"])\n",
    "            dt_end = dt_start + len(dt[\"original\"])\n",
    "            date_text = text[dt_start:dt_end]\n",
    "\n",
    "            # Label: check if pair is in gold_map\n",
    "            key = (d_start, dt_start)\n",
    "            label = gold_map.get(key, \"no_relation\")\n",
    "\n",
    "            # Insert entity markers (insert later span first)\n",
    "            marked = text\n",
    "            for span, token1, token2, ent_text, span_end in sorted(\n",
    "                [(d_start, \"[E1]\", \"[/E1]\", disorder_text, d_end),\n",
    "                 (dt_start, \"[E2]\", \"[/E2]\", date_text, dt_end)],\n",
    "                reverse=True\n",
    "            ):\n",
    "                marked = marked[:span] + f\"{token1} {ent_text} {token2}\" + marked[span_end:]\n",
    "\n",
    "            samples.append({\n",
    "                \"text\": text,\n",
    "                \"marked_text\": marked,\n",
    "                \"ent1_start\": d_start, \"ent1_end\": d_end,\n",
    "                \"ent2_start\": dt_start, \"ent2_end\": dt_end,\n",
    "                \"label\": label\n",
    "            })\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1c6f9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>marked_text</th>\n",
       "      <th>ent1_start</th>\n",
       "      <th>ent1_end</th>\n",
       "      <th>ent2_start</th>\n",
       "      <th>ent2_end</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "      <td>57</td>\n",
       "      <td>63</td>\n",
       "      <td>311</td>\n",
       "      <td>326</td>\n",
       "      <td>diagnosis_date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "      <td>57</td>\n",
       "      <td>63</td>\n",
       "      <td>587</td>\n",
       "      <td>602</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "      <td>410</td>\n",
       "      <td>427</td>\n",
       "      <td>311</td>\n",
       "      <td>326</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "      <td>410</td>\n",
       "      <td>427</td>\n",
       "      <td>587</td>\n",
       "      <td>602</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "      <td>491</td>\n",
       "      <td>511</td>\n",
       "      <td>311</td>\n",
       "      <td>326</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Ultrasound (30nd Jun 2024): no significant fin...   \n",
       "1  Ultrasound (30nd Jun 2024): no significant fin...   \n",
       "2  Ultrasound (30nd Jun 2024): no significant fin...   \n",
       "3  Ultrasound (30nd Jun 2024): no significant fin...   \n",
       "4  Ultrasound (30nd Jun 2024): no significant fin...   \n",
       "\n",
       "                                         marked_text  ent1_start  ent1_end  \\\n",
       "0  Ultrasound (30nd Jun 2024): no significant fin...          57        63   \n",
       "1  Ultrasound (30nd Jun 2024): no significant fin...          57        63   \n",
       "2  Ultrasound (30nd Jun 2024): no significant fin...         410       427   \n",
       "3  Ultrasound (30nd Jun 2024): no significant fin...         410       427   \n",
       "4  Ultrasound (30nd Jun 2024): no significant fin...         491       511   \n",
       "\n",
       "   ent2_start  ent2_end           label  \n",
       "0         311       326  diagnosis_date  \n",
       "1         587       602     no_relation  \n",
       "2         311       326     no_relation  \n",
       "3         587       602     no_relation  \n",
       "4         311       326     no_relation  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explode dataset into pairs\n",
    "all_samples = []\n",
    "for _, row in data.iterrows():\n",
    "    all_samples.extend(process_row(row))\n",
    "\n",
    "processed_df = pd.DataFrame(all_samples)\n",
    "processed_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57bb4c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define labels\n",
    "label_list = [\"no_relation\", \"diagnosis_date\"]\n",
    "label2id = {lbl: i for i, lbl in enumerate(label_list)}\n",
    "id2label = {i: lbl for lbl, i in label2id.items()}\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0afed2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>marked_text</th>\n",
       "      <th>ent1_start</th>\n",
       "      <th>ent1_end</th>\n",
       "      <th>ent2_start</th>\n",
       "      <th>ent2_end</th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "      <td>57</td>\n",
       "      <td>63</td>\n",
       "      <td>311</td>\n",
       "      <td>326</td>\n",
       "      <td>diagnosis_date</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "      <td>57</td>\n",
       "      <td>63</td>\n",
       "      <td>587</td>\n",
       "      <td>602</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "      <td>410</td>\n",
       "      <td>427</td>\n",
       "      <td>311</td>\n",
       "      <td>326</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "      <td>410</td>\n",
       "      <td>427</td>\n",
       "      <td>587</td>\n",
       "      <td>602</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "      <td>491</td>\n",
       "      <td>511</td>\n",
       "      <td>311</td>\n",
       "      <td>326</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Ultrasound (30nd Jun 2024): no significant fin...   \n",
       "1  Ultrasound (30nd Jun 2024): no significant fin...   \n",
       "2  Ultrasound (30nd Jun 2024): no significant fin...   \n",
       "3  Ultrasound (30nd Jun 2024): no significant fin...   \n",
       "4  Ultrasound (30nd Jun 2024): no significant fin...   \n",
       "\n",
       "                                         marked_text  ent1_start  ent1_end  \\\n",
       "0  Ultrasound (30nd Jun 2024): no significant fin...          57        63   \n",
       "1  Ultrasound (30nd Jun 2024): no significant fin...          57        63   \n",
       "2  Ultrasound (30nd Jun 2024): no significant fin...         410       427   \n",
       "3  Ultrasound (30nd Jun 2024): no significant fin...         410       427   \n",
       "4  Ultrasound (30nd Jun 2024): no significant fin...         491       511   \n",
       "\n",
       "   ent2_start  ent2_end           label  label_id  \n",
       "0         311       326  diagnosis_date         1  \n",
       "1         587       602     no_relation         0  \n",
       "2         311       326     no_relation         0  \n",
       "3         587       602     no_relation         0  \n",
       "4         311       326     no_relation         0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply labels\n",
    "processed_df[\"label_id\"] = processed_df[\"label\"].map(label2id)\n",
    "processed_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad0ef1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['marked_text', 'label_id'],\n",
       "    num_rows: 1242\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dataset\n",
    "dataset = Dataset.from_pandas(processed_df[[\"marked_text\", \"label_id\"]])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8be13d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train/test split\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6b19070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenizer with special tokens (+ model name)\n",
    "model_name = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "special_tokens = {\"additional_special_tokens\": [\"[E1]\", \"[/E1]\", \"[E2]\", \"[/E2]\"]}\n",
    "tokenizer.add_special_tokens(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90d7af66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a78746671f91441392de8376cb61fc8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/993 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b963e845044abbadcea7ee00fc534b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/249 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Tokenization\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch[\"marked_text\"], truncation=True, padding=\"max_length\", max_length=256)\n",
    "\n",
    "tokenized = dataset.map(tokenize_fn, batched=True)\n",
    "\n",
    "tokenized = tokenized.rename_column(\"label_id\", \"labels\")\n",
    "tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1666dc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 214, 1: 35}\n"
     ]
    }
   ],
   "source": [
    "#Look at class distribution\n",
    "unique, counts = np.unique(tokenized[\"test\"][\"labels\"], return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9b49ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(29000, 768, padding_idx=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# Resize embeddings so new tokens are usable\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9846473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Satyam\\AppData\\Local\\Temp\\ipykernel_10912\\3958405703.py:25: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "c:\\Users\\Satyam\\Downloads\\pituitary_adenoma\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [189/189 55:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.415599</td>\n",
       "      <td>0.859438</td>\n",
       "      <td>0.462203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.408040</td>\n",
       "      <td>0.859438</td>\n",
       "      <td>0.462203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.408008</td>\n",
       "      <td>0.859438</td>\n",
       "      <td>0.462203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Satyam\\Downloads\\pituitary_adenoma\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Satyam\\Downloads\\pituitary_adenoma\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=189, training_loss=0.3990698113012566, metrics={'train_runtime': 3380.1347, 'train_samples_per_second': 0.881, 'train_steps_per_second': 0.056, 'total_flos': 391903916958720.0, 'train_loss': 0.3990698113012566, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run training\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d1fd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set and print F1\n",
    "metrics = trainer.evaluate(tokenized[\"test\"])\n",
    "print(\"Test F1 (macro):\", metrics.get(\"f1\", metrics.get(\"f1_macro\")))\n",
    "print(\"All metrics:\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92153e4c",
   "metadata": {},
   "source": [
    "Additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe84dbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tokenized[\"train\"]\n",
    "eval_dataset = tokenized[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eca01f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for computing class weights for weighted CE loss (to handle imbalance)\n",
    "def compute_class_weights(ds: Dataset, n_labels: int):\n",
    "    if len(ds) == 0:\n",
    "        return torch.ones(n_labels)  # neutral\n",
    "    counts = Counter([int(x) for x in ds[\"labels\"]])\n",
    "    total = sum(counts.values())\n",
    "    weights = []\n",
    "    for i in range(n_labels):\n",
    "        # Inverse frequency (scaled): total / (n_labels * count_i)\n",
    "        # Clamp to avoid inf if a class is missing in train set.\n",
    "        c = max(1, counts.get(i, 0))\n",
    "        w = total / (n_labels * c)\n",
    "        weights.append(w)\n",
    "    # Normalize so mean weight ~= 1\n",
    "    mean_w = sum(weights) / len(weights)\n",
    "    weights = [w / mean_w for w in weights]\n",
    "    return torch.tensor(weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08097997",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute class weights\n",
    "class_weights = compute_class_weights(train_dataset, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60642f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom model: Bio_ClinicalBERT + span pooling between markers\n",
    "class BertRC(nn.Module):\n",
    "    \"\"\"\n",
    "    Forward expected inputs (from Trainer):\n",
    "        input_ids:      [B, L]   torch.long\n",
    "        attention_mask: [B, L]   torch.long\n",
    "        labels:         [B]      torch.long\n",
    "\n",
    "    Internals:\n",
    "        last_hidden_state: [B, L, H]\n",
    "        span pooling: mask tokens strictly between [E1]...[/E1] and [E2]...[/E2]\n",
    "                       -> e1_emb, e2_emb: [B, H]\n",
    "        concat: [B, 2H] -> classifier -> logits: [B, num_labels]\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name: str, tokenizer, num_labels: int, class_weights: torch.Tensor = None):\n",
    "        super().__init__()\n",
    "        self.backbone = AutoModel.from_pretrained(model_name)\n",
    "        self.backbone.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "        self.hidden_size = self.backbone.config.hidden_size  # e.g., 768\n",
    "        self.dropout = nn.Dropout(self.backbone.config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(2 * self.hidden_size, num_labels)\n",
    "\n",
    "        # Cache token IDs for markers\n",
    "        self.e1_open_id = tokenizer.convert_tokens_to_ids(\"[E1]\")\n",
    "        self.e1_close_id = tokenizer.convert_tokens_to_ids(\"[/E1]\")\n",
    "        self.e2_open_id = tokenizer.convert_tokens_to_ids(\"[E2]\")\n",
    "        self.e2_close_id = tokenizer.convert_tokens_to_ids(\"[/E2]\")\n",
    "\n",
    "        # Class weights for imbalance\n",
    "        if class_weights is not None:\n",
    "            self.register_buffer(\"class_weights\", class_weights)\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "\n",
    "    @staticmethod\n",
    "    def _first_index(mask: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        mask: [B, L] bool\n",
    "        returns: [B] first True index (0 if none)\n",
    "        \"\"\"\n",
    "        # Convert to float and argmax: if no True, argmax returns 0 (handled later)\n",
    "        return mask.float().argmax(dim=1)\n",
    "\n",
    "    def _span_mean(\n",
    "        self,\n",
    "        hidden: torch.Tensor,      # [B, L, H]\n",
    "        input_ids: torch.Tensor,   # [B, L]\n",
    "        open_id: int,\n",
    "        close_id: int,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Mean-pool tokens strictly between open and close markers.\n",
    "        Fallback: if span is empty or markers missing (e.g., truncation), use the open-marker embedding.\n",
    "\n",
    "        returns: [B, H]\n",
    "        \"\"\"\n",
    "        B, L, H = hidden.shape\n",
    "        pos = torch.arange(L, device=hidden.device).unsqueeze(0).expand(B, L)  # [B, L]\n",
    "\n",
    "        open_mask = (input_ids == open_id)    # [B, L]\n",
    "        close_mask = (input_ids == close_id)  # [B, L]\n",
    "\n",
    "        open_idx = self._first_index(open_mask)   # [B]\n",
    "        close_idx = self._first_index(close_mask) # [B]\n",
    "\n",
    "        # span_mask[b, t] = True iff open_idx[b] < t < close_idx[b]\n",
    "        span_mask = (pos > open_idx.unsqueeze(1)) & (pos < close_idx.unsqueeze(1))  # [B, L]\n",
    "\n",
    "        # Pool\n",
    "        denom = span_mask.sum(dim=1, keepdim=True).clamp_min(1)  # [B, 1]\n",
    "        span_sum = (hidden * span_mask.unsqueeze(-1)).sum(dim=1)  # [B, H]\n",
    "        span_mean = span_sum / denom  # [B, H]\n",
    "\n",
    "        # Fallback to open marker embedding if span empty or markers missing\n",
    "        has_tokens = span_mask.any(dim=1, keepdim=True)  # [B, 1] bool\n",
    "        open_emb = (hidden * open_mask.unsqueeze(-1)).sum(dim=1)  # [B, H]\n",
    "        e_emb = torch.where(has_tokens, span_mean, open_emb)      # [B, H]\n",
    "        return e_emb\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "        last_hidden = outputs.last_hidden_state  # [B, L, H]\n",
    "\n",
    "        # Pool entity and date spans\n",
    "        e1_emb = self._span_mean(last_hidden, input_ids, self.e1_open_id, self.e1_close_id)  # [B, H]\n",
    "        e2_emb = self._span_mean(last_hidden, input_ids, self.e2_open_id, self.e2_close_id)  # [B, H]\n",
    "\n",
    "        # Concatenate -> classify\n",
    "        x = torch.cat([e1_emb, e2_emb], dim=-1)  # [B, 2H]\n",
    "        x = self.dropout(x)\n",
    "        logits = self.classifier(x)  # [B, num_labels]\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if hasattr(self, \"class_weights\") and self.class_weights is not None:\n",
    "                loss_fn = nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "            else:\n",
    "                loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "\n",
    "        return {\"loss\": loss, \"logits\": logits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5e5631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics: accuracy + F1s\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1_macro\": f1_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "        \"f1_micro\": f1_score(labels, preds, average=\"micro\", zero_division=0),\n",
    "        \"f1_weighted\": f1_score(labels, preds, average=\"weighted\", zero_division=0),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0867b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "model = BertRC(model_name, tokenizer, num_labels=num_labels, class_weights=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea8a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./rc_results\",\n",
    "    evaluation_strategy=\"epoch\" if len(eval_dataset) > 0 else \"no\",\n",
    "    save_strategy=\"epoch\" if len(eval_dataset) > 0 else \"no\",\n",
    "    load_best_model_at_end=True if len(eval_dataset) > 0 else False,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    greater_is_better=True,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to=[],  # turn off W&B/MLflow by default\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e59f909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset if len(train_dataset) > 0 else None,\n",
    "    eval_dataset=eval_dataset if len(eval_dataset) > 0 else None,\n",
    "    compute_metrics=compute_metrics if len(eval_dataset) > 0 else None,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)] if len(eval_dataset) > 0 else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c12d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model\n",
    "if len(train_dataset) > 0:\n",
    "    trainer.train()\n",
    "    if len(eval_dataset) > 0:\n",
    "        metrics = trainer.evaluate()\n",
    "        print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
