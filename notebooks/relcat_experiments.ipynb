{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61b2cc81",
   "metadata": {},
   "source": [
    "Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17372f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import logging\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "from medcat.cdb import CDB\n",
    "from medcat.config_rel_cat import ConfigRelCAT\n",
    "from medcat.rel_cat import RelCAT\n",
    "from medcat.utils.relation_extraction.base_component import BaseComponent_RelationExtraction\n",
    "from medcat.utils.relation_extraction.bert.model import BaseModel_RelationExtraction\n",
    "from medcat.utils.relation_extraction.bert.config import BaseConfig_RelationExtraction\n",
    "from medcat.utils.relation_extraction.tokenizer import BaseTokenizerWrapper_RelationExtraction\n",
    "\n",
    "import sys, os\n",
    "utils_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'utils'))\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.insert(0, utils_path)\n",
    "\n",
    "from utils import load_data\n",
    "from relative_date_extractor import add_relative_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83bdbf24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 records\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>note_text</th>\n",
       "      <th>entities_json</th>\n",
       "      <th>dates_json</th>\n",
       "      <th>relative_dates_json</th>\n",
       "      <th>links_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26461</td>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "      <td>[{'id': 308244, 'value': 'history of meningiti...</td>\n",
       "      <td>[{'id': 308320, 'value': '30nd Jun 2024', 'sta...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'date': '12nd Sep 2024', 'entity': 'pituitar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26462</td>\n",
       "      <td>Labs (27th Sep 2024): anemia. resolving  Skin:...</td>\n",
       "      <td>[{'id': 308371, 'value': 'lesions', 'cui': '52...</td>\n",
       "      <td>[{'id': 308581, 'value': '22/11/24', 'start': ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'date': '27th Sep 2024', 'entity': 'anemia',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26463</td>\n",
       "      <td>URGENT REVIEW (2024-10-04): cough. suspect ost...</td>\n",
       "      <td>[{'id': 308886, 'value': 'frequent urination',...</td>\n",
       "      <td>[{'id': 308940, 'value': '2024-10-04', 'start'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'date': '2024-10-04', 'entity': 'cough', 'da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26464</td>\n",
       "      <td>URGENT REVIEW (13rd Feb 2025) MRI of the brain...</td>\n",
       "      <td>[{'id': 308951, 'value': 'multiple_sclerosis',...</td>\n",
       "      <td>[{'id': 308996, 'value': '05-03-2025', 'start'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'date': '13rd Feb 2025', 'entity': 'visual',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26465</td>\n",
       "      <td>New pt((18/11/24)): pt presents with nausea/vo...</td>\n",
       "      <td>[{'id': 308998, 'value': 'history of neoplasm ...</td>\n",
       "      <td>[{'id': 309070, 'value': '18/11/24', 'start': ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'date': '18/11/24', 'entity': 'nausea/vomiti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                          note_text  \\\n",
       "0   26461  Ultrasound (30nd Jun 2024): no significant fin...   \n",
       "1   26462  Labs (27th Sep 2024): anemia. resolving  Skin:...   \n",
       "2   26463  URGENT REVIEW (2024-10-04): cough. suspect ost...   \n",
       "3   26464  URGENT REVIEW (13rd Feb 2025) MRI of the brain...   \n",
       "4   26465  New pt((18/11/24)): pt presents with nausea/vo...   \n",
       "\n",
       "                                       entities_json  \\\n",
       "0  [{'id': 308244, 'value': 'history of meningiti...   \n",
       "1  [{'id': 308371, 'value': 'lesions', 'cui': '52...   \n",
       "2  [{'id': 308886, 'value': 'frequent urination',...   \n",
       "3  [{'id': 308951, 'value': 'multiple_sclerosis',...   \n",
       "4  [{'id': 308998, 'value': 'history of neoplasm ...   \n",
       "\n",
       "                                          dates_json relative_dates_json  \\\n",
       "0  [{'id': 308320, 'value': '30nd Jun 2024', 'sta...                  []   \n",
       "1  [{'id': 308581, 'value': '22/11/24', 'start': ...                  []   \n",
       "2  [{'id': 308940, 'value': '2024-10-04', 'start'...                  []   \n",
       "3  [{'id': 308996, 'value': '05-03-2025', 'start'...                  []   \n",
       "4  [{'id': 309070, 'value': '18/11/24', 'start': ...                  []   \n",
       "\n",
       "                                          links_json  \n",
       "0  [{'date': '12nd Sep 2024', 'entity': 'pituitar...  \n",
       "1  [{'date': '27th Sep 2024', 'entity': 'anemia',...  \n",
       "2  [{'date': '2024-10-04', 'entity': 'cough', 'da...  \n",
       "3  [{'date': '13rd Feb 2025', 'entity': 'visual',...  \n",
       "4  [{'date': '18/11/24', 'entity': 'nausea/vomiti...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "original_df = load_data(\"../data/medcat_trainer_dataset.csv\")\n",
    "print(f\"Loaded {len(original_df)} records\")\n",
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d74adce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative dates already present, skipping extraction\n"
     ]
    }
   ],
   "source": [
    "#Add relative dates if not already added via MedCAT trainer \n",
    "if 'relative_dates_json' not in original_df.columns:\n",
    "    original_df = add_relative_dates(original_df)\n",
    "    print(\"Added relative dates\")\n",
    "else:\n",
    "    print(\"Relative dates already present, skipping extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61acc0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert marker function\n",
    "def insert_marker(txt, start, end, tag_open, tag_close):\n",
    "                    return txt[:start] + tag_open + txt[start:end] + tag_close + txt[end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8e2fe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 741 date-entity pairs (including relative dates)\n"
     ]
    }
   ],
   "source": [
    "# Create dataset for training\n",
    "rows = []\n",
    "\n",
    "for _, row in original_df.iterrows():\n",
    "    doc_id = row[\"doc_id\"]\n",
    "    text = row[\"note_text\"]\n",
    "    \n",
    "    # Parse the JSON columns - handle both string and already-parsed cases\n",
    "    entities = row[\"entities_json\"] if isinstance(row[\"entities_json\"], list) else json.loads(row[\"entities_json\"])\n",
    "    dates = row[\"dates_json\"] if isinstance(row[\"dates_json\"], list) else json.loads(row[\"dates_json\"])\n",
    "    relative_dates = row[\"relative_dates_json\"] if isinstance(row[\"relative_dates_json\"], list) else json.loads(row[\"relative_dates_json\"]) if \"relative_dates_json\" in row else []\n",
    "    \n",
    "    # Combine absolute and relative dates\n",
    "    all_dates = dates + relative_dates\n",
    "    \n",
    "    # Get original links for labeling\n",
    "    links = row[\"links_json\"] if isinstance(row[\"links_json\"], list) else json.loads(row[\"links_json\"])\n",
    "    \n",
    "    # Build link pairs from validated links - match by IDs, not values\n",
    "    link_pairs = {tuple(sorted([str(L[\"date_id\"]), str(L[\"entity_id\"])])) for L in links}\n",
    "    \n",
    "    # Create pairs for all date-entity combinations\n",
    "    for date in all_dates:\n",
    "        for entity in entities:\n",
    "            # Use IDs for matching, not values\n",
    "            date_id = str(date[\"id\"])\n",
    "            entity_id = str(entity[\"id\"])\n",
    "            \n",
    "            # Determine label (both absolute and relative dates can have links)\n",
    "            if tuple(sorted([date_id, entity_id])) in link_pairs:\n",
    "                label, label_id = \"LINK\", 1\n",
    "            else:\n",
    "                label, label_id = \"NO_LINK\", 0\n",
    "            \n",
    "            # Insert markers\n",
    "            s1, e1 = date.get(\"start\"), date.get(\"end\")\n",
    "            s2, e2 = entity.get(\"start\"), entity.get(\"end\")\n",
    "            \n",
    "            if s1 is not None and s2 is not None:\n",
    "                if s1 < s2:\n",
    "                    marked = insert_marker(text, s2, e2, \"[s2]\", \"[e2]\")\n",
    "                    marked = insert_marker(marked, s1, e1, \"[s1]\", \"[e1]\")\n",
    "                else:\n",
    "                    marked = insert_marker(text, s1, e1, \"[s2]\", \"[e2]\")\n",
    "                    marked = insert_marker(marked, s2, e2, \"[s1]\", \"[e1]\")\n",
    "            else:\n",
    "                marked = text\n",
    "            \n",
    "            rows.append({\n",
    "                \"relation_token_span_ids\": None,\n",
    "                \"ent1_ent2_start\": (s1, s2),\n",
    "                \"ent1\": date.get(\"value\", \"\"),\n",
    "                \"ent2\": entity.get(\"value\", \"\"),\n",
    "                \"label\": label,\n",
    "                \"label_id\": label_id,\n",
    "                \"ent1_type\": \"DATE\",\n",
    "                \"ent2_type\": \"ENTITY\",\n",
    "                \"ent1_id\": date_id,\n",
    "                \"ent2_id\": entity_id,\n",
    "                \"ent1_cui\": None,\n",
    "                \"ent2_cui\": None,\n",
    "                \"doc_id\": doc_id,\n",
    "                \"text\": marked\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(f\"Created {len(df)} date-entity pairs (including relative dates)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be91d40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect data\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f16571e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>n_entities</th>\n",
       "      <th>n_dates</th>\n",
       "      <th>n_relative_dates</th>\n",
       "      <th>n_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26461</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26462</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26463</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26464</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26465</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  n_entities  n_dates  n_relative_dates  n_links\n",
       "0   26461          64        6                 0        4\n",
       "1   26462          21        7                 0       11\n",
       "2   26463          15        7                 0       12\n",
       "3   26464          11        3                 0        6\n",
       "4   26465          24        3                 0        4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Per-document summary from original data\n",
    "summary = []\n",
    "\n",
    "for _, row in original_df.iterrows():\n",
    "    # Parse the JSON columns - handle both string and already-parsed cases\n",
    "    entities = row[\"entities_json\"] if isinstance(row[\"entities_json\"], list) else json.loads(row[\"entities_json\"])\n",
    "    dates = row[\"dates_json\"] if isinstance(row[\"dates_json\"], list) else json.loads(row[\"dates_json\"])\n",
    "    relative_dates = row[\"relative_dates_json\"] if isinstance(row[\"relative_dates_json\"], list) else json.loads(row[\"relative_dates_json\"]) if \"relative_dates_json\" in row else []\n",
    "    links = row[\"links_json\"] if isinstance(row[\"links_json\"], list) else json.loads(row[\"links_json\"])\n",
    "    \n",
    "    summary.append({\n",
    "        \"doc_id\": row[\"doc_id\"],\n",
    "        \"n_entities\": len(entities),\n",
    "        \"n_dates\": len(dates),\n",
    "        \"n_relative_dates\": len(relative_dates),\n",
    "        \"n_links\": len(links),\n",
    "    })\n",
    "\n",
    "doc_level = pd.DataFrame(summary)\n",
    "doc_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32d00e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>total_pairs</th>\n",
       "      <th>link_pairs</th>\n",
       "      <th>link_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26461</td>\n",
       "      <td>384</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26462</td>\n",
       "      <td>147</td>\n",
       "      <td>11</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26463</td>\n",
       "      <td>105</td>\n",
       "      <td>12</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26464</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26465</td>\n",
       "      <td>72</td>\n",
       "      <td>4</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  total_pairs  link_pairs  link_pct\n",
       "0   26461          384           4       1.0\n",
       "1   26462          147          11       7.5\n",
       "2   26463          105          12      11.4\n",
       "3   26464           33           6      18.2\n",
       "4   26465           72           4       5.6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pair-based stats from the generated df\n",
    "pair_stats = (\n",
    "    df.groupby(\"doc_id\")\n",
    "      .agg(\n",
    "          total_pairs=(\"label\", \"size\"),\n",
    "          link_pairs=(\"label\", lambda s: (s == \"LINK\").sum()),\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "pair_stats[\"link_pct\"] = (100 * pair_stats[\"link_pairs\"] / pair_stats[\"total_pairs\"]).round(1)\n",
    "pair_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce540151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of date-entity pairs is 741\n",
      "total number of links: 37\n",
      "percentage positive class: 5.0%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>n_entities</th>\n",
       "      <th>n_dates</th>\n",
       "      <th>n_relative_dates</th>\n",
       "      <th>n_links</th>\n",
       "      <th>total_pairs</th>\n",
       "      <th>link_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26461</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>384</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26462</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>147</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26463</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>105</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26464</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26465</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>72</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  n_entities  n_dates  n_relative_dates  n_links  total_pairs  \\\n",
       "0   26461          64        6                 0        4          384   \n",
       "1   26462          21        7                 0       11          147   \n",
       "2   26463          15        7                 0       12          105   \n",
       "3   26464          11        3                 0        6           33   \n",
       "4   26465          24        3                 0        4           72   \n",
       "\n",
       "   link_pct  \n",
       "0       1.0  \n",
       "1       7.5  \n",
       "2      11.4  \n",
       "3      18.2  \n",
       "4       5.6  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge stats with doc_level summary\n",
    "doc_level = (\n",
    "    doc_level.merge(pair_stats[[\"doc_id\", \"total_pairs\", \"link_pct\"]], on=\"doc_id\", how=\"left\")\n",
    "             .sort_values(\"doc_id\")\n",
    "             .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Calculate additional metrics\n",
    "total_pairs_overall = len(df)\n",
    "link_total = (df[\"label\"] == \"LINK\").sum()\n",
    "link_pct_overall = 100 * (df[\"label\"] == \"LINK\").mean()\n",
    "\n",
    "print(f\"total number of date-entity pairs is {total_pairs_overall}\")\n",
    "print(f\"total number of links: {link_total}\")\n",
    "print(f\"percentage positive class: {link_pct_overall:.1f}%\")\n",
    "\n",
    "#Look at overall doc level summary\n",
    "doc_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b1d11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset\n",
    "#df.to_csv(\"../data/relcat_training_data.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d7f9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset and save\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "\n",
    "print(f\"Train set: {len(train_df)} samples\")\n",
    "print(f\"Test set: {len(test_df)} samples\")\n",
    "print(\"\\nTrain label distribution:\")\n",
    "print(train_df[\"label\"].value_counts())\n",
    "print(\"\\nTest label distribution:\")\n",
    "print(test_df[\"label\"].value_counts())\n",
    "\n",
    "# Save train and test sets\n",
    "train_df.to_csv(\"../data/relcat_training_data.tsv\", sep=\"\\t\", index=False)\n",
    "test_df.to_csv(\"../data/relcat_test_data.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b97b1e3",
   "metadata": {},
   "source": [
    "Config & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190063fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create RelCAT config and set parameters\n",
    "config = ConfigRelCAT()\n",
    "config.general.log_level = logging.INFO\n",
    "config.general.model_name = \"bert-base-uncased\" # base model that you want to use, we're going to use the HuggingFace bert-base-uncased model\n",
    "\n",
    "#logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404b03da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hidden size, model size and hidden layers\n",
    "config.model.hidden_size= 256\n",
    "config.model.model_size = 2304 # 4096 for llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f98025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further config\n",
    "config.general.cntx_left = 15 # how many tokens to the left of the start entity we select\n",
    "config.general.cntx_right = 15 # how many tokens to the right of the end entity we selecd\n",
    "config.general.window_size = 300 # distance (in characters) between two entities to be considered a relation\n",
    "config.train.nclasses = 2 # number of classes in your medcat export / dataset\n",
    "config.train.nepochs = 3 # number of epochs to train for\n",
    "config.model.freeze_layers = False # whether to freeze the layers of the base model\n",
    "config.general.limit_samples_per_class = 300 # limit the number of training samples per class to this number, to avoid overfitting in unbalanced datasets\n",
    "config.train.batch_size = 32 # batch size\n",
    "config.train.lr = 3e-5\n",
    "config.train.adam_epsilon = 1e-8\n",
    "config.train.adam_weight_decay = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646e1fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create CDB\n",
    "cdb = CDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a25fb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create tokenizer\n",
    "tokenizer = BaseTokenizerWrapper_RelationExtraction.load(tokenizer_path=config.general.model_name,\n",
    "                                                       relcat_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28ce90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add special tokens\n",
    "special_ent_tokens = [\"[s1]\", \"[e1]\", \"[s2]\", \"[e2]\"]\n",
    "tokenizer.hf_tokenizers.add_tokens(special_ent_tokens, special_tokens=True)\n",
    "tokenizer.hf_tokenizers.add_special_tokens({'pad_token': '[PAD]'}) # used in llama tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a46f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add tokens to config\n",
    "config.general.tokenizer_relation_annotation_special_tokens_tags = special_ent_tokens\n",
    "config.general.annotation_schema_tag_ids = tokenizer.hf_tokenizers.convert_tokens_to_ids(special_ent_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11e8338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create RelCAT object and initialize components\n",
    "# if you wish to skip the steps in section 6.1 you can pass the init_model=True arguement to intialize the components with the default ConfigRelCAT settings.\n",
    "relCAT = RelCAT(cdb, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc437ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model configuration\n",
    "model_config = BaseConfig_RelationExtraction.load(pretrained_model_name_or_path=config.general.model_name,\n",
    "                                                 relcat_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2ee74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update vocab size in model config to match tokenizer\n",
    "model_config.hf_model_config.vocab_size = tokenizer.get_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657d3f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the padding idx in the model config and relcat config, this is necesasry as it depends on what tokenizer you use\n",
    "config.model.padding_idx = model_config.pad_token_id = tokenizer.get_pad_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b81f863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = BaseModel_RelationExtraction.load(pretrained_model_name_or_path=config.general.model_name,\n",
    "                                         model_config=model_config,\n",
    "                                         relcat_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4db06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize embeddings to match tokenizer\n",
    "model.hf_model.resize_token_embeddings(len(tokenizer.hf_tokenizers)) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83084dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create component\n",
    "component = BaseComponent_RelationExtraction(tokenizer=tokenizer, config=config)\n",
    "component.model = model\n",
    "component.model_config = model_config\n",
    "component.relcat_config = config\n",
    "component.tokenizer = tokenizer\n",
    "relCAT.component = component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c0514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the dataset we created\n",
    "relCAT.train(\n",
    "    train_csv_path=\"../data/relcat_training_data.tsv\",  \n",
    "    checkpoint_path=\"../models/relcat_models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4343546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "relCAT.save(save_path=\"../models/relcat_models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332aa3d6",
   "metadata": {},
   "source": [
    "Inference & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2d6c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "relCAT = RelCAT.load(\"../models/relcat_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2d50d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv(\"../data/relcat_test_data.tsv\", sep=\"\\t\")\n",
    "print(f\"Loaded test data: {len(test_df)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c1d88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06194e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on all test documents using the same data source as training\n",
    "all_predictions = []\n",
    "\n",
    "test_doc_ids = test_df['doc_id'].unique()\n",
    "\n",
    "for doc_id in test_doc_ids:\n",
    "    # Find the document in medcat_df (same source as training)\n",
    "    doc_row = medcat_df[medcat_df['doc_id'] == doc_id].iloc[0]\n",
    "    \n",
    "    # Parse the same JSON columns used in training\n",
    "    entities = json.loads(doc_row[\"entities_json\"])\n",
    "    dates = json.loads(doc_row[\"dates_json\"])\n",
    "    \n",
    "    # Create annotations in the same format as training\n",
    "    annotations = []\n",
    "    for entity in entities:\n",
    "        annotations.append({\n",
    "            \"value\": entity[\"value\"],\n",
    "            \"cui\": entity.get(\"cui\"),\n",
    "            \"start\": entity.get(\"start\"),\n",
    "            \"end\": entity.get(\"end\")\n",
    "        })\n",
    "    for date in dates:\n",
    "        annotations.append({\n",
    "            \"value\": date[\"value\"],\n",
    "            \"cui\": DATE_CUI,\n",
    "            \"start\": date.get(\"start\"),\n",
    "            \"end\": date.get(\"end\")\n",
    "        })\n",
    "    \n",
    "    try:\n",
    "        # Run inference\n",
    "        output_doc_with_relations = relCAT.predict_text_with_anns(\n",
    "            text=doc_row[\"note_text\"], \n",
    "            annotations=annotations\n",
    "        )\n",
    "        \n",
    "        # Collect results - only keep date-entity pairs\n",
    "        for relation in output_doc_with_relations._.relations:\n",
    "            # Check if this is a date-entity pair (not entity-entity)\n",
    "            if (relation['ent1_text'] in [d['value'] for d in dates] and \n",
    "                relation['ent2_text'] in [e['value'] for e in entities]) or \\\n",
    "               (relation['ent2_text'] in [d['value'] for d in dates] and \n",
    "                relation['ent1_text'] in [e['value'] for e in entities]):\n",
    "                \n",
    "                all_predictions.append({\n",
    "                    'entity_label': relation['ent1_text'],\n",
    "                    'date': relation['ent2_text'],\n",
    "                    'confidence': relation['confidence'],\n",
    "                    'doc_id': doc_id\n",
    "                })\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing document {doc_id}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Processed {len(test_doc_ids)} test documents\")\n",
    "print(f\"Total predictions: {len(all_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208a9a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results\n",
    "print(\"Test Set Results:\")\n",
    "print(f\"Total predictions: {len(all_predictions)}\")\n",
    "\n",
    "# Show first 10 predictions\n",
    "print(\"\\nFirst 10 predictions:\")\n",
    "for i, pred in enumerate(all_predictions[:10]):\n",
    "    print(f\"{i+1}. {pred['entity_label']} -> {pred['date']} (conf: {pred['confidence']:.3f}) [doc: {pred['doc_id']}]\")\n",
    "\n",
    "# Show high confidence predictions\n",
    "high_conf = [p for p in all_predictions if p['confidence'] > 0.7]\n",
    "print(f\"\\nHigh confidence predictions (>0.7): {len(high_conf)}\")\n",
    "for i, pred in enumerate(high_conf[:5]):  # Show first 5\n",
    "    print(f\"{i+1}. {pred['entity_label']} -> {pred['date']} (conf: {pred['confidence']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee40d8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's debug the exact counts\n",
    "print(f\"Total test pairs: {len(test_df)}\")\n",
    "print(f\"Total predictions: {len(all_predictions)}\")\n",
    "\n",
    "# Count how many test pairs were actually predicted\n",
    "predicted_count = 0\n",
    "for _, row in test_df.iterrows():\n",
    "    found = False\n",
    "    for pred in all_predictions:\n",
    "        if (pred['doc_id'] == row['doc_id'] and \n",
    "            ((pred['entity_label'] == row['ent1'] and pred['date'] == row['ent2']) or\n",
    "             (pred['entity_label'] == row['ent2'] and pred['date'] == row['ent1']))):\n",
    "            found = True\n",
    "            break\n",
    "    if found:\n",
    "        predicted_count += 1\n",
    "\n",
    "print(f\"Test pairs that were predicted: {predicted_count}\")\n",
    "print(f\"Test pairs that were NOT predicted: {len(test_df) - predicted_count}\")\n",
    "\n",
    "# Also check if there are predictions for documents not in test set\n",
    "test_doc_ids = set(test_df['doc_id'].unique())\n",
    "pred_doc_ids = set([p['doc_id'] for p in all_predictions])\n",
    "print(f\"Test doc IDs: {test_doc_ids}\")\n",
    "print(f\"Prediction doc IDs: {pred_doc_ids}\")\n",
    "print(f\"Extra predictions (not in test): {len(pred_doc_ids - test_doc_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbb1e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions for all test pairs\n",
    "all_test_predictions = []\n",
    "\n",
    "for _, row in test_df.iterrows():\n",
    "    # Check if this pair was predicted as a link\n",
    "    found = False\n",
    "    for pred in all_predictions:\n",
    "        if (pred['doc_id'] == row['doc_id'] and \n",
    "            ((pred['entity_label'] == row['ent1'] and pred['date'] == row['ent2']) or\n",
    "             (pred['entity_label'] == row['ent2'] and pred['date'] == row['ent1']))):\n",
    "            all_test_predictions.append('LINK')\n",
    "            found = True\n",
    "            break\n",
    "    \n",
    "    if not found:\n",
    "        all_test_predictions.append('NO_LINK')\n",
    "\n",
    "# Now calculate metrics on all test pairs\n",
    "y_true_all = test_df['label'].tolist()\n",
    "y_pred_all = all_test_predictions\n",
    "\n",
    "print(f\"\\nAll Test Pairs Metrics:\")\n",
    "print(f\"Accuracy: {sum(1 for t, p in zip(y_true_all, y_pred_all) if t == p) / len(y_true_all):.3f}\")\n",
    "print(classification_report(y_true_all, y_pred_all, labels=['LINK', 'NO_LINK']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
