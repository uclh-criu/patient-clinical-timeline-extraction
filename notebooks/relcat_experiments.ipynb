{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61b2cc81",
   "metadata": {},
   "source": [
    "Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17372f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import logging\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "from medcat.cdb import CDB\n",
    "from medcat.config_rel_cat import ConfigRelCAT\n",
    "from medcat.rel_cat import RelCAT\n",
    "from medcat.utils.relation_extraction.base_component import BaseComponent_RelationExtraction\n",
    "from medcat.utils.relation_extraction.bert.model import BaseModel_RelationExtraction\n",
    "from medcat.utils.relation_extraction.bert.config import BaseConfig_RelationExtraction\n",
    "from medcat.utils.relation_extraction.tokenizer import BaseTokenizerWrapper_RelationExtraction\n",
    "\n",
    "import sys, os\n",
    "utils_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'utils'))\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.insert(0, utils_path)\n",
    "\n",
    "from medcat_etl import (\n",
    "    DATE_CUI,\n",
    "    get_validated_entities, get_validated_dates, get_validated_links,\n",
    "    id2value_from_items\n",
    ")\n",
    "\n",
    "from relative_date_extractor import add_relative_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "691cb693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MedCAT data\n",
    "with open(\"../data/MedCAT_Export_With_Text_2025-09-11_08_19_37.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f87e83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data with 5 documents\n"
     ]
    }
   ],
   "source": [
    "# Count documents\n",
    "num_docs = sum(len(p.get(\"documents\", [])) for p in data.get(\"projects\", []))\n",
    "print(f\"Loaded data with {num_docs} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cf30c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created MedCAT format dataset with 5 documents\n"
     ]
    }
   ],
   "source": [
    "# Convert medcat data to df with json columns to match other extractors / notebooks\n",
    "medcat_rows = []\n",
    "for project in data.get(\"projects\", []):\n",
    "    for doc in project.get(\"documents\", []):\n",
    "        doc_id = doc.get(\"id\")\n",
    "        text = doc.get(\"text\", \"\")\n",
    "        \n",
    "        # Extract validated entities and dates using medcat_etl.py logic\n",
    "        ents = get_validated_entities(doc, DATE_CUI)\n",
    "        dates = get_validated_dates(doc, DATE_CUI)\n",
    "        links = get_validated_links(doc, DATE_CUI)\n",
    "        \n",
    "        # Convert to JSON format expected by add_relative_dates\n",
    "        entities_json = json.dumps([\n",
    "            {\"id\": e[\"id\"], \"value\": e[\"value\"], \"cui\": e.get(\"cui\"), \"start\": e.get(\"start\"), \"end\": e.get(\"end\")} \n",
    "            for e in ents\n",
    "        ])\n",
    "        dates_json = json.dumps([\n",
    "            {\"id\": d[\"id\"], \"value\": d[\"value\"], \"start\": d.get(\"start\"), \"end\": d.get(\"end\")} \n",
    "            for d in dates\n",
    "        ])\n",
    "        links_json = json.dumps([\n",
    "            {\"date\": next((d[\"value\"] for d in dates if d[\"id\"] == L[\"date_id\"]), \"\"),\n",
    "             \"entity\": next((e[\"value\"] for e in ents if e[\"id\"] == L[\"entity_id\"]), \"\")}\n",
    "            for L in links\n",
    "        ])\n",
    "        \n",
    "        medcat_rows.append({\n",
    "            \"doc_id\": doc_id,\n",
    "            \"note_text\": text,\n",
    "            \"entities_json\": entities_json,\n",
    "            \"dates_json\": dates_json,\n",
    "            \"links_json\": links_json\n",
    "        })\n",
    "\n",
    "medcat_df = pd.DataFrame(medcat_rows)\n",
    "print(f\"Created MedCAT format dataset with {len(medcat_df)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d74adce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added relative dates\n"
     ]
    }
   ],
   "source": [
    "# Add relative dates using the same logic as other notebooks\n",
    "if 'relative_dates_json' not in medcat_df.columns:\n",
    "    medcat_df = add_relative_dates(medcat_df)\n",
    "    print(\"Added relative dates\")\n",
    "else:\n",
    "    print(\"Relative dates already present, skipping extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a75837e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>note_text</th>\n",
       "      <th>entities_json</th>\n",
       "      <th>dates_json</th>\n",
       "      <th>links_json</th>\n",
       "      <th>relative_dates_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26461</td>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "      <td>[{\"id\": 308244, \"value\": \"history of meningiti...</td>\n",
       "      <td>[{\"id\": 308320, \"value\": \"30nd Jun 2024\", \"sta...</td>\n",
       "      <td>[{\"date\": \"12nd Sep 2024\", \"entity\": \"pituitar...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26462</td>\n",
       "      <td>Labs (27th Sep 2024): anemia. resolving  Skin:...</td>\n",
       "      <td>[{\"id\": 308371, \"value\": \"lesions\", \"cui\": \"52...</td>\n",
       "      <td>[{\"id\": 308581, \"value\": \"22/11/24\", \"start\": ...</td>\n",
       "      <td>[{\"date\": \"27th Sep 2024\", \"entity\": \"anemia\"}...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26463</td>\n",
       "      <td>URGENT REVIEW (2024-10-04): cough. suspect ost...</td>\n",
       "      <td>[{\"id\": 308886, \"value\": \"frequent urination\",...</td>\n",
       "      <td>[{\"id\": 308940, \"value\": \"2024-10-04\", \"start\"...</td>\n",
       "      <td>[{\"date\": \"2024-10-04\", \"entity\": \"cough\"}, {\"...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26464</td>\n",
       "      <td>URGENT REVIEW (13rd Feb 2025) MRI of the brain...</td>\n",
       "      <td>[{\"id\": 308951, \"value\": \"multiple_sclerosis\",...</td>\n",
       "      <td>[{\"id\": 308996, \"value\": \"05-03-2025\", \"start\"...</td>\n",
       "      <td>[{\"date\": \"13rd Feb 2025\", \"entity\": \"visual\"}...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26465</td>\n",
       "      <td>New pt((18/11/24)): pt presents with nausea/vo...</td>\n",
       "      <td>[{\"id\": 308998, \"value\": \"history of neoplasm ...</td>\n",
       "      <td>[{\"id\": 309070, \"value\": \"18/11/24\", \"start\": ...</td>\n",
       "      <td>[{\"date\": \"18/11/24\", \"entity\": \"nausea/vomiti...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                          note_text  \\\n",
       "0   26461  Ultrasound (30nd Jun 2024): no significant fin...   \n",
       "1   26462  Labs (27th Sep 2024): anemia. resolving  Skin:...   \n",
       "2   26463  URGENT REVIEW (2024-10-04): cough. suspect ost...   \n",
       "3   26464  URGENT REVIEW (13rd Feb 2025) MRI of the brain...   \n",
       "4   26465  New pt((18/11/24)): pt presents with nausea/vo...   \n",
       "\n",
       "                                       entities_json  \\\n",
       "0  [{\"id\": 308244, \"value\": \"history of meningiti...   \n",
       "1  [{\"id\": 308371, \"value\": \"lesions\", \"cui\": \"52...   \n",
       "2  [{\"id\": 308886, \"value\": \"frequent urination\",...   \n",
       "3  [{\"id\": 308951, \"value\": \"multiple_sclerosis\",...   \n",
       "4  [{\"id\": 308998, \"value\": \"history of neoplasm ...   \n",
       "\n",
       "                                          dates_json  \\\n",
       "0  [{\"id\": 308320, \"value\": \"30nd Jun 2024\", \"sta...   \n",
       "1  [{\"id\": 308581, \"value\": \"22/11/24\", \"start\": ...   \n",
       "2  [{\"id\": 308940, \"value\": \"2024-10-04\", \"start\"...   \n",
       "3  [{\"id\": 308996, \"value\": \"05-03-2025\", \"start\"...   \n",
       "4  [{\"id\": 309070, \"value\": \"18/11/24\", \"start\": ...   \n",
       "\n",
       "                                          links_json relative_dates_json  \n",
       "0  [{\"date\": \"12nd Sep 2024\", \"entity\": \"pituitar...                  []  \n",
       "1  [{\"date\": \"27th Sep 2024\", \"entity\": \"anemia\"}...                  []  \n",
       "2  [{\"date\": \"2024-10-04\", \"entity\": \"cough\"}, {\"...                  []  \n",
       "3  [{\"date\": \"13rd Feb 2025\", \"entity\": \"visual\"}...                  []  \n",
       "4  [{\"date\": \"18/11/24\", \"entity\": \"nausea/vomiti...                  []  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspect data\n",
    "medcat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61acc0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert marker function\n",
    "def insert_marker(txt, start, end, tag_open, tag_close):\n",
    "                    return txt[:start] + tag_open + txt[start:end] + tag_close + txt[end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8e2fe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 741 date-entity pairs (including relative dates)\n"
     ]
    }
   ],
   "source": [
    "# Create dataset for training\n",
    "rows = []\n",
    "\n",
    "for _, row in medcat_df.iterrows():\n",
    "    doc_id = row[\"doc_id\"]\n",
    "    text = row[\"note_text\"]\n",
    "    \n",
    "    # Parse the JSON columns\n",
    "    entities = json.loads(row[\"entities_json\"])\n",
    "    dates = json.loads(row[\"dates_json\"])\n",
    "    relative_dates = json.loads(row[\"relative_dates_json\"]) if \"relative_dates_json\" in row else []\n",
    "    \n",
    "    # Combine absolute and relative dates\n",
    "    all_dates = dates + relative_dates\n",
    "    \n",
    "    # Get original links for labeling\n",
    "    links = []\n",
    "    for project in data.get(\"projects\", []):\n",
    "        for doc in project.get(\"documents\", []):\n",
    "            if doc.get(\"id\") == doc_id:\n",
    "                links = get_validated_links(doc, DATE_CUI)\n",
    "                break\n",
    "        if links:  # Break outer loop if we found links\n",
    "            break\n",
    "    \n",
    "    # Build link pairs from validated links (convert to strings to match)\n",
    "    link_pairs = {tuple(sorted([str(L[\"date_id\"]), str(L[\"entity_id\"])])) for L in links}\n",
    "    \n",
    "    # Create pairs for all date-entity combinations\n",
    "    for date in all_dates:\n",
    "        for entity in entities:\n",
    "            # Use real ID for both absolute and relative dates\n",
    "            date_id = str(date[\"id\"])\n",
    "            entity_id = str(entity[\"id\"])\n",
    "            \n",
    "            # Determine label (both absolute and relative dates can have links)\n",
    "            if tuple(sorted([date_id, entity_id])) in link_pairs:\n",
    "                label, label_id = \"LINK\", 1\n",
    "            else:\n",
    "                label, label_id = \"NO_LINK\", 0\n",
    "            \n",
    "            # Insert markers\n",
    "            s1, e1 = date.get(\"start\"), date.get(\"end\")\n",
    "            s2, e2 = entity.get(\"start\"), entity.get(\"end\")\n",
    "            \n",
    "            if s1 is not None and s2 is not None:\n",
    "                if s1 < s2:\n",
    "                    marked = insert_marker(text, s2, e2, \"[s2]\", \"[e2]\")\n",
    "                    marked = insert_marker(marked, s1, e1, \"[s1]\", \"[e1]\")\n",
    "                else:\n",
    "                    marked = insert_marker(text, s1, e1, \"[s2]\", \"[e2]\")\n",
    "                    marked = insert_marker(marked, s2, e2, \"[s1]\", \"[e1]\")\n",
    "            else:\n",
    "                marked = text\n",
    "            \n",
    "            rows.append({\n",
    "                \"relation_token_span_ids\": None,\n",
    "                \"ent1_ent2_start\": (s1, s2),\n",
    "                \"ent1\": date.get(\"value\", \"\"),\n",
    "                \"ent2\": entity.get(\"value\", \"\"),\n",
    "                \"label\": label,\n",
    "                \"label_id\": label_id,\n",
    "                \"ent1_type\": \"DATE\",\n",
    "                \"ent2_type\": \"ENTITY\",\n",
    "                \"ent1_id\": date_id,\n",
    "                \"ent2_id\": entity_id,\n",
    "                \"ent1_cui\": None,\n",
    "                \"ent2_cui\": None,\n",
    "                \"doc_id\": doc_id,\n",
    "                \"text\": marked\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(f\"Created {len(df)} date-entity pairs (including relative dates)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be91d40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect data\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f16571e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>n_entities</th>\n",
       "      <th>n_dates</th>\n",
       "      <th>n_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26461</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26462</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26463</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26464</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26465</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  n_entities  n_dates  n_links\n",
       "0   26461          64        6        4\n",
       "1   26462          21        7       11\n",
       "2   26463          15        7       12\n",
       "3   26464          11        3        6\n",
       "4   26465          24        3        4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Per-document summary \n",
    "summary = []\n",
    "\n",
    "for project in data.get(\"projects\", []):\n",
    "    for d in project.get(\"documents\", []):\n",
    "        ents  = get_validated_entities(d, DATE_CUI)\n",
    "        dates = get_validated_dates(d, DATE_CUI)\n",
    "        links = get_validated_links(d, DATE_CUI)\n",
    "        summary.append({\n",
    "            \"doc_id\": d.get(\"id\"),\n",
    "            \"n_entities\": len(ents),\n",
    "            \"n_dates\": len(dates),\n",
    "            \"n_links\": len(links),\n",
    "        })\n",
    "\n",
    "doc_level = pd.DataFrame(summary)\n",
    "doc_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32d00e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>total_pairs</th>\n",
       "      <th>link_pairs</th>\n",
       "      <th>link_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26461</td>\n",
       "      <td>384</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26462</td>\n",
       "      <td>147</td>\n",
       "      <td>11</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26463</td>\n",
       "      <td>105</td>\n",
       "      <td>12</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26464</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26465</td>\n",
       "      <td>72</td>\n",
       "      <td>4</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  total_pairs  link_pairs  link_pct\n",
       "0   26461          384           4       1.0\n",
       "1   26462          147          11       7.5\n",
       "2   26463          105          12      11.4\n",
       "3   26464           33           6      18.2\n",
       "4   26465           72           4       5.6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pair-based stats from the generated df\n",
    "pair_stats = (\n",
    "    df.groupby(\"doc_id\")\n",
    "      .agg(\n",
    "          total_pairs=(\"label\", \"size\"),\n",
    "          link_pairs=(\"label\", lambda s: (s == \"LINK\").sum()),\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "pair_stats[\"link_pct\"] = (100 * pair_stats[\"link_pairs\"] / pair_stats[\"total_pairs\"]).round(1)\n",
    "pair_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce540151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of date-entity pairs is 741\n",
      "total number of links: 37\n",
      "percentage positive class: 5.0%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>n_entities</th>\n",
       "      <th>n_dates</th>\n",
       "      <th>n_links</th>\n",
       "      <th>total_pairs</th>\n",
       "      <th>link_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26461</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>384</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26462</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>147</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26463</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>105</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26464</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26465</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>72</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  n_entities  n_dates  n_links  total_pairs  link_pct\n",
       "0   26461          64        6        4          384       1.0\n",
       "1   26462          21        7       11          147       7.5\n",
       "2   26463          15        7       12          105      11.4\n",
       "3   26464          11        3        6           33      18.2\n",
       "4   26465          24        3        4           72       5.6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge stats with doc_level summary\n",
    "doc_level = (\n",
    "    doc_level.merge(pair_stats[[\"doc_id\", \"total_pairs\", \"link_pct\"]], on=\"doc_id\", how=\"left\")\n",
    "             .sort_values(\"doc_id\")\n",
    "             .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Calculate additional metrics\n",
    "total_pairs_overall = len(df)\n",
    "link_total = (df[\"label\"] == \"LINK\").sum()\n",
    "link_pct_overall = 100 * (df[\"label\"] == \"LINK\").mean()\n",
    "\n",
    "print(f\"total number of date-entity pairs is {total_pairs_overall}\")\n",
    "print(f\"total number of links: {link_total}\")\n",
    "print(f\"percentage positive class: {link_pct_overall:.1f}%\")\n",
    "\n",
    "#Look at overall doc level summary\n",
    "doc_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96b1d11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset\n",
    "#df.to_csv(\"../data/relcat_training_data.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16d7f9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 592 samples\n",
      "Test set: 149 samples\n",
      "\n",
      "Train label distribution:\n",
      "label\n",
      "NO_LINK    562\n",
      "LINK        30\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test label distribution:\n",
      "label\n",
      "NO_LINK    142\n",
      "LINK         7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset and save\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "\n",
    "print(f\"Train set: {len(train_df)} samples\")\n",
    "print(f\"Test set: {len(test_df)} samples\")\n",
    "print(\"\\nTrain label distribution:\")\n",
    "print(train_df[\"label\"].value_counts())\n",
    "print(\"\\nTest label distribution:\")\n",
    "print(test_df[\"label\"].value_counts())\n",
    "\n",
    "# Save train and test sets\n",
    "train_df.to_csv(\"../data/relcat_training_data.tsv\", sep=\"\\t\", index=False)\n",
    "test_df.to_csv(\"../data/relcat_test_data.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b97b1e3",
   "metadata": {},
   "source": [
    "Config & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "190063fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create RelCAT config and set parameters\n",
    "config = ConfigRelCAT()\n",
    "config.general.log_level = logging.INFO\n",
    "config.general.model_name = \"bert-base-uncased\" # base model that you want to use, we're going to use the HuggingFace bert-base-uncased model\n",
    "\n",
    "#logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "404b03da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hidden size, model size and hidden layers\n",
    "config.model.hidden_size= 256\n",
    "config.model.model_size = 2304 # 4096 for llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6f98025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further config\n",
    "config.general.cntx_left = 15 # how many tokens to the left of the start entity we select\n",
    "config.general.cntx_right = 15 # how many tokens to the right of the end entity we selecd\n",
    "config.general.window_size = 300 # distance (in characters) between two entities to be considered a relation\n",
    "config.train.nclasses = 2 # number of classes in your medcat export / dataset\n",
    "config.train.nepochs = 3 # number of epochs to train for\n",
    "config.model.freeze_layers = False # whether to freeze the layers of the base model\n",
    "config.general.limit_samples_per_class = 300 # limit the number of training samples per class to this number, to avoid overfitting in unbalanced datasets\n",
    "config.train.batch_size = 32 # batch size\n",
    "config.train.lr = 3e-5\n",
    "config.train.adam_epsilon = 1e-8\n",
    "config.train.adam_weight_decay = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "646e1fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create CDB\n",
    "cdb = CDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a25fb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create tokenizer\n",
    "tokenizer = BaseTokenizerWrapper_RelationExtraction.load(tokenizer_path=config.general.model_name,\n",
    "                                                       relcat_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b28ce90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add special tokens\n",
    "special_ent_tokens = [\"[s1]\", \"[e1]\", \"[s2]\", \"[e2]\"]\n",
    "tokenizer.hf_tokenizers.add_tokens(special_ent_tokens, special_tokens=True)\n",
    "tokenizer.hf_tokenizers.add_special_tokens({'pad_token': '[PAD]'}) # used in llama tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a46f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add tokens to config\n",
    "config.general.tokenizer_relation_annotation_special_tokens_tags = special_ent_tokens\n",
    "config.general.annotation_schema_tag_ids = tokenizer.hf_tokenizers.convert_tokens_to_ids(special_ent_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e11e8338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:medcat.utils.relation_extraction.base_component:BaseComponent_RelationExtraction initialized\n"
     ]
    }
   ],
   "source": [
    "#Create RelCAT object and initialize components\n",
    "# if you wish to skip the steps in section 6.1 you can pass the init_model=True arguement to intialize the components with the default ConfigRelCAT settings.\n",
    "relCAT = RelCAT(cdb, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bc437ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "INFO:medcat.utils.relation_extraction.config:Loaded config from : bert-base-uncased\\model_config.json\n"
     ]
    }
   ],
   "source": [
    "# Load model configuration\n",
    "model_config = BaseConfig_RelationExtraction.load(pretrained_model_name_or_path=config.general.model_name,\n",
    "                                                 relcat_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d2ee74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update vocab size in model config to match tokenizer\n",
    "model_config.hf_model_config.vocab_size = tokenizer.get_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "657d3f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the padding idx in the model config and relcat config, this is necesasry as it depends on what tokenizer you use\n",
    "config.model.padding_idx = model_config.pad_token_id = tokenizer.get_pad_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b81f863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:medcat.utils.relation_extraction.models:RelCAT model config: PretrainedConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.55.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30526\n",
      "}\n",
      "\n",
      "INFO:medcat.utils.relation_extraction.bert.model:RelCAT model config: PretrainedConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.55.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30526\n",
      "}\n",
      "\n",
      "Some weights of BertModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized because the shapes did not match:\n",
      "- embeddings.word_embeddings.weight: found shape torch.Size([30522, 768]) in the checkpoint and torch.Size([30526, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:medcat.utils.relation_extraction.bert.model:Loaded model from pretrained: bert-base-uncased\n",
      "INFO:medcat.utils.relation_extraction.models:Loaded BertModel_RelationExtraction from pretrained_model_name_or_path: bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = BaseModel_RelationExtraction.load(pretrained_model_name_or_path=config.general.model_name,\n",
    "                                         model_config=model_config,\n",
    "                                         relcat_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea4db06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30526, 768, padding_idx=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resize embeddings to match tokenizer\n",
    "model.hf_model.resize_token_embeddings(len(tokenizer.hf_tokenizers)) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83084dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:medcat.utils.relation_extraction.base_component:BaseComponent_RelationExtraction initialized\n"
     ]
    }
   ],
   "source": [
    "# Create component\n",
    "component = BaseComponent_RelationExtraction(tokenizer=tokenizer, config=config)\n",
    "component.model = model\n",
    "component.model_config = model_config\n",
    "component.relcat_config = config\n",
    "component.tokenizer = tokenizer\n",
    "relCAT.component = component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "045c0514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:medcat.utils.relation_extraction.rel_dataset:CSV dataset | No. of relations detected:208| from : ../data/relcat_training_data.tsv | nclasses: 2 | idx2label: {0: 'LINK', 1: 'NO_LINK'}\n",
      "INFO:medcat.utils.relation_extraction.rel_dataset:Samples per class: \n",
      "INFO:medcat.utils.relation_extraction.rel_dataset: label: LINK | samples: 28\n",
      "INFO:medcat.utils.relation_extraction.rel_dataset: label: NO_LINK | samples: 180\n",
      "INFO:root:Relations after train, test split :  train - 167 | test - 41\n",
      "INFO:root: label: NO_LINK samples | train 144 | test 36\n",
      "INFO:root: label: LINK samples | train 23 | test 5\n",
      "INFO:root:Attempting to load RelCAT model on device: cpu\n",
      "INFO:medcat.rel_cat:Starting training process...\n",
      "INFO:medcat.rel_cat:Total epochs on this model: 3 | currently training epoch 0\n",
      "  0%|          | 0/167 [00:00<?, ?it/s]c:\\Users\\Satyam\\Downloads\\pituitary_adenoma\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "100%|██████████| 167/167 [01:15<00:00,  2.22it/s]\n",
      "c:\\Users\\Satyam\\Downloads\\pituitary_adenoma\\venv\\lib\\site-packages\\medcat\\rel_cat.py:345: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\autograd\\generated\\python_variable_methods.cpp:836.)\n",
      "  self.log.info(\"Losses at Epoch %d: %.5f\" %\n",
      "INFO:medcat.rel_cat:Losses at Epoch 0: 0.01650\n",
      "INFO:medcat.rel_cat:Train accuracy at Epoch 0: 0.77083\n",
      "INFO:medcat.rel_cat:======================== TRAIN SET TEST RESULTS ========================\n",
      "INFO:medcat.rel_cat:Evaluating test samples...\n",
      "INFO:medcat.rel_cat:==================== Evaluation Results ===================\n",
      "INFO:medcat.rel_cat: no. of batches:6\n",
      "INFO:medcat.rel_cat: accuracy = 0.880\n",
      "INFO:medcat.rel_cat: f1 = 0.880\n",
      "INFO:medcat.rel_cat: loss = 0.367\n",
      "INFO:medcat.rel_cat: precision = 0.880\n",
      "INFO:medcat.rel_cat: recall = 0.880\n",
      "INFO:medcat.rel_cat:----------------------- class stats -----------------------\n",
      "INFO:medcat.rel_cat:label: LINK | f1: 0.000 | prec : 0.000 | acc: 0.714 | recall: 0.000 \n",
      "INFO:medcat.rel_cat:label: NO_LINK | f1: 0.935 | prec : 1.000 | acc: 0.880 | recall: 0.880 \n",
      "INFO:medcat.rel_cat:-----------------------------------------------------------\n",
      "INFO:medcat.rel_cat:===========================================================\n",
      "INFO:medcat.rel_cat:======================== TEST SET TEST RESULTS ========================\n",
      "INFO:medcat.rel_cat:Evaluating test samples...\n",
      "INFO:medcat.rel_cat:==================== Evaluation Results ===================\n",
      "INFO:medcat.rel_cat: no. of batches:2\n",
      "INFO:medcat.rel_cat: accuracy = 0.882\n",
      "INFO:medcat.rel_cat: f1 = 0.882\n",
      "INFO:medcat.rel_cat: loss = 0.363\n",
      "INFO:medcat.rel_cat: precision = 0.882\n",
      "INFO:medcat.rel_cat: recall = 0.882\n",
      "INFO:medcat.rel_cat:----------------------- class stats -----------------------\n",
      "INFO:medcat.rel_cat:label: LINK | f1: 0.000 | prec : 0.000 | acc: 0.882 | recall: 0.000 \n",
      "INFO:medcat.rel_cat:label: NO_LINK | f1: 0.937 | prec : 1.000 | acc: 0.882 | recall: 0.882 \n",
      "INFO:medcat.rel_cat:-----------------------------------------------------------\n",
      "INFO:medcat.rel_cat:===========================================================\n",
      "INFO:medcat.rel_cat:Epoch finished, took 0:01:15.154347 seconds\n",
      "INFO:medcat.rel_cat:Total epochs on this model: 3 | currently training epoch 1\n",
      "100%|██████████| 167/167 [01:18<00:00,  2.13it/s]\n",
      "INFO:medcat.rel_cat:Losses at Epoch 1: 0.01407\n",
      "INFO:medcat.rel_cat:Train accuracy at Epoch 1: 0.88021\n",
      "INFO:medcat.rel_cat:======================== TRAIN SET TEST RESULTS ========================\n",
      "INFO:medcat.rel_cat:Evaluating test samples...\n",
      "INFO:medcat.rel_cat:==================== Evaluation Results ===================\n",
      "INFO:medcat.rel_cat: no. of batches:6\n",
      "INFO:medcat.rel_cat: accuracy = 0.862\n",
      "INFO:medcat.rel_cat: f1 = 0.862\n",
      "INFO:medcat.rel_cat: loss = 0.398\n",
      "INFO:medcat.rel_cat: precision = 0.862\n",
      "INFO:medcat.rel_cat: recall = 0.862\n",
      "INFO:medcat.rel_cat:----------------------- class stats -----------------------\n",
      "INFO:medcat.rel_cat:label: LINK | f1: 0.000 | prec : 0.000 | acc: 0.862 | recall: 0.000 \n",
      "INFO:medcat.rel_cat:label: NO_LINK | f1: 0.925 | prec : 1.000 | acc: 0.862 | recall: 0.862 \n",
      "INFO:medcat.rel_cat:-----------------------------------------------------------\n",
      "INFO:medcat.rel_cat:===========================================================\n",
      "INFO:medcat.rel_cat:======================== TEST SET TEST RESULTS ========================\n",
      "INFO:medcat.rel_cat:Evaluating test samples...\n",
      "INFO:medcat.rel_cat:==================== Evaluation Results ===================\n",
      "INFO:medcat.rel_cat: no. of batches:2\n",
      "INFO:medcat.rel_cat: accuracy = 0.802\n",
      "INFO:medcat.rel_cat: f1 = 0.802\n",
      "INFO:medcat.rel_cat: loss = 0.528\n",
      "INFO:medcat.rel_cat: precision = 0.802\n",
      "INFO:medcat.rel_cat: recall = 0.802\n",
      "INFO:medcat.rel_cat:----------------------- class stats -----------------------\n",
      "INFO:medcat.rel_cat:label: LINK | f1: 0.000 | prec : 0.000 | acc: 0.802 | recall: 0.000 \n",
      "INFO:medcat.rel_cat:label: NO_LINK | f1: 0.884 | prec : 1.000 | acc: 0.802 | recall: 0.802 \n",
      "INFO:medcat.rel_cat:-----------------------------------------------------------\n",
      "INFO:medcat.rel_cat:===========================================================\n",
      "INFO:medcat.rel_cat:Epoch finished, took 0:01:18.299776 seconds\n",
      "INFO:medcat.rel_cat:Total epochs on this model: 3 | currently training epoch 2\n",
      "100%|██████████| 167/167 [01:14<00:00,  2.24it/s]\n",
      "INFO:medcat.rel_cat:Losses at Epoch 2: 0.01454\n",
      "INFO:medcat.rel_cat:Train accuracy at Epoch 2: 0.88021\n",
      "INFO:medcat.rel_cat:======================== TRAIN SET TEST RESULTS ========================\n",
      "INFO:medcat.rel_cat:Evaluating test samples...\n",
      "INFO:medcat.rel_cat:==================== Evaluation Results ===================\n",
      "INFO:medcat.rel_cat: no. of batches:6\n",
      "INFO:medcat.rel_cat: accuracy = 0.862\n",
      "INFO:medcat.rel_cat: f1 = 0.862\n",
      "INFO:medcat.rel_cat: loss = 0.383\n",
      "INFO:medcat.rel_cat: precision = 0.862\n",
      "INFO:medcat.rel_cat: recall = 0.862\n",
      "INFO:medcat.rel_cat:----------------------- class stats -----------------------\n",
      "INFO:medcat.rel_cat:label: LINK | f1: 0.000 | prec : 0.000 | acc: 0.862 | recall: 0.000 \n",
      "INFO:medcat.rel_cat:label: NO_LINK | f1: 0.925 | prec : 1.000 | acc: 0.862 | recall: 0.862 \n",
      "INFO:medcat.rel_cat:-----------------------------------------------------------\n",
      "INFO:medcat.rel_cat:===========================================================\n",
      "INFO:medcat.rel_cat:======================== TEST SET TEST RESULTS ========================\n",
      "INFO:medcat.rel_cat:Evaluating test samples...\n",
      "INFO:medcat.rel_cat:==================== Evaluation Results ===================\n",
      "INFO:medcat.rel_cat: no. of batches:2\n",
      "INFO:medcat.rel_cat: accuracy = 0.922\n",
      "INFO:medcat.rel_cat: f1 = 0.922\n",
      "INFO:medcat.rel_cat: loss = 0.277\n",
      "INFO:medcat.rel_cat: precision = 0.922\n",
      "INFO:medcat.rel_cat: recall = 0.922\n",
      "INFO:medcat.rel_cat:----------------------- class stats -----------------------\n",
      "INFO:medcat.rel_cat:label: LINK | f1: 0.000 | prec : 0.000 | acc: 0.422 | recall: 0.000 \n",
      "INFO:medcat.rel_cat:label: NO_LINK | f1: 0.958 | prec : 1.000 | acc: 0.922 | recall: 0.922 \n",
      "INFO:medcat.rel_cat:-----------------------------------------------------------\n",
      "INFO:medcat.rel_cat:===========================================================\n",
      "INFO:medcat.rel_cat:Epoch finished, took 0:01:14.607933 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train the model using the dataset we created\n",
    "relCAT.train(\n",
    "    train_csv_path=\"../data/relcat_training_data.tsv\",  \n",
    "    checkpoint_path=\"../models/relcat_models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4343546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "relCAT.save(save_path=\"../models/relcat_models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332aa3d6",
   "metadata": {},
   "source": [
    "Inference & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d2d6c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:medcat.rel_cat:The default CDB file name 'cdb.dat' doesn't exist in the specified path, you will need to load & set                 a CDB manually via rel_cat.cdb = CDB.load('path') \n",
      "INFO:root:Loaded config.json\n",
      "INFO:medcat.utils.relation_extraction.bert.config:Loaded config from file: ../models/relcat_models\\model_config.json\n",
      "INFO:medcat.utils.relation_extraction.tokenizer:Tokenizer loaded TokenizerWrapperBERT_RelationExtraction from:../models/relcat_models\n",
      "INFO:medcat.utils.relation_extraction.models:RelCAT model config: BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.55.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30526\n",
      "}\n",
      "\n",
      "INFO:medcat.utils.relation_extraction.bert.model:RelCAT model config: BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.55.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30526\n",
      "}\n",
      "\n",
      "INFO:medcat.utils.relation_extraction.bert.model:Loaded model from file: ../models/relcat_models\\model.dat\n",
      "INFO:medcat.utils.relation_extraction.models:Loaded BertModel_RelationExtraction from pretrained_model_name_or_path: ../models/relcat_models\n",
      "INFO:root:Attempting to load RelCAT model on device: cpu\n",
      "INFO:root:Loaded checkpoint model.\n",
      "INFO:root:Loaded model and optimizer.\n",
      "INFO:medcat.utils.relation_extraction.base_component:BaseComponent_RelationExtraction initialized\n",
      "INFO:medcat.utils.relation_extraction.base_component:BaseComponent_RelationExtraction initialized\n"
     ]
    }
   ],
   "source": [
    "#Load model\n",
    "relCAT = RelCAT.load(\"../models/relcat_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe2d50d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded test data: 149 samples\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv(\"../data/relcat_test_data.tsv\", sep=\"\\t\")\n",
    "print(f\"Loaded test data: {len(test_df)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a9c1d88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relation_token_span_ids</th>\n",
       "      <th>ent1_ent2_start</th>\n",
       "      <th>ent1</th>\n",
       "      <th>ent2</th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "      <th>ent1_type</th>\n",
       "      <th>ent2_type</th>\n",
       "      <th>ent1_id</th>\n",
       "      <th>ent2_id</th>\n",
       "      <th>ent1_cui</th>\n",
       "      <th>ent2_cui</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(715, 305)</td>\n",
       "      <td>07.05.25</td>\n",
       "      <td>weight gain</td>\n",
       "      <td>NO_LINK</td>\n",
       "      <td>0</td>\n",
       "      <td>DATE</td>\n",
       "      <td>ENTITY</td>\n",
       "      <td>308945</td>\n",
       "      <td>308898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26463</td>\n",
       "      <td>URGENT REVIEW (2024-10-04): cough. suspect ost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(588, 1221)</td>\n",
       "      <td>23rd Oct 2024</td>\n",
       "      <td>improved</td>\n",
       "      <td>NO_LINK</td>\n",
       "      <td>0</td>\n",
       "      <td>DATE</td>\n",
       "      <td>ENTITY</td>\n",
       "      <td>308323</td>\n",
       "      <td>308426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26461</td>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(935, 946)</td>\n",
       "      <td>16/02/25</td>\n",
       "      <td>elevated CRP</td>\n",
       "      <td>LINK</td>\n",
       "      <td>1</td>\n",
       "      <td>DATE</td>\n",
       "      <td>ENTITY</td>\n",
       "      <td>308885</td>\n",
       "      <td>308820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26462</td>\n",
       "      <td>Labs (27th Sep 2024): anemia. resolving  Skin:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(339, 307)</td>\n",
       "      <td>22/11/24</td>\n",
       "      <td>multiple_sclerosis</td>\n",
       "      <td>NO_LINK</td>\n",
       "      <td>0</td>\n",
       "      <td>DATE</td>\n",
       "      <td>ENTITY</td>\n",
       "      <td>308581</td>\n",
       "      <td>308809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26462</td>\n",
       "      <td>Labs (27th Sep 2024): anemia. resolving  Skin:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(471, 50)</td>\n",
       "      <td>26/12/24</td>\n",
       "      <td>rashes</td>\n",
       "      <td>NO_LINK</td>\n",
       "      <td>0</td>\n",
       "      <td>DATE</td>\n",
       "      <td>ENTITY</td>\n",
       "      <td>308882</td>\n",
       "      <td>308853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26462</td>\n",
       "      <td>Labs (27th Sep 2024): anemia. resolving  Skin:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(588, 429)</td>\n",
       "      <td>23rd Oct 2024</td>\n",
       "      <td>CLINIC</td>\n",
       "      <td>NO_LINK</td>\n",
       "      <td>0</td>\n",
       "      <td>DATE</td>\n",
       "      <td>ENTITY</td>\n",
       "      <td>308323</td>\n",
       "      <td>308297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26461</td>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(443, 854)</td>\n",
       "      <td>16 Sep'24</td>\n",
       "      <td>mild</td>\n",
       "      <td>NO_LINK</td>\n",
       "      <td>0</td>\n",
       "      <td>DATE</td>\n",
       "      <td>ENTITY</td>\n",
       "      <td>308322</td>\n",
       "      <td>308438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26461</td>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(935, 641)</td>\n",
       "      <td>16/02/25</td>\n",
       "      <td>multiple_sclerosis</td>\n",
       "      <td>NO_LINK</td>\n",
       "      <td>0</td>\n",
       "      <td>DATE</td>\n",
       "      <td>ENTITY</td>\n",
       "      <td>308885</td>\n",
       "      <td>308810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26462</td>\n",
       "      <td>Labs (27th Sep 2024): anemia. resolving  Skin:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(12, 328)</td>\n",
       "      <td>30nd Jun 2024</td>\n",
       "      <td>reveals</td>\n",
       "      <td>NO_LINK</td>\n",
       "      <td>0</td>\n",
       "      <td>DATE</td>\n",
       "      <td>ENTITY</td>\n",
       "      <td>308320</td>\n",
       "      <td>308284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26461</td>\n",
       "      <td>Ultrasound ([s1]30nd Jun 2024[e1]): no signifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(1205, 573)</td>\n",
       "      <td>16st Nov 2024</td>\n",
       "      <td>URGENT</td>\n",
       "      <td>NO_LINK</td>\n",
       "      <td>0</td>\n",
       "      <td>DATE</td>\n",
       "      <td>ENTITY</td>\n",
       "      <td>308324</td>\n",
       "      <td>308298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26461</td>\n",
       "      <td>Ultrasound (30nd Jun 2024): no significant fin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     relation_token_span_ids ent1_ent2_start           ent1  \\\n",
       "0                        NaN      (715, 305)       07.05.25   \n",
       "1                        NaN     (588, 1221)  23rd Oct 2024   \n",
       "2                        NaN      (935, 946)       16/02/25   \n",
       "3                        NaN      (339, 307)       22/11/24   \n",
       "4                        NaN       (471, 50)       26/12/24   \n",
       "..                       ...             ...            ...   \n",
       "144                      NaN      (588, 429)  23rd Oct 2024   \n",
       "145                      NaN      (443, 854)      16 Sep'24   \n",
       "146                      NaN      (935, 641)       16/02/25   \n",
       "147                      NaN       (12, 328)  30nd Jun 2024   \n",
       "148                      NaN     (1205, 573)  16st Nov 2024   \n",
       "\n",
       "                   ent2    label  label_id ent1_type ent2_type  ent1_id  \\\n",
       "0           weight gain  NO_LINK         0      DATE    ENTITY   308945   \n",
       "1              improved  NO_LINK         0      DATE    ENTITY   308323   \n",
       "2          elevated CRP     LINK         1      DATE    ENTITY   308885   \n",
       "3    multiple_sclerosis  NO_LINK         0      DATE    ENTITY   308581   \n",
       "4                rashes  NO_LINK         0      DATE    ENTITY   308882   \n",
       "..                  ...      ...       ...       ...       ...      ...   \n",
       "144              CLINIC  NO_LINK         0      DATE    ENTITY   308323   \n",
       "145                mild  NO_LINK         0      DATE    ENTITY   308322   \n",
       "146  multiple_sclerosis  NO_LINK         0      DATE    ENTITY   308885   \n",
       "147             reveals  NO_LINK         0      DATE    ENTITY   308320   \n",
       "148              URGENT  NO_LINK         0      DATE    ENTITY   308324   \n",
       "\n",
       "     ent2_id  ent1_cui  ent2_cui  doc_id  \\\n",
       "0     308898       NaN       NaN   26463   \n",
       "1     308426       NaN       NaN   26461   \n",
       "2     308820       NaN       NaN   26462   \n",
       "3     308809       NaN       NaN   26462   \n",
       "4     308853       NaN       NaN   26462   \n",
       "..       ...       ...       ...     ...   \n",
       "144   308297       NaN       NaN   26461   \n",
       "145   308438       NaN       NaN   26461   \n",
       "146   308810       NaN       NaN   26462   \n",
       "147   308284       NaN       NaN   26461   \n",
       "148   308298       NaN       NaN   26461   \n",
       "\n",
       "                                                  text  \n",
       "0    URGENT REVIEW (2024-10-04): cough. suspect ost...  \n",
       "1    Ultrasound (30nd Jun 2024): no significant fin...  \n",
       "2    Labs (27th Sep 2024): anemia. resolving  Skin:...  \n",
       "3    Labs (27th Sep 2024): anemia. resolving  Skin:...  \n",
       "4    Labs (27th Sep 2024): anemia. resolving  Skin:...  \n",
       "..                                                 ...  \n",
       "144  Ultrasound (30nd Jun 2024): no significant fin...  \n",
       "145  Ultrasound (30nd Jun 2024): no significant fin...  \n",
       "146  Labs (27th Sep 2024): anemia. resolving  Skin:...  \n",
       "147  Ultrasound ([s1]30nd Jun 2024[e1]): no signifi...  \n",
       "148  Ultrasound (30nd Jun 2024): no significant fin...  \n",
       "\n",
       "[149 rows x 14 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:medcat.rel_cat:total relations for doc: 45\n",
      "INFO:medcat.rel_cat:processing...\n",
      "  0%|          | 0/45 [00:00<?, ?it/s]c:\\Users\\Satyam\\Downloads\\pituitary_adenoma\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "100%|██████████| 45/45 [00:08<00:00,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing document 26461: min() arg is an empty sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:medcat.rel_cat:total relations for doc: 55\n",
      "INFO:medcat.rel_cat:processing...\n",
      "100%|██████████| 55/55 [00:10<00:00,  5.31it/s]\n",
      "INFO:medcat.rel_cat:total relations for doc: 20\n",
      "INFO:medcat.rel_cat:processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing document 26465: min() arg is an empty sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:03<00:00,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5 test documents\n",
      "Total predictions: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run inference on all test documents using the same data source as training\n",
    "all_predictions = []\n",
    "\n",
    "test_doc_ids = test_df['doc_id'].unique()\n",
    "\n",
    "for doc_id in test_doc_ids:\n",
    "    # Find the document in medcat_df (same source as training)\n",
    "    doc_row = medcat_df[medcat_df['doc_id'] == doc_id].iloc[0]\n",
    "    \n",
    "    # Parse the same JSON columns used in training\n",
    "    entities = json.loads(doc_row[\"entities_json\"])\n",
    "    dates = json.loads(doc_row[\"dates_json\"])\n",
    "    \n",
    "    # Create annotations in the same format as training\n",
    "    annotations = []\n",
    "    for entity in entities:\n",
    "        annotations.append({\n",
    "            \"value\": entity[\"value\"],\n",
    "            \"cui\": entity.get(\"cui\"),\n",
    "            \"start\": entity.get(\"start\"),\n",
    "            \"end\": entity.get(\"end\")\n",
    "        })\n",
    "    for date in dates:\n",
    "        annotations.append({\n",
    "            \"value\": date[\"value\"],\n",
    "            \"cui\": DATE_CUI,\n",
    "            \"start\": date.get(\"start\"),\n",
    "            \"end\": date.get(\"end\")\n",
    "        })\n",
    "    \n",
    "    try:\n",
    "        # Run inference\n",
    "        output_doc_with_relations = relCAT.predict_text_with_anns(\n",
    "            text=doc_row[\"note_text\"], \n",
    "            annotations=annotations\n",
    "        )\n",
    "        \n",
    "        # Collect results - only keep date-entity pairs\n",
    "        for relation in output_doc_with_relations._.relations:\n",
    "            # Check if this is a date-entity pair (not entity-entity)\n",
    "            if (relation['ent1_text'] in [d['value'] for d in dates] and \n",
    "                relation['ent2_text'] in [e['value'] for e in entities]) or \\\n",
    "               (relation['ent2_text'] in [d['value'] for d in dates] and \n",
    "                relation['ent1_text'] in [e['value'] for e in entities]):\n",
    "                \n",
    "                all_predictions.append({\n",
    "                    'entity_label': relation['ent1_text'],\n",
    "                    'date': relation['ent2_text'],\n",
    "                    'confidence': relation['confidence'],\n",
    "                    'doc_id': doc_id\n",
    "                })\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing document {doc_id}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Processed {len(test_doc_ids)} test documents\")\n",
    "print(f\"Total predictions: {len(all_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "208a9a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Results:\n",
      "Total predictions: 31\n",
      "\n",
      "First 10 predictions:\n",
      "1. frequent urination -> 07.05.25 (conf: 0.911) [doc: 26463]\n",
      "2. diabetes_mellitus -> 23rd Feb 2025 (conf: 0.852) [doc: 26463]\n",
      "3. osteoarthritis -> 21-11-2024 (conf: 0.889) [doc: 26463]\n",
      "4. weight gain -> 23rd Feb 2025 (conf: 0.863) [doc: 26463]\n",
      "5. hemorrhage -> 23rd Feb 2025 (conf: 0.871) [doc: 26463]\n",
      "6. PET scan -> 21-11-2024 (conf: 0.864) [doc: 26463]\n",
      "7. PET scan -> 23rd Feb 2025 (conf: 0.832) [doc: 26463]\n",
      "8. anemia -> 07.05.25 (conf: 0.848) [doc: 26463]\n",
      "9. cough -> 21-11-2024 (conf: 0.858) [doc: 26463]\n",
      "10. cough -> 21-11-2024 (conf: 0.859) [doc: 26463]\n",
      "\n",
      "High confidence predictions (>0.7): 31\n",
      "1. frequent urination -> 07.05.25 (conf: 0.911)\n",
      "2. diabetes_mellitus -> 23rd Feb 2025 (conf: 0.852)\n",
      "3. osteoarthritis -> 21-11-2024 (conf: 0.889)\n",
      "4. weight gain -> 23rd Feb 2025 (conf: 0.863)\n",
      "5. hemorrhage -> 23rd Feb 2025 (conf: 0.871)\n"
     ]
    }
   ],
   "source": [
    "# Show results\n",
    "print(\"Test Set Results:\")\n",
    "print(f\"Total predictions: {len(all_predictions)}\")\n",
    "\n",
    "# Show first 10 predictions\n",
    "print(\"\\nFirst 10 predictions:\")\n",
    "for i, pred in enumerate(all_predictions[:10]):\n",
    "    print(f\"{i+1}. {pred['entity_label']} -> {pred['date']} (conf: {pred['confidence']:.3f}) [doc: {pred['doc_id']}]\")\n",
    "\n",
    "# Show high confidence predictions\n",
    "high_conf = [p for p in all_predictions if p['confidence'] > 0.7]\n",
    "print(f\"\\nHigh confidence predictions (>0.7): {len(high_conf)}\")\n",
    "for i, pred in enumerate(high_conf[:5]):  # Show first 5\n",
    "    print(f\"{i+1}. {pred['entity_label']} -> {pred['date']} (conf: {pred['confidence']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ee40d8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test pairs: 149\n",
      "Total predictions: 31\n",
      "Test pairs that were predicted: 7\n",
      "Test pairs that were NOT predicted: 142\n",
      "Test doc IDs: {26464, 26465, 26461, 26462, 26463}\n",
      "Prediction doc IDs: {26464, 26462, 26463}\n",
      "Extra predictions (not in test): 0\n"
     ]
    }
   ],
   "source": [
    "# Let's debug the exact counts\n",
    "print(f\"Total test pairs: {len(test_df)}\")\n",
    "print(f\"Total predictions: {len(all_predictions)}\")\n",
    "\n",
    "# Count how many test pairs were actually predicted\n",
    "predicted_count = 0\n",
    "for _, row in test_df.iterrows():\n",
    "    found = False\n",
    "    for pred in all_predictions:\n",
    "        if (pred['doc_id'] == row['doc_id'] and \n",
    "            ((pred['entity_label'] == row['ent1'] and pred['date'] == row['ent2']) or\n",
    "             (pred['entity_label'] == row['ent2'] and pred['date'] == row['ent1']))):\n",
    "            found = True\n",
    "            break\n",
    "    if found:\n",
    "        predicted_count += 1\n",
    "\n",
    "print(f\"Test pairs that were predicted: {predicted_count}\")\n",
    "print(f\"Test pairs that were NOT predicted: {len(test_df) - predicted_count}\")\n",
    "\n",
    "# Also check if there are predictions for documents not in test set\n",
    "test_doc_ids = set(test_df['doc_id'].unique())\n",
    "pred_doc_ids = set([p['doc_id'] for p in all_predictions])\n",
    "print(f\"Test doc IDs: {test_doc_ids}\")\n",
    "print(f\"Prediction doc IDs: {pred_doc_ids}\")\n",
    "print(f\"Extra predictions (not in test): {len(pred_doc_ids - test_doc_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6dbb1e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Test Pairs Metrics:\n",
      "Accuracy: 0.919\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LINK       0.14      0.14      0.14         7\n",
      "     NO_LINK       0.96      0.96      0.96       142\n",
      "\n",
      "    accuracy                           0.92       149\n",
      "   macro avg       0.55      0.55      0.55       149\n",
      "weighted avg       0.92      0.92      0.92       149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create predictions for all test pairs\n",
    "all_test_predictions = []\n",
    "\n",
    "for _, row in test_df.iterrows():\n",
    "    # Check if this pair was predicted as a link\n",
    "    found = False\n",
    "    for pred in all_predictions:\n",
    "        if (pred['doc_id'] == row['doc_id'] and \n",
    "            ((pred['entity_label'] == row['ent1'] and pred['date'] == row['ent2']) or\n",
    "             (pred['entity_label'] == row['ent2'] and pred['date'] == row['ent1']))):\n",
    "            all_test_predictions.append('LINK')\n",
    "            found = True\n",
    "            break\n",
    "    \n",
    "    if not found:\n",
    "        all_test_predictions.append('NO_LINK')\n",
    "\n",
    "# Now calculate metrics on all test pairs\n",
    "y_true_all = test_df['label'].tolist()\n",
    "y_pred_all = all_test_predictions\n",
    "\n",
    "print(f\"\\nAll Test Pairs Metrics:\")\n",
    "print(f\"Accuracy: {sum(1 for t, p in zip(y_true_all, y_pred_all) if t == p) / len(y_true_all):.3f}\")\n",
    "print(classification_report(y_true_all, y_pred_all, labels=['LINK', 'NO_LINK']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
