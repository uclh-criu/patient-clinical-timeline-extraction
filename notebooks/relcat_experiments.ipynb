{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61b2cc81",
   "metadata": {},
   "source": [
    "Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17372f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import json\n",
    "import pandas as pd\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from medcat.cdb import CDB\n",
    "from medcat.config_rel_cat import ConfigRelCAT\n",
    "from medcat.rel_cat import RelCAT\n",
    "from medcat.utils.relation_extraction.base_component import BaseComponent_RelationExtraction\n",
    "from medcat.utils.relation_extraction.bert.model import BaseModel_RelationExtraction\n",
    "from medcat.utils.relation_extraction.bert.config import BaseConfig_RelationExtraction\n",
    "from medcat.utils.relation_extraction.tokenizer import BaseTokenizerWrapper_RelationExtraction\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "691cb693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data with 1 projects\n"
     ]
    }
   ],
   "source": [
    "# Load MedCAT data\n",
    "with open(\"../data/MedCAT_Export_With_Text_2025-09-11_08_19_37.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Loaded data with {len(data['projects'])} projects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8e2fe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "DATE_CUI = \"410671006\"\n",
    "rows = []\n",
    "\n",
    "for project in data[\"projects\"]:\n",
    "    for doc in project[\"documents\"]:\n",
    "        doc_id = doc[\"id\"]\n",
    "        text = doc[\"text\"]\n",
    "\n",
    "        # All annotations in this doc\n",
    "        anns = {a[\"id\"]: a for a in doc.get(\"annotations\", [])}\n",
    "\n",
    "        # Collect dates and non-dates\n",
    "        dates = [a for a in anns.values() if a.get(\"cui\") == DATE_CUI]\n",
    "        others = [a for a in anns.values() if a.get(\"cui\") != DATE_CUI]\n",
    "\n",
    "        # Relations explicitly annotated as 'link'\n",
    "        link_pairs = set()\n",
    "        for rel in doc.get(\"relations\", []):\n",
    "            link_pairs.add(tuple(sorted([rel[\"start_entity\"], rel[\"end_entity\"]])))\n",
    "\n",
    "        # Create entity–date pairs\n",
    "        for date in dates:\n",
    "            for ent in others:\n",
    "                ent1, ent2 = date, ent\n",
    "\n",
    "                ent1_id, ent2_id = ent1[\"id\"], ent2[\"id\"]\n",
    "                ent1_val, ent2_val = ent1[\"value\"], ent2[\"value\"]\n",
    "                ent1_cui, ent2_cui = ent1.get(\"cui\"), ent2.get(\"cui\")\n",
    "                ent1_s, ent1_e = ent1.get(\"start\"), ent1.get(\"end\")\n",
    "                ent2_s, ent2_e = ent2.get(\"start\"), ent2.get(\"end\")\n",
    "\n",
    "                # Determine label\n",
    "                if tuple(sorted([ent1_id, ent2_id])) in link_pairs:\n",
    "                    label, label_id = \"LINK\", 1\n",
    "                else:\n",
    "                    label, label_id = \"NO_LINK\", 0\n",
    "\n",
    "                # Insert ADE-style markers into text\n",
    "                def insert_marker(txt, start, end, tag_open, tag_close):\n",
    "                    return txt[:start] + tag_open + txt[start:end] + tag_close + txt[end:]\n",
    "\n",
    "                if ent1_s is not None and ent2_s is not None:\n",
    "                    if ent1_s < ent2_s:\n",
    "                        marked = insert_marker(text, ent2_s, ent2_e, \"[s2]\", \"[e2]\")\n",
    "                        marked = insert_marker(marked, ent1_s, ent1_e, \"[s1]\", \"[e1]\")\n",
    "                    else:\n",
    "                        marked = insert_marker(text, ent1_s, ent1_e, \"[s2]\", \"[e2]\")\n",
    "                        marked = insert_marker(marked, ent2_s, ent2_e, \"[s1]\", \"[e1]\")\n",
    "                else:\n",
    "                    marked = text\n",
    "\n",
    "                rows.append({\n",
    "                    \"relation_token_span_ids\": None,\n",
    "                    \"ent1_ent2_start\": (ent1_s, ent2_s),\n",
    "                    \"ent1\": ent1_val,\n",
    "                    \"ent2\": ent2_val,\n",
    "                    \"label\": label,\n",
    "                    \"label_id\": label_id,\n",
    "                    \"ent1_type\": \"DATE\",\n",
    "                    \"ent2_type\": \"ENTITY\",\n",
    "                    \"ent1_id\": ent1_id,\n",
    "                    \"ent2_id\": ent2_id,\n",
    "                    \"ent1_cui\": ent1_cui,\n",
    "                    \"ent2_cui\": ent2_cui,\n",
    "                    \"doc_id\": doc_id,\n",
    "                    \"text\": marked\n",
    "                })\n",
    "\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d00e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16d7f9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 1405 samples\n",
      "Test set: 352 samples\n",
      "\n",
      "Train label distribution:\n",
      "label\n",
      "NO_LINK    1375\n",
      "LINK         30\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test label distribution:\n",
      "label\n",
      "NO_LINK    344\n",
      "LINK         8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "\n",
    "print(f\"Train set: {len(train_df)} samples\")\n",
    "print(f\"Test set: {len(test_df)} samples\")\n",
    "print(\"\\nTrain label distribution:\")\n",
    "print(train_df[\"label\"].value_counts())\n",
    "print(\"\\nTest label distribution:\")\n",
    "print(test_df[\"label\"].value_counts())\n",
    "\n",
    "# Save train and test sets\n",
    "train_df.to_csv(\"../data/relations_date_entity_train.tsv\", sep=\"\\t\", index=False)\n",
    "test_df.to_csv(\"../data/relations_date_entity_test.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b97b1e3",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6f98025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure RelCAT\n",
    "config = ConfigRelCAT()\n",
    "config.general.log_level = logging.INFO\n",
    "config.general.model_name = \"bert-base-uncased\"\n",
    "config.model.hidden_size = 256\n",
    "config.model.model_size = 2304\n",
    "config.general.cntx_left = 15\n",
    "config.general.cntx_right = 15\n",
    "config.general.window_size = 300\n",
    "config.train.nclasses = 2\n",
    "config.train.nepochs = 3\n",
    "config.model.freeze_layers = False\n",
    "config.general.limit_samples_per_class = 300\n",
    "config.train.batch_size = 32\n",
    "config.train.lr = 3e-5\n",
    "config.train.adam_epsilon = 1e-8\n",
    "config.train.adam_weight_decay = 0.0005\n",
    "\n",
    "cdb = CDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a25fb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:medcat.utils.relation_extraction.tokenizer:Attempted to load Tokenizer from path:bert-base-uncased, but it doesn't exist, loading default toknizer from model_name relcat_config.general.model_name:bert-base-uncased\n",
      "INFO:medcat.utils.relation_extraction.tokenizer:Addeding special tokens to tokenizer:['[s1]', '[e1]', '[s2]', '[e2]'] {'pad_token': '[PAD]'}\n"
     ]
    }
   ],
   "source": [
    "#Create tokenizer\n",
    "tokenizer = BaseTokenizerWrapper_RelationExtraction.load(tokenizer_path=config.general.model_name,\n",
    "                                                       relcat_config=config)\n",
    "\n",
    "special_ent_tokens = [\"[s1]\", \"[e1]\", \"[s2]\", \"[e2]\"]\n",
    "tokenizer.hf_tokenizers.add_tokens(special_ent_tokens, special_tokens=True)\n",
    "tokenizer.hf_tokenizers.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "config.general.tokenizer_relation_annotation_special_tokens_tags = special_ent_tokens\n",
    "config.general.annotation_schema_tag_ids = tokenizer.hf_tokenizers.convert_tokens_to_ids(special_ent_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bc437ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "INFO:medcat.utils.relation_extraction.config:Loaded config from : bert-base-uncased\\model_config.json\n",
      "INFO:medcat.utils.relation_extraction.models:RelCAT model config: PretrainedConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.55.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30526\n",
      "}\n",
      "\n",
      "INFO:medcat.utils.relation_extraction.bert.model:RelCAT model config: PretrainedConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.55.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30526\n",
      "}\n",
      "\n",
      "Some weights of BertModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized because the shapes did not match:\n",
      "- embeddings.word_embeddings.weight: found shape torch.Size([30522, 768]) in the checkpoint and torch.Size([30526, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:medcat.utils.relation_extraction.bert.model:Loaded model from pretrained: bert-base-uncased\n",
      "INFO:medcat.utils.relation_extraction.models:Loaded BertModel_RelationExtraction from pretrained_model_name_or_path: bert-base-uncased\n",
      "INFO:medcat.utils.relation_extraction.base_component:BaseComponent_RelationExtraction initialized\n",
      "INFO:medcat.utils.relation_extraction.base_component:BaseComponent_RelationExtraction initialized\n"
     ]
    }
   ],
   "source": [
    "#Initiliaze model\n",
    "\n",
    "# Load model configuration\n",
    "model_config = BaseConfig_RelationExtraction.load(pretrained_model_name_or_path=config.general.model_name,\n",
    "                                                 relcat_config=config)\n",
    "\n",
    "# Update vocab size\n",
    "model_config.hf_model_config.vocab_size = tokenizer.get_size()\n",
    "config.model.padding_idx = model_config.pad_token_id = tokenizer.get_pad_id()\n",
    "\n",
    "# Load model\n",
    "model = BaseModel_RelationExtraction.load(pretrained_model_name_or_path=config.general.model_name,\n",
    "                                         model_config=model_config,\n",
    "                                         relcat_config=config)\n",
    "\n",
    "# Resize embeddings\n",
    "model.hf_model.resize_token_embeddings(len(tokenizer.hf_tokenizers))\n",
    "\n",
    "# Create component\n",
    "component = BaseComponent_RelationExtraction(tokenizer=tokenizer, config=config)\n",
    "component.model = model\n",
    "component.model_config = model_config\n",
    "component.relcat_config = config\n",
    "component.tokenizer = tokenizer\n",
    "\n",
    "\n",
    "# Create RelCAT with component\n",
    "relCAT = RelCAT(cdb, config=config)\n",
    "relCAT.component = component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "045c0514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:medcat.utils.relation_extraction.rel_dataset:CSV dataset | No. of relations detected:482| from : ../data/relations_date_entity_train.tsv | nclasses: 2 | idx2label: {0: 'NO_LINK', 1: 'LINK'}\n",
      "INFO:medcat.utils.relation_extraction.rel_dataset:Samples per class: \n",
      "INFO:medcat.utils.relation_extraction.rel_dataset: label: NO_LINK | samples: 454\n",
      "INFO:medcat.utils.relation_extraction.rel_dataset: label: LINK | samples: 28\n",
      "INFO:root:Relations after train, test split :  train - 323 | test - 65\n",
      "INFO:root: label: NO_LINK samples | train 300 | test 60\n",
      "INFO:root: label: LINK samples | train 23 | test 5\n",
      "INFO:root:Attempting to load RelCAT model on device: cpu\n",
      "INFO:medcat.rel_cat:Starting training process...\n",
      "INFO:medcat.rel_cat:Total epochs on this model: 3 | currently training epoch 0\n",
      "  0%|          | 0/323 [00:00<?, ?it/s]c:\\Users\\Satyam\\Downloads\\pituitary_adenoma\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "100%|██████████| 323/323 [02:27<00:00,  2.20it/s]\n",
      "c:\\Users\\Satyam\\Downloads\\pituitary_adenoma\\venv\\lib\\site-packages\\medcat\\rel_cat.py:345: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\autograd\\generated\\python_variable_methods.cpp:836.)\n",
      "  self.log.info(\"Losses at Epoch %d: %.5f\" %\n",
      "INFO:medcat.rel_cat:Losses at Epoch 0: 0.01256\n",
      "INFO:medcat.rel_cat:Train accuracy at Epoch 0: 0.92045\n",
      "INFO:medcat.rel_cat:======================== TRAIN SET TEST RESULTS ========================\n",
      "INFO:medcat.rel_cat:Evaluating test samples...\n",
      "INFO:medcat.rel_cat:==================== Evaluation Results ===================\n",
      "INFO:medcat.rel_cat: no. of batches:11\n",
      "INFO:medcat.rel_cat: accuracy = 0.880\n",
      "INFO:medcat.rel_cat: f1 = 0.880\n",
      "INFO:medcat.rel_cat: loss = 0.341\n",
      "INFO:medcat.rel_cat: precision = 0.880\n",
      "INFO:medcat.rel_cat: recall = 0.880\n",
      "INFO:medcat.rel_cat:----------------------- class stats -----------------------\n",
      "INFO:medcat.rel_cat:label: NO_LINK | f1: 0.923 | prec : 1.000 | acc: 0.880 | recall: 0.880 \n",
      "INFO:medcat.rel_cat:label: LINK | f1: 0.000 | prec : 0.000 | acc: 0.789 | recall: 0.000 \n",
      "INFO:medcat.rel_cat:-----------------------------------------------------------\n",
      "INFO:medcat.rel_cat:===========================================================\n",
      "INFO:medcat.rel_cat:======================== TEST SET TEST RESULTS ========================\n",
      "INFO:medcat.rel_cat:Evaluating test samples...\n",
      "INFO:medcat.rel_cat:==================== Evaluation Results ===================\n",
      "INFO:medcat.rel_cat: no. of batches:3\n",
      "INFO:medcat.rel_cat: accuracy = 0.615\n",
      "INFO:medcat.rel_cat: f1 = 0.615\n",
      "INFO:medcat.rel_cat: loss = 0.188\n",
      "INFO:medcat.rel_cat: precision = 0.615\n",
      "INFO:medcat.rel_cat: recall = 0.615\n",
      "INFO:medcat.rel_cat:----------------------- class stats -----------------------\n",
      "INFO:medcat.rel_cat:label: NO_LINK | f1: 0.638 | prec : 0.667 | acc: 0.615 | recall: 0.615 \n",
      "INFO:medcat.rel_cat:label: LINK | f1: 0.000 | prec : 0.000 | acc: 0.281 | recall: 0.000 \n",
      "INFO:medcat.rel_cat:-----------------------------------------------------------\n",
      "INFO:medcat.rel_cat:===========================================================\n",
      "INFO:medcat.rel_cat:Epoch finished, took 0:02:27.062474 seconds\n",
      "INFO:medcat.rel_cat:Total epochs on this model: 3 | currently training epoch 1\n",
      "100%|██████████| 323/323 [02:29<00:00,  2.16it/s]\n",
      "INFO:medcat.rel_cat:Losses at Epoch 1: 0.00916\n",
      "INFO:medcat.rel_cat:Train accuracy at Epoch 1: 0.93466\n",
      "INFO:medcat.rel_cat:======================== TRAIN SET TEST RESULTS ========================\n",
      "INFO:medcat.rel_cat:Evaluating test samples...\n",
      "INFO:medcat.rel_cat:==================== Evaluation Results ===================\n",
      "INFO:medcat.rel_cat: no. of batches:11\n",
      "INFO:medcat.rel_cat: accuracy = 0.880\n",
      "INFO:medcat.rel_cat: f1 = 0.880\n",
      "INFO:medcat.rel_cat: loss = 0.294\n",
      "INFO:medcat.rel_cat: precision = 0.880\n",
      "INFO:medcat.rel_cat: recall = 0.880\n",
      "INFO:medcat.rel_cat:----------------------- class stats -----------------------\n",
      "INFO:medcat.rel_cat:label: NO_LINK | f1: 0.923 | prec : 1.000 | acc: 0.880 | recall: 0.880 \n",
      "INFO:medcat.rel_cat:label: LINK | f1: 0.000 | prec : 0.000 | acc: 0.789 | recall: 0.000 \n",
      "INFO:medcat.rel_cat:-----------------------------------------------------------\n",
      "INFO:medcat.rel_cat:===========================================================\n",
      "INFO:medcat.rel_cat:======================== TEST SET TEST RESULTS ========================\n",
      "INFO:medcat.rel_cat:Evaluating test samples...\n",
      "INFO:medcat.rel_cat:==================== Evaluation Results ===================\n",
      "INFO:medcat.rel_cat: no. of batches:3\n",
      "INFO:medcat.rel_cat: accuracy = 0.615\n",
      "INFO:medcat.rel_cat: f1 = 0.615\n",
      "INFO:medcat.rel_cat: loss = 0.175\n",
      "INFO:medcat.rel_cat: precision = 0.615\n",
      "INFO:medcat.rel_cat: recall = 0.615\n",
      "INFO:medcat.rel_cat:----------------------- class stats -----------------------\n",
      "INFO:medcat.rel_cat:label: NO_LINK | f1: 0.639 | prec : 0.667 | acc: 0.615 | recall: 0.615 \n",
      "INFO:medcat.rel_cat:label: LINK | f1: 0.000 | prec : 0.000 | acc: 0.615 | recall: 0.000 \n",
      "INFO:medcat.rel_cat:-----------------------------------------------------------\n",
      "INFO:medcat.rel_cat:===========================================================\n",
      "INFO:medcat.rel_cat:Epoch finished, took 0:02:29.500808 seconds\n",
      "INFO:medcat.rel_cat:Total epochs on this model: 3 | currently training epoch 2\n",
      "100%|██████████| 323/323 [02:26<00:00,  2.20it/s]\n",
      "INFO:medcat.rel_cat:Losses at Epoch 2: 0.00750\n",
      "INFO:medcat.rel_cat:Train accuracy at Epoch 2: 0.93466\n",
      "INFO:medcat.rel_cat:======================== TRAIN SET TEST RESULTS ========================\n",
      "INFO:medcat.rel_cat:Evaluating test samples...\n",
      "INFO:medcat.rel_cat:==================== Evaluation Results ===================\n",
      "INFO:medcat.rel_cat: no. of batches:11\n",
      "INFO:medcat.rel_cat: accuracy = 0.935\n",
      "INFO:medcat.rel_cat: f1 = 0.935\n",
      "INFO:medcat.rel_cat: loss = 0.189\n",
      "INFO:medcat.rel_cat: precision = 0.935\n",
      "INFO:medcat.rel_cat: recall = 0.935\n",
      "INFO:medcat.rel_cat:----------------------- class stats -----------------------\n",
      "INFO:medcat.rel_cat:label: NO_LINK | f1: 0.965 | prec : 1.000 | acc: 0.935 | recall: 0.935 \n",
      "INFO:medcat.rel_cat:label: LINK | f1: 0.000 | prec : 0.000 | acc: 0.753 | recall: 0.000 \n",
      "INFO:medcat.rel_cat:-----------------------------------------------------------\n",
      "INFO:medcat.rel_cat:===========================================================\n",
      "INFO:medcat.rel_cat:======================== TEST SET TEST RESULTS ========================\n",
      "INFO:medcat.rel_cat:Evaluating test samples...\n",
      "INFO:medcat.rel_cat:==================== Evaluation Results ===================\n",
      "INFO:medcat.rel_cat: no. of batches:3\n",
      "INFO:medcat.rel_cat: accuracy = 0.625\n",
      "INFO:medcat.rel_cat: f1 = 0.625\n",
      "INFO:medcat.rel_cat: loss = 0.839\n",
      "INFO:medcat.rel_cat: precision = 0.625\n",
      "INFO:medcat.rel_cat: recall = 0.625\n",
      "INFO:medcat.rel_cat:----------------------- class stats -----------------------\n",
      "INFO:medcat.rel_cat:label: NO_LINK | f1: 0.645 | prec : 0.667 | acc: 0.625 | recall: 0.625 \n",
      "INFO:medcat.rel_cat:label: LINK | f1: 0.000 | prec : 0.000 | acc: 0.625 | recall: 0.000 \n",
      "INFO:medcat.rel_cat:-----------------------------------------------------------\n",
      "INFO:medcat.rel_cat:===========================================================\n",
      "INFO:medcat.rel_cat:Epoch finished, took 0:02:26.678891 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "relCAT.train(\n",
    "    train_csv_path=\"../data/relations_date_entity_train.tsv\",  \n",
    "    checkpoint_path=\"../models/relcat_models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4343546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "relCAT.save(save_path=\"../models/relcat_models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332aa3d6",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d2d6c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:medcat.rel_cat:The default CDB file name 'cdb.dat' doesn't exist in the specified path, you will need to load & set                 a CDB manually via rel_cat.cdb = CDB.load('path') \n",
      "INFO:root:Loaded config.json\n",
      "INFO:medcat.utils.relation_extraction.bert.config:Loaded config from file: ../models/relcat_models\\model_config.json\n",
      "INFO:medcat.utils.relation_extraction.tokenizer:Tokenizer loaded TokenizerWrapperBERT_RelationExtraction from:../models/relcat_models\n",
      "INFO:medcat.utils.relation_extraction.models:RelCAT model config: BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.55.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30526\n",
      "}\n",
      "\n",
      "INFO:medcat.utils.relation_extraction.bert.model:RelCAT model config: BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.55.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30526\n",
      "}\n",
      "\n",
      "INFO:medcat.utils.relation_extraction.bert.model:Loaded model from file: ../models/relcat_models\\model.dat\n",
      "INFO:medcat.utils.relation_extraction.models:Loaded BertModel_RelationExtraction from pretrained_model_name_or_path: ../models/relcat_models\n",
      "INFO:root:Attempting to load RelCAT model on device: cpu\n",
      "INFO:root:Loaded checkpoint model.\n",
      "INFO:root:Loaded model and optimizer.\n",
      "INFO:medcat.utils.relation_extraction.base_component:BaseComponent_RelationExtraction initialized\n",
      "INFO:medcat.utils.relation_extraction.base_component:BaseComponent_RelationExtraction initialized\n"
     ]
    }
   ],
   "source": [
    "#Load model\n",
    "relCAT = RelCAT.load(\"../models/relcat_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe2d50d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded test data: 352 samples\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv(\"../data/relations_date_entity_test.tsv\", sep=\"\\t\")\n",
    "print(f\"Loaded test data: {len(test_df)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:medcat.rel_cat:total relations for doc: 183\n",
      "INFO:medcat.rel_cat:processing...\n",
      "100%|██████████| 183/183 [00:33<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing document 26461: min() arg is an empty sequence\n",
      "Error processing document 26462: min() arg is an empty sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:medcat.rel_cat:total relations for doc: 213\n",
      "INFO:medcat.rel_cat:processing...\n",
      "100%|██████████| 213/213 [00:39<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing document 26465: min() arg is an empty sequence\n",
      "Processed 5 test documents\n",
      "Total predictions: 396\n"
     ]
    }
   ],
   "source": [
    "# Run inference on all test documents with error handling\n",
    "all_predictions = []\n",
    "\n",
    "test_doc_ids = test_df['doc_id'].unique()\n",
    "\n",
    "for doc_id in test_doc_ids:\n",
    "    # Find the document\n",
    "    for project in data[\"projects\"]:\n",
    "        for doc in project[\"documents\"]:\n",
    "            if doc[\"id\"] == doc_id:\n",
    "                try:\n",
    "                    # Run inference\n",
    "                    output_doc_with_relations = relCAT.predict_text_with_anns(\n",
    "                        text=doc[\"text\"], \n",
    "                        annotations=doc[\"annotations\"]\n",
    "                    )\n",
    "                    \n",
    "                    # Collect results using correct dict keys\n",
    "                    for relation in output_doc_with_relations._.relations:\n",
    "                        all_predictions.append({\n",
    "                            'entity_label': relation['ent1_text'],\n",
    "                            'date': relation['ent2_text'],\n",
    "                            'confidence': relation['confidence'],\n",
    "                            'doc_id': doc_id\n",
    "                        })\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing document {doc_id}: {e}\")\n",
    "                    continue\n",
    "                \n",
    "                break\n",
    "\n",
    "print(f\"Processed {len(test_doc_ids)} test documents\")\n",
    "print(f\"Total predictions: {len(all_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "208a9a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Results:\n",
      "Total predictions: 396\n",
      "\n",
      "First 10 predictions:\n",
      "1. laboratory findings -> current medication (conf: 0.971) [doc: 26464]\n",
      "2. laboratory findings -> compliance (conf: 0.956) [doc: 26464]\n",
      "3. laboratory findings -> Cardiology (conf: 0.962) [doc: 26464]\n",
      "4. laboratory findings -> etiology (conf: 0.972) [doc: 26464]\n",
      "5. laboratory findings -> reports (conf: 0.965) [doc: 26464]\n",
      "6. laboratory findings -> stroke (conf: 0.960) [doc: 26464]\n",
      "7. laboratory findings -> follow (conf: 0.959) [doc: 26464]\n",
      "8. laboratory findings -> COPD (conf: 0.959) [doc: 26464]\n",
      "9. Current medications -> multiple_sclerosis (conf: 0.963) [doc: 26464]\n",
      "10. Current medications -> review of systems (conf: 0.957) [doc: 26464]\n",
      "\n",
      "High confidence predictions (>0.7): 396\n",
      "1. laboratory findings -> current medication (conf: 0.971)\n",
      "2. laboratory findings -> compliance (conf: 0.956)\n",
      "3. laboratory findings -> Cardiology (conf: 0.962)\n",
      "4. laboratory findings -> etiology (conf: 0.972)\n",
      "5. laboratory findings -> reports (conf: 0.965)\n"
     ]
    }
   ],
   "source": [
    "# Show results\n",
    "print(\"Test Set Results:\")\n",
    "print(f\"Total predictions: {len(all_predictions)}\")\n",
    "\n",
    "# Show first 10 predictions\n",
    "print(\"\\nFirst 10 predictions:\")\n",
    "for i, pred in enumerate(all_predictions[:10]):\n",
    "    print(f\"{i+1}. {pred['entity_label']} -> {pred['date']} (conf: {pred['confidence']:.3f}) [doc: {pred['doc_id']}]\")\n",
    "\n",
    "# Show high confidence predictions\n",
    "high_conf = [p for p in all_predictions if p['confidence'] > 0.7]\n",
    "print(f\"\\nHigh confidence predictions (>0.7): {len(high_conf)}\")\n",
    "for i, pred in enumerate(high_conf[:5]):  # Show first 5\n",
    "    print(f\"{i+1}. {pred['entity_label']} -> {pred['date']} (conf: {pred['confidence']:.3f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
